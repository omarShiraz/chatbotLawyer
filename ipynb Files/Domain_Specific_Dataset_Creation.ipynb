{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omarShiraz/chatbotLawyer/blob/main/ipynb%20Files/Domain_Specific_Dataset_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z4L5Ty6u38rT",
        "outputId": "1380608a-f221-4187-c247-6862dc0abe8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting git+https://github.com/omarShiraz/Questgen.ai.git\n",
            "  Cloning https://github.com/omarShiraz/Questgen.ai.git to /tmp/pip-req-build-9veltsz8\n",
            "  Running command git version\n",
            "  git version 2.34.1\n",
            "  Running command git clone --filter=blob:none https://github.com/omarShiraz/Questgen.ai.git /tmp/pip-req-build-9veltsz8\n",
            "  Cloning into '/tmp/pip-req-build-9veltsz8'...\n",
            "  Running command git rev-parse HEAD\n",
            "  536c78d94a21ce02ea5a4d11232263177e447c66\n",
            "  Resolved https://github.com/omarShiraz/Questgen.ai.git to commit 536c78d94a21ce02ea5a4d11232263177e447c66\n",
            "  Running command git rev-parse HEAD\n",
            "  536c78d94a21ce02ea5a4d11232263177e447c66\n",
            "  Running command python setup.py egg_info\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==2.0.1 (from Questgen==1.0.1)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.29.2 (from Questgen==1.0.1)\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sense2vec==2.0.2 (from Questgen==1.0.1)\n",
            "  Downloading sense2vec-2.0.2-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting strsim==0.0.3 (from Questgen==1.0.1)\n",
            "  Downloading strsim-0.0.3-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from Questgen==1.0.1) (1.16.0)\n",
            "Collecting networkx==3.1 (from Questgen==1.0.1)\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.22.4 (from Questgen==1.0.1)\n",
            "  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Link requires a different Python (3.10.12 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/99/f1/c00d6be56e1a718a3068079e3ec8ce044d7179345280f6a3f5066068af0d/scipy-1.6.2.tar.gz (from https://pypi.org/simple/scipy/) (requires-python:>=3.7,<3.10)\n",
            "  Link requires a different Python (3.10.12 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/fe/fd/8704c7b7b34cdac850485e638346025ca57c5a859934b9aa1be5399b33b7/scipy-1.6.3.tar.gz (from https://pypi.org/simple/scipy/) (requires-python:>=3.7,<3.10)\n",
            "  Link requires a different Python (3.10.12 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/bb/bb/944f559d554df6c9adf037aa9fc982a9706ee0e96c0d5beac701cb158900/scipy-1.7.0.tar.gz (from https://pypi.org/simple/scipy/) (requires-python:>=3.7,<3.10)\n",
            "  Link requires a different Python (3.10.12 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/47/33/a24aec22b7be7fdb10ec117a95e1e4099890d8bbc6646902f443fc7719d1/scipy-1.7.1.tar.gz (from https://pypi.org/simple/scipy/) (requires-python:>=3.7,<3.10)\n",
            "Collecting scipy==1.10.1 (from Questgen==1.0.1)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from Questgen==1.0.1) (1.2.2)\n",
            "Collecting unidecode==1.3 (from Questgen==1.0.1)\n",
            "  Downloading Unidecode-1.3.0-py2.py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.7/235.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future==0.18.3 in /usr/local/lib/python3.10/dist-packages (from Questgen==1.0.1) (0.18.3)\n",
            "Collecting joblib==1.2.0 (from Questgen==1.0.1)\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz==2022.7.1 (from Questgen==1.0.1)\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from Questgen==1.0.1) (2.8.2)\n",
            "Collecting flashtext==2.7 (from Questgen==1.0.1)\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-7ilf8xse/flashtext.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-7ilf8xse/flashtext.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-7ilf8xse/flashtext.egg-info/dependency_links.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-7ilf8xse/flashtext.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-7ilf8xse/flashtext.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-7ilf8xse/flashtext.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-7ilf8xse/flashtext.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas==1.5.3 (from Questgen==1.0.1)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from Questgen==1.0.1) (0.1.99)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->Questgen==1.0.1) (3.4.0)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from sense2vec==2.0.2->Questgen==1.0.1) (3.7.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from sense2vec==2.0.2->Questgen==1.0.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from sense2vec==2.0.2->Questgen==1.0.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from sense2vec==2.0.2->Questgen==1.0.1) (2.0.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->Questgen==1.0.1) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->Questgen==1.0.1) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->Questgen==1.0.1) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->Questgen==1.0.1) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.2->Questgen==1.0.1) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.2->Questgen==1.0.1) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.2->Questgen==1.0.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.2->Questgen==1.0.1) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.2->Questgen==1.0.1) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.2->Questgen==1.0.1)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.29.2->Questgen==1.0.1) (4.66.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->Questgen==1.0.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->Questgen==1.0.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->Questgen==1.0.1) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->Questgen==1.0.1)\n",
            "  Downloading lit-18.1.2.tar.gz (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting setuptools\n",
            "    Downloading setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 821.5/821.5 kB 5.4 MB/s eta 0:00:00\n",
            "  Installing collected packages: setuptools\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "  Successfully installed setuptools-69.2.0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Getting requirements to build wheel\n",
            "  running egg_info\n",
            "  writing lit.egg-info/PKG-INFO\n",
            "  writing dependency_links to lit.egg-info/dependency_links.txt\n",
            "  writing entry points to lit.egg-info/entry_points.txt\n",
            "  writing top-level names to lit.egg-info/top_level.txt\n",
            "  reading manifest file 'lit.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no files found matching 'TODO'\n",
            "  warning: no previously-included files matching '*pyc' found anywhere in distribution\n",
            "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
            "  no previously-included directories found matching 'tests/Output'\n",
            "  no previously-included directories found matching 'tests/*/Output'\n",
            "  no previously-included directories found matching 'tests/*/*/Output'\n",
            "  no previously-included directories found matching 'tests/*/*/*/Output'\n",
            "  adding license file 'LICENSE.TXT'\n",
            "  writing manifest file 'lit.egg-info/SOURCES.txt'\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command pip subprocess to install backend dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting wheel\n",
            "    Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.8/65.8 kB 991.8 kB/s eta 0:00:00\n",
            "  Installing collected packages: wheel\n",
            "    Creating /tmp/pip-build-env-yfjb54h6/normal/local/bin\n",
            "    changing mode of /tmp/pip-build-env-yfjb54h6/normal/local/bin/wheel to 755\n",
            "  Successfully installed wheel-0.43.0\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  running dist_info\n",
            "  creating /tmp/pip-modern-metadata-set8d5t_/lit.egg-info\n",
            "  writing /tmp/pip-modern-metadata-set8d5t_/lit.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-modern-metadata-set8d5t_/lit.egg-info/dependency_links.txt\n",
            "  writing entry points to /tmp/pip-modern-metadata-set8d5t_/lit.egg-info/entry_points.txt\n",
            "  writing top-level names to /tmp/pip-modern-metadata-set8d5t_/lit.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-modern-metadata-set8d5t_/lit.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-modern-metadata-set8d5t_/lit.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no files found matching 'TODO'\n",
            "  warning: no previously-included files matching '*pyc' found anywhere in distribution\n",
            "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
            "  no previously-included directories found matching 'tests/Output'\n",
            "  no previously-included directories found matching 'tests/*/Output'\n",
            "  no previously-included directories found matching 'tests/*/*/Output'\n",
            "  no previously-included directories found matching 'tests/*/*/*/Output'\n",
            "  adding license file 'LICENSE.TXT'\n",
            "  writing manifest file '/tmp/pip-modern-metadata-set8d5t_/lit.egg-info/SOURCES.txt'\n",
            "  creating '/tmp/pip-modern-metadata-set8d5t_/lit-18.1.2.dist-info'\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.2->Questgen==1.0.1) (2023.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (8.2.3)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (2.6.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (3.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.29.2->Questgen==1.0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.29.2->Questgen==1.0.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.29.2->Questgen==1.0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.29.2->Questgen==1.0.1) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->Questgen==1.0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->Questgen==1.0.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (2.16.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.0.0->sense2vec==2.0.2->Questgen==1.0.1) (0.16.0)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'unidecode' candidate (version 1.3.0 at https://files.pythonhosted.org/packages/2f/45/118b264e2740a29bb3f6e52431e2425c45f0ef44f37e985c147624042f00/Unidecode-1.3.0-py2.py3-none-any.whl (from https://pypi.org/simple/unidecode/))\n",
            "Reason for being yanked: Wheel falsely claims to support Python 2.\u001b[0m\u001b[33m\n",
            "\u001b[0mBuilding wheels for collected packages: Questgen, flashtext, lit\n",
            "  Running command python setup.py bdist_wheel\n",
            "  /usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Please avoid running ``setup.py`` directly.\n",
            "          Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "          other standards-based tools.\n",
            "\n",
            "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    self.initialize_options()\n",
            "  Building wheel for Questgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Questgen: filename=Questgen-1.0.1-py3-none-any.whl size=8690 sha256=cf3c9e2ba815ff1e86faeb24c09c7189c839e201becde1d6e99dd03421a40028\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s16uk78n/wheels/60/f4/df/ae4fdacf63a817fde32e46ea11037fa64e9f0d01d919be8b23\n",
            "  Running command python setup.py bdist_wheel\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/flashtext\n",
            "  copying flashtext/__init__.py -> build/lib/flashtext\n",
            "  copying flashtext/keyword.py -> build/lib/flashtext\n",
            "  /usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Please avoid running ``setup.py`` directly.\n",
            "          Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "          other standards-based tools.\n",
            "\n",
            "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    self.initialize_options()\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/flashtext\n",
            "  copying build/lib/flashtext/__init__.py -> build/bdist.linux-x86_64/wheel/flashtext\n",
            "  copying build/lib/flashtext/keyword.py -> build/bdist.linux-x86_64/wheel/flashtext\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing flashtext.egg-info/PKG-INFO\n",
            "  writing dependency_links to flashtext.egg-info/dependency_links.txt\n",
            "  writing top-level names to flashtext.egg-info/top_level.txt\n",
            "  reading manifest file 'flashtext.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'flashtext.egg-info/SOURCES.txt'\n",
            "  Copying flashtext.egg-info to build/bdist.linux-x86_64/wheel/flashtext-2.7-py3.10.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/flashtext-2.7.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-50b7lrwg/flashtext-2.7-py2.py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'flashtext/__init__.py'\n",
            "  adding 'flashtext/keyword.py'\n",
            "  adding 'flashtext-2.7.dist-info/LICENSE'\n",
            "  adding 'flashtext-2.7.dist-info/METADATA'\n",
            "  adding 'flashtext-2.7.dist-info/WHEEL'\n",
            "  adding 'flashtext-2.7.dist-info/top_level.txt'\n",
            "  adding 'flashtext-2.7.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9296 sha256=2b11ac9991fe68ced293ddef4664434121b9dda6e19e6cf5c8abf79568c29798\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
            "  Running command Building wheel for lit (pyproject.toml)\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/lit\n",
            "  copying lit/ShCommands.py -> build/lib/lit\n",
            "  copying lit/__init__.py -> build/lib/lit\n",
            "  copying lit/cl_arguments.py -> build/lib/lit\n",
            "  copying lit/ProgressBar.py -> build/lib/lit\n",
            "  copying lit/util.py -> build/lib/lit\n",
            "  copying lit/Test.py -> build/lib/lit\n",
            "  copying lit/worker.py -> build/lib/lit\n",
            "  copying lit/TestTimes.py -> build/lib/lit\n",
            "  copying lit/reports.py -> build/lib/lit\n",
            "  copying lit/ShUtil.py -> build/lib/lit\n",
            "  copying lit/run.py -> build/lib/lit\n",
            "  copying lit/TestingConfig.py -> build/lib/lit\n",
            "  copying lit/LitTestCase.py -> build/lib/lit\n",
            "  copying lit/discovery.py -> build/lib/lit\n",
            "  copying lit/LitConfig.py -> build/lib/lit\n",
            "  copying lit/BooleanExpression.py -> build/lib/lit\n",
            "  copying lit/display.py -> build/lib/lit\n",
            "  copying lit/main.py -> build/lib/lit\n",
            "  copying lit/TestRunner.py -> build/lib/lit\n",
            "  creating build/lib/lit/formats\n",
            "  copying lit/formats/__init__.py -> build/lib/lit/formats\n",
            "  copying lit/formats/googletest.py -> build/lib/lit/formats\n",
            "  copying lit/formats/shtest.py -> build/lib/lit/formats\n",
            "  copying lit/formats/base.py -> build/lib/lit/formats\n",
            "  creating build/lib/lit/llvm\n",
            "  copying lit/llvm/__init__.py -> build/lib/lit/llvm\n",
            "  copying lit/llvm/subst.py -> build/lib/lit/llvm\n",
            "  copying lit/llvm/config.py -> build/lib/lit/llvm\n",
            "  creating build/lib/lit/builtin_commands\n",
            "  copying lit/builtin_commands/__init__.py -> build/lib/lit/builtin_commands\n",
            "  copying lit/builtin_commands/cat.py -> build/lib/lit/builtin_commands\n",
            "  copying lit/builtin_commands/diff.py -> build/lib/lit/builtin_commands\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/ShCommands.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/__init__.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/cl_arguments.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  creating build/bdist.linux-x86_64/wheel/lit/formats\n",
            "  copying build/lib/lit/formats/__init__.py -> build/bdist.linux-x86_64/wheel/lit/formats\n",
            "  copying build/lib/lit/formats/googletest.py -> build/bdist.linux-x86_64/wheel/lit/formats\n",
            "  copying build/lib/lit/formats/shtest.py -> build/bdist.linux-x86_64/wheel/lit/formats\n",
            "  copying build/lib/lit/formats/base.py -> build/bdist.linux-x86_64/wheel/lit/formats\n",
            "  copying build/lib/lit/ProgressBar.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/util.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  creating build/bdist.linux-x86_64/wheel/lit/llvm\n",
            "  copying build/lib/lit/llvm/__init__.py -> build/bdist.linux-x86_64/wheel/lit/llvm\n",
            "  copying build/lib/lit/llvm/subst.py -> build/bdist.linux-x86_64/wheel/lit/llvm\n",
            "  copying build/lib/lit/llvm/config.py -> build/bdist.linux-x86_64/wheel/lit/llvm\n",
            "  copying build/lib/lit/Test.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/worker.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/TestTimes.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/reports.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/ShUtil.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/run.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/TestingConfig.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/LitTestCase.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/discovery.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/LitConfig.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/BooleanExpression.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/display.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  creating build/bdist.linux-x86_64/wheel/lit/builtin_commands\n",
            "  copying build/lib/lit/builtin_commands/__init__.py -> build/bdist.linux-x86_64/wheel/lit/builtin_commands\n",
            "  copying build/lib/lit/builtin_commands/cat.py -> build/bdist.linux-x86_64/wheel/lit/builtin_commands\n",
            "  copying build/lib/lit/builtin_commands/diff.py -> build/bdist.linux-x86_64/wheel/lit/builtin_commands\n",
            "  copying build/lib/lit/main.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  copying build/lib/lit/TestRunner.py -> build/bdist.linux-x86_64/wheel/lit\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing lit.egg-info/PKG-INFO\n",
            "  writing dependency_links to lit.egg-info/dependency_links.txt\n",
            "  writing entry points to lit.egg-info/entry_points.txt\n",
            "  writing top-level names to lit.egg-info/top_level.txt\n",
            "  reading manifest file 'lit.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no files found matching 'TODO'\n",
            "  warning: no previously-included files matching '*pyc' found anywhere in distribution\n",
            "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
            "  no previously-included directories found matching 'tests/Output'\n",
            "  no previously-included directories found matching 'tests/*/Output'\n",
            "  no previously-included directories found matching 'tests/*/*/Output'\n",
            "  no previously-included directories found matching 'tests/*/*/*/Output'\n",
            "  adding license file 'LICENSE.TXT'\n",
            "  writing manifest file 'lit.egg-info/SOURCES.txt'\n",
            "  Copying lit.egg-info to build/bdist.linux-x86_64/wheel/lit-18.1.2-py3.10.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/lit-18.1.2.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-rl5btp45/.tmp-zh3mc37i/lit-18.1.2-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'lit/BooleanExpression.py'\n",
            "  adding 'lit/LitConfig.py'\n",
            "  adding 'lit/LitTestCase.py'\n",
            "  adding 'lit/ProgressBar.py'\n",
            "  adding 'lit/ShCommands.py'\n",
            "  adding 'lit/ShUtil.py'\n",
            "  adding 'lit/Test.py'\n",
            "  adding 'lit/TestRunner.py'\n",
            "  adding 'lit/TestTimes.py'\n",
            "  adding 'lit/TestingConfig.py'\n",
            "  adding 'lit/__init__.py'\n",
            "  adding 'lit/cl_arguments.py'\n",
            "  adding 'lit/discovery.py'\n",
            "  adding 'lit/display.py'\n",
            "  adding 'lit/main.py'\n",
            "  adding 'lit/reports.py'\n",
            "  adding 'lit/run.py'\n",
            "  adding 'lit/util.py'\n",
            "  adding 'lit/worker.py'\n",
            "  adding 'lit/builtin_commands/__init__.py'\n",
            "  adding 'lit/builtin_commands/cat.py'\n",
            "  adding 'lit/builtin_commands/diff.py'\n",
            "  adding 'lit/formats/__init__.py'\n",
            "  adding 'lit/formats/base.py'\n",
            "  adding 'lit/formats/googletest.py'\n",
            "  adding 'lit/formats/shtest.py'\n",
            "  adding 'lit/llvm/__init__.py'\n",
            "  adding 'lit/llvm/config.py'\n",
            "  adding 'lit/llvm/subst.py'\n",
            "  adding 'lit-18.1.2.dist-info/LICENSE.TXT'\n",
            "  adding 'lit-18.1.2.dist-info/METADATA'\n",
            "  adding 'lit-18.1.2.dist-info/WHEEL'\n",
            "  adding 'lit-18.1.2.dist-info/entry_points.txt'\n",
            "  adding 'lit-18.1.2.dist-info/top_level.txt'\n",
            "  adding 'lit-18.1.2.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-18.1.2-py3-none-any.whl size=96368 sha256=29ff4fd67af432c34682f674ec5e8f343014b03469a5ba7cf1d075c0c5ac4ad3\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/4d/9c/3e28d23c2c6fc6a9bd89c91a7b7ff775fc71a41ac9a52563e9\n",
            "Successfully built Questgen flashtext lit\n",
            "Installing collected packages: tokenizers, strsim, pytz, lit, flashtext, unidecode, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, joblib, scipy, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, transformers, sense2vec, triton, torch, Questgen\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/tokenizers-0.15.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/tokenizers/\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.4\n",
            "    Uninstalling pytz-2023.4:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/pytz-2023.4.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/pytz/\n",
            "      Successfully uninstalled pytz-2023.4\n",
            "  changing mode of /usr/local/bin/lit to 755\n",
            "  changing mode of /usr/local/bin/unidecode to 755\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Removing file or directory /usr/local/bin/f2py\n",
            "      Removing file or directory /usr/local/bin/f2py3\n",
            "      Removing file or directory /usr/local/bin/f2py3.10\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy-1.25.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/numpy/\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  changing mode of /usr/local/bin/f2py to 755\n",
            "  changing mode of /usr/local/bin/f2py3 to 755\n",
            "  changing mode of /usr/local/bin/f2py3.10 to 755\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/networkx-3.2.1.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/networkx/\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/joblib-1.3.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/joblib/\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scipy-1.11.4.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scipy.libs/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/scipy/\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/pandas-2.0.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/pandas/\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Removing file or directory /usr/local/bin/transformers-cli\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/transformers-4.38.2.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/transformers/\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "  changing mode of /usr/local/bin/transformers-cli to 755\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/triton-2.2.0.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/triton/\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Removing file or directory /usr/local/bin/convert-caffe2-to-onnx\n",
            "      Removing file or directory /usr/local/bin/convert-onnx-to-caffe2\n",
            "      Removing file or directory /usr/local/bin/torchrun\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/functorch/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/torch-2.2.1+cu121.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/torch/\n",
            "      Removing file or directory /usr/local/lib/python3.10/dist-packages/torchgen/\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  changing mode of /usr/local/bin/convert-caffe2-to-onnx to 755\n",
            "  changing mode of /usr/local/bin/convert-onnx-to-caffe2 to 755\n",
            "  changing mode of /usr/local/bin/torchrun to 755\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.5.3 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.22.4 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Questgen-1.0.1 flashtext-2.7 joblib-1.2.0 lit-18.1.2 networkx-3.1 numpy-1.22.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pandas-1.5.3 pytz-2022.7.1 scipy-1.10.1 sense2vec-2.0.2 strsim-0.0.3 tokenizers-0.13.3 torch-2.0.1 transformers-4.29.2 triton-2.0.0 unidecode-1.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "441cb73f46fa47c7817eff3f0c7553c6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#installing and upgrading Questgen.ai package from the specified GitHub repository using pip. Using verbose to give more detailed output\n",
        "!pip install --upgrade --verbose git+https://github.com/omarShiraz/Questgen.ai.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FUXJxwqJ3_tA",
        "outputId": "7b1c4dee-8c17-4fb0-d7c0-8c5a117fd395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fitz in /usr/local/lib/python3.10/dist-packages (0.0.1.dev2)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from fitz) (5.0.8)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (from fitz) (6.0.1)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (4.0.2)\n",
            "Requirement already satisfied: nipype in /usr/local/lib/python3.10/dist-packages (from fitz) (1.8.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (1.5.3)\n",
            "Requirement already satisfied: pyxnat in /usr/local/lib/python3.10/dist-packages (from fitz) (1.6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->fitz) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.1.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (67.7.2)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.1)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.0.0)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (7.0.0)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.19.2)\n",
            "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (6.3.2)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.13.3)\n",
            "Requirement already satisfied: etelemetry>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (0.3.1)\n",
            "Requirement already satisfied: looseversion in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2022.7.1)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.31.0)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.10/dist-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2024.2.2)\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.1-cp310-none-manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.1 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.1 PyMuPDFb-1.24.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "questgen 1.0.1 requires numpy==1.22.4, but you have numpy 1.26.4 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Collecting spaCy==2.3.3\n",
            "  Downloading spacy-2.3.3.tar.gz (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spaCy==2.3.3) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy==2.3.3) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy==2.3.3) (3.0.9)\n",
            "Collecting thinc<7.5.0,>=7.4.1 (from spaCy==2.3.3)\n",
            "  Using cached thinc-7.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Collecting wasabi<1.1.0,>=0.4.0 (from spaCy==2.3.3)\n",
            "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<1.1.0,>=1.0.2 (from spaCy==2.3.3)\n",
            "  Using cached srsly-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (369 kB)\n",
            "Collecting catalogue<1.1.0,>=0.0.7 (from spaCy==2.3.3)\n",
            "  Using cached catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spaCy==2.3.3) (4.66.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spaCy==2.3.3) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spaCy==2.3.3) (1.26.4)\n",
            "Collecting plac<1.2.0,>=0.9.6 (from spaCy==2.3.3)\n",
            "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spaCy==2.3.3) (2.31.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spaCy==2.3.3) (0.7.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy==2.3.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy==2.3.3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy==2.3.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy==2.3.3) (2024.2.2)\n",
            "Building wheels for collected packages: spaCy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for spaCy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for spaCy (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for spaCy\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build spaCy\n",
            "\u001b[31mERROR: Could not build wheels for spaCy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "#fitz package for PDF file manipulation.\n",
        "!pip install fitz\n",
        "\n",
        "#PyMuPDF for PDF handling functionalities.\n",
        "!pip install PyMuPDF\n",
        "\n",
        "#transformers for utilizing pre-trained NLP models.\n",
        "!pip install transformers\n",
        "\n",
        "# Upgrade numpy to ensure compatibility and access to the latest features.\n",
        "!pip install --upgrade numpy\n",
        "\n",
        "#spaCy version 2.3.3 for natural language processing tasks. since this verison only supports questgen\n",
        "!pip install spaCy==2.3.3\n",
        "\n",
        "# Install 'pke' (Python Keyphrase Extraction toolkit) for extracting keyphrases from text.\n",
        "!pip install --quiet git+https://github.com/boudinfl/pke.git\n",
        "\n",
        "# Download the universal tagset for NLTK (Natural Language Toolkit) to be used in tagging text.\n",
        "!python -m nltk.downloader universal_tagset\n",
        "\n",
        "# Download the English model for spaCy to support English language processing tasks.\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#datasets package for easy access to various datasets.\n",
        "#transformers package for accessing pre-trained models and related utilities.\n",
        "#sentence_transformers package for sentence embeddings.\n",
        "#faiss-gpu package for efficient similarity search on GPUs.\n",
        "!pip install -q datasets sentence_transformers faiss-gpu"
      ],
      "metadata": {
        "id": "KAAyEqcxspzE",
        "outputId": "d58a4609-7dbd-43c4-89ac-a035684d3d3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/510.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m501.8/510.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rO8bFx44VWN"
      },
      "source": [
        "## **Restart runtime before continuing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k2R-b20B6OFj",
        "outputId": "94d0c2e3-cf93-4cda-befb-35f2c5bc25ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-04 10:09:38--  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240404T100938Z&X-Amz-Expires=300&X-Amz-Signature=d90da1132855da0f93b685f43ec94c88e5df337fe339189c13d77d989fa883ce&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-04 10:09:38--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240404T100938Z&X-Amz-Expires=300&X-Amz-Signature=d90da1132855da0f93b685f43ec94c88e5df337fe339189c13d77d989fa883ce&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600444501 (573M) [application/octet-stream]\n",
            "Saving to: ‘s2v_reddit_2015_md.tar.gz.1’\n",
            "\n",
            "s2v_reddit_2015_md. 100%[===================>] 572.63M   114MB/s    in 4.2s    \n",
            "\n",
            "2024-04-04 10:09:42 (135 MB/s) - ‘s2v_reddit_2015_md.tar.gz.1’ saved [600444501/600444501]\n",
            "\n",
            "./._s2v_old\n",
            "./s2v_old/\n",
            "./s2v_old/._freqs.json\n",
            "./s2v_old/freqs.json\n",
            "./s2v_old/._vectors\n",
            "./s2v_old/vectors\n",
            "./s2v_old/._cfg\n",
            "./s2v_old/cfg\n",
            "./s2v_old/._strings.json\n",
            "./s2v_old/strings.json\n",
            "./s2v_old/._key2row\n",
            "./s2v_old/key2row\n",
            "cfg  freqs.json  key2row  strings.json\tvectors\n"
          ]
        }
      ],
      "source": [
        "# Downloads and extracts the sense2vec model, which provides word vectors with additional semantic information.\n",
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "\n",
        "# Extract the contents of the downloaded tar.gz file.\n",
        "!tar -xvf s2v_reddit_2015_md.tar.gz\n",
        "\n",
        "# List the contents of the directory named 's2v_old'.\n",
        "!ls s2v_old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3FTRjmMz4092",
        "outputId": "7d9f9dc8-197f-483b-a25c-115a4e24c120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b53d699cd1cd40c49d84f0eaa688d068",
            "7762674f5c3c4636bcf11e644f154d2c",
            "b5175cdd4d9549d2851ff698c9f447e2",
            "cf5922237ba846ef8167113628dee223",
            "2eb5e889b15a4a17bb53810a32a72693",
            "d21ac0e4eb8441f5901b7329e70973a4",
            "2c37b256835c4356b69e67853dd196f7",
            "7e5e57de850a42d99b51545f13b4c8f1",
            "92fae06ae8f042339ca77823f2c66da8",
            "8e9320fc2cc6433f94d92f7c6b4b95d7",
            "bbe40f5ab4154473a0a61688314791ad",
            "3b5afe3b1dfc4b0fbc40db6cfa38cbd2",
            "420625c7c20e4c7ab17658c1c29dc7b4",
            "1c0f1fe4c56f47d88b57a9cce1bf6cca",
            "1fd6c2e019fd4ebdb2ecb0b7e0bf883d",
            "3e22ea1534bc401cb6ce8943b65eb84b",
            "04d16b9236474b45a8b9f8e42414778e",
            "4408ed4063294ab2927afaf231337718",
            "a4d0aec02da74f9a8f6ba5b73d2d6516",
            "03e44ab47e4c42d6a5c12e2c69d4b79a",
            "d901407748144b3d99c6a4b96f8d137e",
            "a1f1d003b3854960bb6274f7035634bc",
            "503dad18262e44dc84bcc283148e8159",
            "3fbe1756fa5e4736863a547c9f681d2c",
            "650b80d6fd274fff9623ec26ac0867b4",
            "fc00e15918e744a69fd19b71b25cbb66",
            "f775f8b867eb4acc8865376282092cbf",
            "05cc85246807451383fe29320725adca",
            "9a2b3e1a44154160b2a720d2a095ce41",
            "cc0dbb0b88dc43fe909447b734eac4bb",
            "e3bf925b4f4648159956c59a4fe806bc",
            "6bd4c536323f4f1890b1ec220b321666",
            "6e54ea6665c146b7834c7043b4dd6e4a",
            "323be172daf54fd681683410c6e8fc03",
            "fab2d55fce8745b6a1130d7843882d7d",
            "6aef4510ffa144debf0d312909afee37",
            "0fd2511e131b4fc88a9645734ebdf4ca",
            "a4696b5bea264d2091a2b36322e3da6b",
            "e41371909325499e8cf83fafa16924b9",
            "36396aaa899b4983870ebbcf3243a9f8",
            "4acfaef57f964c75a1fd9af9b35e4f5b",
            "eccda2d6bd0745ad8f1f2041de1590a1",
            "76d5799e46834de088fba9a571d31372",
            "31f7bb6d0f47401d86bbae361c86f687"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b53d699cd1cd40c49d84f0eaa688d068"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b5afe3b1dfc4b0fbc40db6cfa38cbd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "503dad18262e44dc84bcc283148e8159"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "323be172daf54fd681683410c6e8fc03"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import nltk  # Import the NLTK library for natural language processing tasks.\n",
        "from pprint import pprint  # Import pprint (Pretty Print) module to print data structures in a readable format.\n",
        "from Questgen import main  # Import the main module from the Questgen package.\n",
        "\n",
        "qg = main.QGen()  # Instantiate the QGen class from the Questgen package to initialize the question generation engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ama9Ef-T9nO_",
        "outputId": "130dda63-f887-421b-e363-7fe1c60c4009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the country that was printed in the Gazette of the Democratic Socialist Republic of Sri Lanka in December 2010?', 'Answer': 'sri lanka', 'id': 1, 'context': '20.00 PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLIC OF SRI LANKA Published as a Supplement to Part II of the Gazette of the Democratic Socialist Republic of Sri Lanka of December 10, 2010. 20.00 PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLIC OF SRI LANKA Published as a Supplement to Part II of the Gazette of the Democratic Socialist Republic of Sri Lanka of December 10, 2010. PRINTED AT THE DEPARTMENT OF GOVERNMENT PRINTING, SRI LANKA TO BE PURCHASED AT THE GOVERNMENT PUBLICATIONS BUREAU, COLOMBO 5 Price : Rs.'}, {'Question': 'What is the political party of Sri Lanka?', 'Answer': 'socialist republic', 'id': 2, 'context': '20.00 PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLIC OF SRI LANKA Published as a Supplement to Part II of the Gazette of the Democratic Socialist Republic of Sri Lanka of December 10, 2010. 20.00 PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLIC OF SRI LANKA Published as a Supplement to Part II of the Gazette of the Democratic Socialist Republic of Sri Lanka of December 10, 2010.'}, {'Question': 'Where is the Government Printing Bureau located?', 'Answer': 'colombo', 'id': 3, 'context': 'PRINTED AT THE DEPARTMENT OF GOVERNMENT PRINTING, SRI LANKA TO BE PURCHASED AT THE GOVERNMENT PUBLICATIONS BUREAU, COLOMBO 5 Price : Rs.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is DIRECTLY ATTRIBUTABLE TO ANY NATURAL DISASTER OR CALAMITY?', 'Answer': 'deaths', 'id': 1, 'context': 'AN ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING AS A RESULT OF TERRORIST OR SUBVERSIVE ACTIVITY OR CIVIL COMMOTION AND OF PERSONS WHOSE DEATHS ARE DIRECTLY ATTRIBUTABLE TO ANY NATURAL DISASTER OR CALAMITY AND SUCH ACTIVITY, DISASTER OR CALAMITY RESULTS IN SERIOUS CONSEQUENCES AT NATIONAL LEVEL; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERET AN ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING AS A RESULT OF TERRORIST OR SUBVERSIVE ACTIVITY OR CIVIL COMMOTION AND OF PERSONS WHOSE DEATHS ARE DIRECTLY ATTRIBUTABLE TO ANY NATURAL DISASTER OR CALAMITY AND SUCH ACTIVITY, DISASTER OR CALAMITY RESULTS IN SERIOUS CONSEQUENCES AT NATIONAL LEVEL; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERET 1 Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'AN ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING AS A RESULT OF TERRORIST OR SUBVERSIVE ACTIVITY OR CIVIL COMMOTION AND OF PERSONS WHOSE DEATHS ARE DIRECTLY ATTRIBUTABLE TO ANY NATURAL DISASTER OR CALAMITY AND SUCH ACTIVITY, DISASTER OR CALAMITY RESULTS IN SE', 'Answer': 'activity', 'id': 2, 'context': 'AN ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING AS A RESULT OF TERRORIST OR SUBVERSIVE ACTIVITY OR CIVIL COMMOTION AND OF PERSONS WHOSE DEATHS ARE DIRECTLY ATTRIBUTABLE TO ANY NATURAL DISASTER OR CALAMITY AND SUCH ACTIVITY, DISASTER OR CALAMITY RESULTS IN SERIOUS CONSEQUENCES AT NATIONAL LEVEL; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERET AN ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING AS A RESULT OF TERRORIST OR SUBVERSIVE ACTIVITY OR CIVIL COMMOTION AND OF PERSONS WHOSE DEATHS ARE DIRECTLY ATTRIBUTABLE TO ANY NATURAL DISASTER OR CALAMITY AND SUCH ACTIVITY, DISASTER OR CALAMITY RESULTS IN SERIOUS CONSEQUENCES AT NATIONAL LEVEL; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERET'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where have there been many deaths or missing persons in the course of the civil disturbances that have taken place in the course of the terrorist or subversive activities or civil commotion?', 'Answer': 'sri lanka', 'id': 1, 'context': 'WHEREAS several persons have died or have been reported missing in the course of the civil disturbances that have taken place in Sri Lanka due to terrorist or subversive activities or civil commotion: AND WHEREAS several people have died due to being exposed to natural disasters or calamities of national proportions : AND WHEREAS there are certain practical difficulties which impede the registration of deaths in the circumstances which are enumerated above under the provisions of the Births and Deaths Re'}, {'Question': 'What are natural disasters or calamities of national proportions?', 'Answer': 'calamities', 'id': 2, 'context': 'WHEREAS several persons have died or have been reported missing in the course of the civil disturbances that have taken place in Sri Lanka due to terrorist or subversive activities or civil commotion: AND WHEREAS several people have died due to being exposed to natural disasters or calamities of national proportions : AND WHEREAS there are certain practical difficulties which impede the registration of deaths in the circumstances which are enumerated above under the provisions of the Births and Deaths Re'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the country that passed the gistration act?', 'Answer': 'sri lanka', 'id': 1, 'context': 'gistration Act: AND WHEREAS it has now become necessary to enact legislation providing measures for the registration of such deaths: NOW THEREFORE BE it enacted by the Parliament of the Democratic Socialist Republic of Sri Lanka as follows:— 1.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the registration of death?', 'Answer': 'deaths', 'id': 1, 'context': '2 Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What is the purpose of the Deaths Act, No. 2?', 'Answer': 'registration', 'id': 2, 'context': '2 Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What is the short title of the Act?', 'Answer': 'title', 'id': 3, 'context': 'he Minister may not less than one month prior to the expiration of any period of operation of this Act, by Order published in the Gazette, extend such period of operation: Short title, duration and extension of operation of the Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where is the person reported missing and he has not been heard of for a period exceeding one year by those who would naturally have heard of him, had he been alive and his disappearance is attributable to any terrorist or subversive activity or civil commotion which has taken place within?', 'Answer': 'sri lanka', 'id': 1, 'context': '(1) Where any person is reported missing and he has not been heard of for a period exceeding one year by those who would naturally have heard of him, had he been alive and his disappearance is attributable to any terrorist or subversive activity or civil commotion which has taken place within Sri Lanka, a next of kin of such person if he verily believes such person to be dead, ma'}, {'Question': 'If a person is reported missing and he has not been heard of for more than one year, who would naturally have heard of him if he was alive and his disappearance is attributable to any terrorist or subversive activity or civil commotion which has taken place within Sri Lanka, a next of kin of such person if he verily believes such person to be dead, ma?', 'Answer': 'kin', 'id': 2, 'context': '(1) Where any person is reported missing and he has not been heard of for a period exceeding one year by those who would naturally have heard of him, had he been alive and his disappearance is attributable to any terrorist or subversive activity or civil commotion which has taken place within Sri Lanka, a next of kin of such person if he verily believes such person to be dead, ma'}, {'Question': 'PART I REGISTRATION OF WHAT PERSONS MISSING DUE TO TERRORIST OR SUBVERSIVE ACTIVITY OR CIVIL COMMOTION 2?', 'Answer': 'deaths', 'id': 3, 'context': 'PART I REGISTRATION OF DEATHS OF PERSONS MISSING DUE TO TERRORIST OR SUBVERSIVE ACTIVITY OR CIVIL COMMOTION 2.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the district registrar of death and births in which missing person was last resident?', 'Answer': 'births', 'id': 1, 'context': '(2) Every application under this section shall be substantially in the Form specified in the Schedule to this Act and shall be forwarded to the Registrar-General or the District Registrar of Births and Deaths of the District in which such missing person was last resident or had his permanen y apply in the manner hereinafter provided, to register the death of such person under the provisions of the Births and Deaths Registration Act and to have issued to him, a Certificate of Death in respect of such person.'}, {'Question': 'What is the name of the document issued to a person who died under the provisions of the Births and Deaths Registration Act and to have issued to him, a Certificate of Death in respect of such person?', 'Answer': 'certificate', 'id': 2, 'context': 'y apply in the manner hereinafter provided, to register the death of such person under the provisions of the Births and Deaths Registration Act and to have issued to him, a Certificate of Death in respect of such person.'}, {'Question': 'What is the form of the application for the Registrar-General or the District Registrar of Births and Deaths of the District in which the missing person was last resident or had his permanen?', 'Answer': 'schedule', 'id': 3, 'context': '(2) Every application under this section shall be substantially in the Form specified in the Schedule to this Act and shall be forwarded to the Registrar-General or the District Registrar of Births and Deaths of the District in which such missing person was last resident or had his permanen'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the basis for the person whose death is sought to be registered, is dead?', 'Answer': 'affidavit', 'id': 1, 'context': 'Every application under this Act shall be supported by an Affidavit of the applicant setting out the grounds for his belief that the person whose death is sought to be registered, is dead, and shall be accompanied by a Report from the Grama Niladhari of the Grama Niladhari Division in which the person whose death is sought to be registered was last resident or had his permanent residence, confirming the fact that such person has not been seen alive or heard of, for a period of over one year,'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'When is a copy of an application under this Act displayed?', 'Answer': 'receipt', 'id': 1, 'context': 'Upon receipt of an application under this Act, the Register General or the District Registrar, as the case may be, shall cause a copy of such application to be displayed for a period of two weeks on the Not'}, {'Question': 'What is the name of the document issued in case of missing person?', 'Answer': 'certificate', 'id': 2, 'context': 'Who may apply for the issue of a certificate of death in case of a person missing due to terrorist activity &c., and procedure.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the last name of the person whose death is sought to be registered?', 'Answer': 'resident', 'id': 1, 'context': 'ice Board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered was last resident or had his permanent residence.'}, {'Question': 'What is displayed on the first day of an application under this Act?', 'Answer': 'copy', 'id': 2, 'context': 'Any person may, within one month of the date on which a copy of an application under this Act is first displayed as provided for in section 4, forward to the Registrar-General or the District Registrar, as the case may be, his objections in writing to the registration of the death of the person to whom such application'}, {'Question': 'Who may, within one month of the date on which a copy of an application under this Act is first displayed as provided for in section 4?', 'Answer': 'application', 'id': 3, 'context': 'Any person may, within one month of the date on which a copy of an application under this Act is first displayed as provided for in section 4, forward to the Registrar-General or the District Registrar, as the case may be, his objections in writing to the registration of the death of the person to whom such application Any person may, within one month of the date on which a copy of an application under this Act is first displayed as provided for in section 4, forward to the Registrar-General or the District Registrar, as the case may be, his objections in writing to the registration of the death of the person to whom such application'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'When is the period of one month allowed for the forwarding of objections to an application?', 'Answer': 'expiry', 'id': 1, 'context': '(1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar, as the case may be, shall consider the application together with the evidence in support of the application and the objections, if any, and the evidence tendered in support of such objections, and'}, {'Question': 'What is the process of submitting objections to an application?', 'Answer': 'forwarding', 'id': 2, 'context': '(1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar, as the case may be, shall consider the application together with the evidence in support of the application and the objections, if any, and the evidence tendered in support of such objections, and'}, {'Question': 'What is supported by an Affidavit of the objector and of any other person, setting out clearly the grounds for their objections?', 'Answer': 'objection', 'id': 3, 'context': 'relates, and such objection shall be supported by an Affidavit of the objector and of any other person, setting out clearly the grounds for their objections.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the procedure for registering a death under the Births and Deaths Registration Act?', 'Answer': 'aforesaid', 'id': 1, 'context': 'Where the application was made to the District Registrar, he shall forward to the Registrar-General a Report under his hand setting out the particulars of the death as is required to be registered, under the Births and Deaths Registration Act, as he has been able to ascertain upon the completion of such inquiry as aforesaid.'}, {'Question': 'What is the name of the death that must be registered under the Births and Deaths Registration Act?', 'Answer': 'births', 'id': 2, 'context': 'Where the application was made to the District Registrar, he shall forward to the Registrar-General a Report under his hand setting out the particulars of the death as is required to be registered, under the Births and Deaths Registration Act, as he has been able to ascertain upon the completion of such inquiry as aforesaid.'}, {'Question': 'On what date is the Report received?', 'Answer': 'receipt', 'id': 3, 'context': '(2) On receipt of the Report under subsection'}, {'Question': 'What is required to be registered under the Births and Deaths Registration Act?', 'Answer': 'particulars', 'id': 4, 'context': 'Where the application was made to the District Registrar, he shall forward to the Registrar-General a Report under his hand setting out the particulars of the death as is required to be registered, under the Births and Deaths Registration Act, as he has been able to ascertain upon the completion of such inquiry as aforesaid.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the register maintained by the Registrar Display of application?', 'Answer': 'deaths', 'id': 1, 'context': '(1), the Registrar-General shall, except in a case where he disallows a Report in the exercise of the powers conferred on him by section 7, make order directing the appropriate Registrar to enter in the Register of Deaths maintained by such Registrar Display of application. 19 of 2010 under the Births and Deaths Registration Act, the particulars specified in such Report and issue in respect of such pe 4 Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What is the reason for registration?', 'Answer': 'objection', 'id': 2, 'context': 'Objection to registration.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the Register of Deaths maintained by the Registrar under the Births and Deaths Registration Act?', 'Answer': 'births', 'id': 1, 'context': '(3) On receipt, by a Registrar, of an order under subsection (2), directing him to enter the particulars in relation to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act and issue in respect of such person a Certificate of Death, the Registrar shall forthwith enter those particulars in such register and sign the Register in the appropriate place and issue the Certificate of Death.'}, {'Question': 'What must a Registrar enter in order to issue a Certificate of Death?', 'Answer': 'particulars', 'id': 2, 'context': '(3) On receipt, by a Registrar, of an order under subsection (2), directing him to enter the particulars in relation to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act and issue in respect of such person a Certificate of Death, the Registrar shall forthwith enter those particulars in such register and sign the Register in the appropriate place and issue the Certificate of Death. (3) On receipt, by a Registrar, of an order under subsection (2), directing him to enter the particulars in relation to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act and issue in respect of such person a Certificate of Death, the Registrar shall forthwith enter those particulars in such register and sign the Register in the appropriate place and issue the Certificate of Death.'}, {'Question': 'What shall the Registrar sign in the appropriate place and issue the Certificate of Death?', 'Answer': 'register', 'id': 3, 'context': '(3) On receipt, by a Registrar, of an order under subsection (2), directing him to enter the particulars in relation to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act and issue in respect of such person a Certificate of Death, the Registrar shall forthwith enter those particulars in such register and sign the Register in the appropriate place and issue the Certificate of Death. (3) On receipt, by a Registrar, of an order under subsection (2), directing him to enter the particulars in relation to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act and issue in respect of such person a Certificate of Death, the Registrar shall forthwith enter those particulars in such register and sign the Register in the appropriate place and issue the Certificate of Death. (3) On receipt, by a Registrar, of an order under subsection (2), directing him to enter the particulars in relation to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act and issue in respect of such person a Certificate of Death, the Registrar shall forthwith enter those particulars in such register and sign the Register in the appropriate place and issue the Certificate of Death.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the duplicate order made under subsection (2)?', 'Answer': 'duplicate', 'id': 1, 'context': 'ate of the relevant registration entry, the written order of the Registrar-General made under subsection (2) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General to be kept in his custody in his office.'}, {'Question': 'What is the purpose of the duplicate order?', 'Answer': 'transmission', 'id': 2, 'context': 'ate of the relevant registration entry, the written order of the Registrar-General made under subsection (2) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General to be kept in his custody in his office.'}, {'Question': 'What is the written order of the Registrar-General made under subsection (2) and such duplicate and order together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General to be kept in his custody in his office?', 'Answer': 'order', 'id': 3, 'context': 'ate of the relevant registration entry, the written order of the Registrar-General made under subsection (2) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General to be kept in his custody in his office. ate of the relevant registration entry, the written order of the Registrar-General made under subsection (2) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General to be kept in his custody in his office.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the reason for the refusal of a Certificate?', 'Answer': 'refusal', 'id': 1, 'context': 'ificate of Death under this Act and who is dissatisfied with the decision of the District Registrar to issue such Certificate, may within one month of the notification of such refusal or issue, as the case may be, appeal to the Registrar-General against such refusal or issue, as the case may be. ificate of Death under this Act and who is dissatisfied with the decision of the District Registrar to issue such Certificate, may within one month of the notification of such refusal or issue, as the case may be, appeal to the Registrar-General against such refusal or issue, as the case may be.'}, {'Question': 'Whose decision is dissatisfied with the District Registrar to issue a Certificate of Death under this Act?', 'Answer': 'decision', 'id': 2, 'context': 'ificate of Death under this Act and who is dissatisfied with the decision of the District Registrar to issue such Certificate, may within one month of the notification of such refusal or issue, as the case may be, appeal to the Registrar-General against such refusal or issue, as the case may be. The Registrar-General may after review of the material before him, either affirm the decision of the District Registrar, or direct the District Registrar to issue a Certificate under section 6, or disallow the repor'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the only thing that can be issued after the refusal of the registration of death?', 'Answer': 'certificate', 'id': 1, 'context': 'Appeal against refusal to issue certificate &C., 5 Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What is the registration of death?', 'Answer': 'deaths', 'id': 2, 'context': 'Appeal against refusal to issue certificate &C., 5 Registration of Deaths (Temporary Provisions) Act, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the person who died under the Births and Deaths Registration Act?', 'Answer': 'births', 'id': 1, 'context': 'eral or to the District Registrar of Births and Deaths of the District in which that person was last residing or had his permanent residence, substantially in the Form set out in the Schedule to this Act, to register the death of that person under the Births and Deaths Registration Act and to have issued to him, a Certificate of Death in respect of the death of that person. eral or to the District Registrar of Births and Deaths of the District in which that person was last residing or had his permanent residence, substantially in the Form set out in the Schedule to this Act, to register the death of that person under the Births and Deaths Registration Act and to have issued to him, a Certificate of Death in respect of the death of that person.'}, {'Question': 'What is the form for the Births and Deaths Registration Act?', 'Answer': 'schedule', 'id': 2, 'context': 'eral or to the District Registrar of Births and Deaths of the District in which that person was last residing or had his permanent residence, substantially in the Form set out in the Schedule to this Act, to register the death of that person under the Births and Deaths Registration Act and to have issued to him, a Certificate of Death in respect of the death of that person.'}, {'Question': 'What must be accompanied by an Affidavit of the applicant in terms of section 3 and a certified copy of the findings?', 'Answer': 'application', 'id': 3, 'context': 'Every such application shall be accompanied by an Affidavit of the applicant in terms of section 3 and a certified copy of the findings'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How do I send a report to the Registrar-General?', 'Answer': 'forthwith', 'id': 1, 'context': '(2) Upon receipt of an application under subsection (1), the District Registrar shall, notwithstanding anything to contrary in the preceding provisions of this Act, forthwith send to the Registrar-General a Report under his hand, setting out the particulars of the death required to be registered under the Births and Deaths Registration Act, as he has been able to ascertain f'}, {'Question': 'What is the first step in registering a death under the Births and Deaths Registration Act?', 'Answer': 'receipt', 'id': 2, 'context': '(2) Upon receipt of an application under subsection (1), the District Registrar shall, notwithstanding anything to contrary in the preceding provisions of this Act, forthwith send to the Registrar-General a Report under his hand, setting out the particulars of the death required to be registered under the Births and Deaths Registration Act, as he has been able to ascertain f'}, {'Question': 'What is subsection (1) of the Births and Deaths Registration Act?', 'Answer': 'subsection', 'id': 3, 'context': '(2) Upon receipt of an application under subsection (1), the District Registrar shall, notwithstanding anything to contrary in the preceding provisions of this Act, forthwith send to the Registrar-General a Report under his hand, setting out the particulars of the death required to be registered under the Births and Deaths Registration Act, as he has been able to ascertain f'}, {'Question': 'What is the commission of inquiry or special presidential commission of inquiry?', 'Answer': 'inquiry', 'id': 4, 'context': 'of the Commission of Inquiry or Special Presidential Commission of Inquiry, as the case may be, relating to the death of such person. of the Commission of Inquiry or Special Presidential Commission of Inquiry, as the case may be, relating to the death of such person.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is responsible for registering a person in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act?', 'Answer': 'registrar', 'id': 1, 'context': '(3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act, the particulars specified in such Report and issue in respect of such person a Certificate of Death. (3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act, the particulars specified in such Report and issue in respect of such person a Certificate of Death. (3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act, the particulars specified in such Report and issue in respect of such person a Certificate of Death.'}, {'Question': 'What is specified in the Report under subsection (3) and issued in respect of such person a Certificate of Death?', 'Answer': 'particulars', 'id': 2, 'context': '(3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act, the particulars specified in such Report and issue in respect of such person a Certificate of Death. (4) Upon receipt of an order under subsection (3) directing him to enter the particulars relating to the r'}, {'Question': 'What is the name of the register maintained by the Births and Deaths Registration Act?', 'Answer': 'deaths', 'id': 3, 'context': '(3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act, the particulars specified in such Report and issue in respect of such person a Certificate of Death. (3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act, the particulars specified in such Report and issue in respect of such person a Certificate of Death.'}, {'Question': 'What is subsection (3) directing the Registrar-General to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act, the particulars specified in such Report and issue in respect of such person a Certificate of Death?', 'Answer': 'subsection', 'id': 4, 'context': '(3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act, the particulars specified in such Report and issue in respect of such person a Certificate of Death. (4) Upon receipt of an order under subsection (3) directing him to enter the particulars relating to the r'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the special procedure relating to registration of deaths of persons in respect of whom there are finding by a Commission of Inquiry or a Special Presidential Commission of Inquiry?', 'Answer': 'inquiry', 'id': 1, 'context': 'elevant death in the Register of Deaths maintained by him under the Special procedure relating to registration of deaths of persons in respect of whom there are finding by a Commission of Inquiry or a Special Presidential Commission of Inquiry. elevant death in the Register of Deaths maintained by him under the Special procedure relating to registration of deaths of persons in respect of whom there are finding by a Commission of Inquiry or a Special Presidential Commission of Inquiry.'}, {'Question': 'What shall the Registrar forthwith enter such particulars in such register and sign the Register in the appropriate place?', 'Answer': 'register', 'id': 2, 'context': 'elevant death in the Register of Deaths maintained by him under the Special procedure relating to registration of deaths of persons in respect of whom there are finding by a Commission of Inquiry or a Special Presidential Commission of Inquiry. 19 of 2010 Births and Deaths Registration Act, the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate place. 19 of 2010 Births and Deaths Registration Act, the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate place.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where is the Registrar-General kept in his office?', 'Answer': 'custody', 'id': 1, 'context': 'of the relevant registration entry, the written order of the Registrar-General made under subsection (3) and such duplicate and order shall be sent together, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General to be kept in his custody in his office.'}, {'Question': \"What is the Registrar-General's order and duplicate?\", 'Answer': 'duplicate', 'id': 2, 'context': 'of the relevant registration entry, the written order of the Registrar-General made under subsection (3) and such duplicate and order shall be sent together, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General to be kept in his custody in his office.'}, {'Question': 'Where the application under subsection (1) is made to the Registrar-General, the provisions of subsection (2) and subsection (5) shall mutatis mutandis apply as if the reference in those sections was made to the District Registrar i?', 'Answer': 'subsection', 'id': 3, 'context': 'of the relevant registration entry, the written order of the Registrar-General made under subsection (3) and such duplicate and order shall be sent together, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General to be kept in his custody in his office. (6) Where the application under subsection (1) is made to the Registrar-General, the provisions of subsections (2) and (5) shall mutatis mutandis apply as if the reference in those section to the District Registrar i'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where there has been a natural disaster or calamity which has caused to either the whole of Sri Lanka or to certain areas thereof, destruction to persons and property which has had far reaching effects at the national level, and where due to the circumstance of the deaths of persons who have died as a result of such disaster or calamity, the application of the Where there has been within Sri Lanka a natural disaster or calamity which has caused to either the whole of Sri Lanka or to certain areas thereof, destruction to persons', 'Answer': 'sri lanka', 'id': 1, 'context': 'Where there has been within Sri Lanka a natural disaster or calamity which has caused to either the whole of Sri Lanka or to certain areas thereof, destruction to persons and property which has had far reaching effects at the national level, and where due to the circumstance of the deaths of persons who have died as a result of such disaster or calamity, the application of the Where there has been within Sri Lanka a natural disaster or calamity which has caused to either the whole of Sri Lanka or to certain areas thereof, destruction to persons and property which has had far reaching effects at the national level, and where due to the circumstance of the deaths of persons who have died as a result of such disaster or calamity, the application of the'}, {'Question': 'What is the term for a natural disaster that has caused to the whole of Sri Lanka or to certain areas thereof?', 'Answer': 'calamity', 'id': 2, 'context': 'Where there has been within Sri Lanka a natural disaster or calamity which has caused to either the whole of Sri Lanka or to certain areas thereof, destruction to persons and property which has had far reaching effects at the national level, and where due to the circumstance of the deaths of persons who have died as a result of such disaster or calamity, the application of the Where there has been within Sri Lanka a natural disaster or calamity which has caused to either the whole of Sri Lanka or to certain areas thereof, destruction to persons and property which has had far reaching effects at the national level, and where due to the circumstance of the deaths of persons who have died as a result of such disaster or calamity, the application of the'}, {'Question': 'What are the natural disasters?', 'Answer': 'disasters', 'id': 3, 'context': 'PART II REGISTRATION OF DEATHS OF PERSONS MISSING DUE TO NATURAL DISASTERS OR CALAMITIES 9.'}, {'Question': 'What is the reason for the deaths of persons who have died as a result of a natural disaster or calamity?', 'Answer': 'circumstance', 'id': 4, 'context': 'Where there has been within Sri Lanka a natural disaster or calamity which has caused to either the whole of Sri Lanka or to certain areas thereof, destruction to persons and property which has had far reaching effects at the national level, and where due to the circumstance of the deaths of persons who have died as a result of such disaster or calamity, the application of the'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If the Births and Deaths Registration Act has become impractical, the Registrar- General may declare any Administrative District, Divisional Secretary\\'s Division or Grama Niladhari Division as the case may be, affected by such disaster or calamity, as a \"National Disaster Area\"', 'Answer': 'calamity', 'id': 1, 'context': 'provisions of the Births and Deaths Registration Act to the registration of the deaths of such persons has become impractical, the Registrar- General may, upon verification of the fact that a natural disaster or calamity has occurred, declare any Administrative District, Divisional Secretary’s Division or Grama Niladhari Division as the case may be, affected by such disaster or calamity, as a \"National Disaster Area\". provisions of the Births and Deaths Registration Act to the registration of the deaths of such persons has become impractical, the Registrar- General may, upon verification of the fact that a natural disaster or calamity has occurred, declare any Administrative District, Divisional Secretary’s Division or Grama Niladhari Division as the case may be, affected by such disaster or calamity, as a \"National Disaster Area\".'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the natural disaster or calamity?', 'Answer': 'calamity', 'id': 1, 'context': '(1) Where any person or persons— (a) who had been resident within an area declared to be a National Disaster Area under section 9 ; or (b) who have been resident within any other area, but was at the time of the occurrence of such natural disaster or calamity, known to have gone to or to have been within any area declared to be a National Disaster Area under section 9, cannot be found subsequent to such natural disaster or calamity and has for all intent and purposes d (1) Where any person or persons— (a) who had been resident within an area declared to be a National Disaster Area under section 9 ; or (b) who have been resident within any other area, but was at the time of the occurrence of such natural disaster or calamity, known to have gone to or to have been within any area declared to be a National Disaster Area under section 9, cannot be found subsequent to such natural disaster or calamity and has for all intent and purposes d'}, {'Question': 'What is the purpose of a natural disaster or calamity?', 'Answer': 'intent', 'id': 2, 'context': '(1) Where any person or persons— (a) who had been resident within an area declared to be a National Disaster Area under section 9 ; or (b) who have been resident within any other area, but was at the time of the occurrence of such natural disaster or calamity, known to have gone to or to have been within any area declared to be a National Disaster Area under section 9, cannot be found subsequent to such natural disaster or calamity and has for all intent and purposes d'}, {'Question': 'What is the time of a natural disaster?', 'Answer': 'occurrence', 'id': 3, 'context': '(1) Where any person or persons— (a) who had been resident within an area declared to be a National Disaster Area under section 9 ; or (b) who have been resident within any other area, but was at the time of the occurrence of such natural disaster or calamity, known to have gone to or to have been within any area declared to be a National Disaster Area under section 9, cannot be found subsequent to such natural disaster or calamity and has for all intent and purposes d'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person or persons has no family members who have survived a natural disaster or calamity, a next of kin of such person or persons may, if he verily believes such person or persons to be dead, apply to register the death of such person or persons, in the manner hereinafter provided, under the Births and Deaths Registration Act and to have issued to him a Certificate of Death or certifi isappeared as a result of such disaster or calamity', 'Answer': 'calamity', 'id': 1, 'context': 'isappeared as a result of such disaster or calamity, a next of kin of such person or persons or where no members of the family of such person or persons have survived the natural disaster or calamity, any person having knowledge of such person or persons may, if he verily believes such person or persons to be dead, apply to register the death of such person or persons, in the manner hereinafter provided, under the Births and Deaths Registration Act and to have issued to him a Certificate of Death or certifi isappeared as a result of such disaster or calamity, a next of kin of such person or persons or where no members of the family of such person or persons have survived the natural disaster or calamity, any person having knowledge of such person or persons may, if he verily believes such person or persons to be dead, apply to register the death of such person or persons, in the manner hereinafter provided, under the Births and Deaths Registration Act and to have issued to him a Certificate of Death or certifi'}, {'Question': 'If a person or persons has survived a natural disaster or calamity, a next of what person or persons may apply to register the death of such person or persons?', 'Answer': 'kin', 'id': 2, 'context': 'isappeared as a result of such disaster or calamity, a next of kin of such person or persons or where no members of the family of such person or persons have survived the natural disaster or calamity, any person having knowledge of such person or persons may, if he verily believes such person or persons to be dead, apply to register the death of such person or persons, in the manner hereinafter provided, under the Births and Deaths Registration Act and to have issued to him a Certificate of Death or certifi'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the person whose death is sought to be registered?', 'Answer': 'description', 'id': 1, 'context': '(3) Every such application shall be submitted in any form whatsoever, containing wherever possible at least some of the information set out in the Schedule hereto, which information would as far as practicable be a description of the person whose death is sought to be registered'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the document issued in case of missing persons?', 'Answer': 'death certificate', 'id': 1, 'context': 'The Grama Niladhari shall as soon as possible upon the receipt of such application, and after such inquiry as he deems necessary, recommend the same and forward it along with a report certifying to the best of his knowledge the accuracy of the facts stated therein, to the Who may apply for the issue of a Death Certificate in case of persons missing as a result of any natural disaster or calamity, and procedure.'}, {'Question': 'What is the reason for the death certificate?', 'Answer': 'calamity', 'id': 2, 'context': 'The Grama Niladhari shall as soon as possible upon the receipt of such application, and after such inquiry as he deems necessary, recommend the same and forward it along with a report certifying to the best of his knowledge the accuracy of the facts stated therein, to the Who may apply for the issue of a Death Certificate in case of persons missing as a result of any natural disaster or calamity, and procedure.'}, {'Question': 'What is the reason for the death certificate?', 'Answer': 'disaster', 'id': 3, 'context': 'The Grama Niladhari shall as soon as possible upon the receipt of such application, and after such inquiry as he deems necessary, recommend the same and forward it along with a report certifying to the best of his knowledge the accuracy of the facts stated therein, to the Who may apply for the issue of a Death Certificate in case of persons missing as a result of any natural disaster or calamity, and procedure.'}, {'Question': 'What does the Grama Niladhari certify in the report of the death certificate?', 'Answer': 'accuracy', 'id': 4, 'context': 'The Grama Niladhari shall as soon as possible upon the receipt of such application, and after such inquiry as he deems necessary, recommend the same and forward it along with a report certifying to the best of his knowledge the accuracy of the facts stated therein, to the Who may apply for the issue of a Death Certificate in case of persons missing as a result of any natural disaster or calamity, and procedure.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the death (temporary provisions) act, No.?', 'Answer': 'ation', 'id': 1, 'context': 'ation of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What is the Register of Deaths maintained by the Re ation of Deaths (Temporary Provisions) Act, No.?', 'Answer': 'deaths', 'id': 2, 'context': '(4) Upon receipt of an application under subsection (2), duly recommended and endorsed in terms of the provisions of subsection (3), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Re ation of Deaths (Temporary Provisions) Act, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the Register of Deaths maintained by the Registrar under the Births and Deaths Registration Act?', 'Answer': 'births', 'id': 1, 'context': '(5) Upon receipt of an order under subsection (4) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act, the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate gistrar under the Births and Deaths Registration Act, the particulars specified in such application and issue in respect of the person to whom the application relates, a Certificate of Death.'}, {'Question': 'What shall the Registrar forthwith enter in the Register of Deaths maintained by him under the Births and Deaths Registration Act, the particulars specified in such application and issue in respect of the person to whom the application relates, a Certificate of Death?', 'Answer': 'particulars', 'id': 2, 'context': '(5) Upon receipt of an order under subsection (4) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act, the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate (5) Upon receipt of an order under subsection (4) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act, the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate gistrar under the Births and Deaths Registration Act, the particulars specified in such application and issue in respect of the person to whom the application relates, a Certificate of Death.'}, {'Question': 'What shall the Registrar sign upon receipt of an order under subsection (4) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act?', 'Answer': 'register', 'id': 3, 'context': '(5) Upon receipt of an order under subsection (4) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act, the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate (5) Upon receipt of an order under subsection (4) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act, the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate (5) Upon receipt of an order under subsection (4) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act, the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is responsible for sending the duplicate of the registration entry to the Registrar-General for custody in his office?', 'Answer': 'registrar', 'id': 1, 'context': '(6) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (4) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office. (6) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (4) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office. (6) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (4) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office.'}, {'Question': \"What is the Registrar-General's office to receive the duplicate of the registration entry?\", 'Answer': 'custody', 'id': 2, 'context': '(6) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (4) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office.'}, {'Question': 'What is attached to the registration entry, the written order of the Registrar-General made under subsection (4) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office?', 'Answer': 'duplicate', 'id': 3, 'context': '(6) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (4) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office. (6) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (4) and such duplicate and order shall together be sent, by the Registrar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the reason for the death of a foreign national in Sri Lanka?', 'Answer': 'calamity', 'id': 1, 'context': 'Where there is evidence to show that a national of another State had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply Registration of Deaths of foreign nationals.'}, {'Question': 'What is the process of registering foreign nationals in Sri Lanka?', 'Answer': 'registration', 'id': 2, 'context': 'Where there is evidence to show that a national of another State had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply Registration of Deaths of foreign nationals.'}, {'Question': 'What is the reason for a national of another state to die in Sri Lanka?', 'Answer': 'disaster', 'id': 3, 'context': 'Where there is evidence to show that a national of another State had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply Registration of Deaths of foreign nationals. Where there is evidence to show that a national of another State had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply Registration of Deaths of foreign nationals.'}, {'Question': 'What is required to register a foreign national in Sri Lanka?', 'Answer': 'knowledge', 'id': 4, 'context': 'Where there is evidence to show that a national of another State had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply Registration of Deaths of foreign nationals.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is issued in respect of a deceased person?', 'Answer': 'certificate', 'id': 1, 'context': 'Every such application shall be authenticated by the representative of the country of which such person was a citizen, present in Sri Lanka, and such application shall be forwarded directly to the Registrar-General who shall forthwith proceed to register such death and issue in respect of such person a Certificate of Death. 19 of 2010 for the issue to him of a Certificate of Death in respect of such person.'}, {'Question': 'What is the term for the death of a person?', 'Answer': 'deaths', 'id': 2, 'context': 'Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What is the nationality of the person who is authenticated by the representative of the country of which such person was a citizen, present in Sri Lanka?', 'Answer': 'citizen', 'id': 3, 'context': 'Every such application shall be authenticated by the representative of the country of which such person was a citizen, present in Sri Lanka, and such application shall be forwarded directly to the Registrar-General who shall forthwith proceed to register such death and issue in respect of such person a Certificate of Death.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the natural disaster or what is the cause of death?', 'Answer': 'calamity', 'id': 1, 'context': '10 of 1988, be applicable to the issue of a Certificate of Death in respect of a person whose death is attributable to any terrorist or subversive activity or civil commotion or to any natural disaster or calamity where the death in question had occurred within an area declared to be a National Disaster Area in terms of section 9.'}, {'Question': 'What is the certificate of death?', 'Answer': 'certificate', 'id': 2, 'context': '10 of 1988, be applicable to the issue of a Certificate of Death in respect of a person whose death is attributable to any terrorist or subversive activity or civil commotion or to any natural disaster or calamity where the death in question had occurred within an area declared to be a National Disaster Area in terms of section 9.'}, {'Question': 'What is the evidence (Amendment) Act, No. 108?', 'Answer': 'amendment', 'id': 3, 'context': 'art of this Act, shall notwithstanding the provisions of section 108 of the Evidence Ordinance as amended by the Evidence (Amendment) Act, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How do I know if a person whose death has been registered is alive?', 'Answer': 'forthwith', 'id': 1, 'context': 'tered pursuant to an application made under sections 2,8,10 or 11 of this Act, and where any person at any time thereafter becomes aware that the person whose death has been so registered is alive, such person shall forthwith furnish such information to the Registrar-General.'}, {'Question': 'Who shall investigate the truth of the information and forward a report to the Registrar-General?', 'Answer': 'police station', 'id': 2, 'context': '(2) The Registrar-General shall, on receipt of such information convey the information to the Officer-in-Charge of the relevant police station, who shall investigate the truth of such information and forward a report to the Registrar-'}, {'Question': 'When does the Registrar-General convey information to the Officer-in-Charge of the relevant police station?', 'Answer': 'receipt', 'id': 3, 'context': '(2) The Registrar-General shall, on receipt of such information convey the information to the Officer-in-Charge of the relevant police station, who shall investigate the truth of such information and forward a report to the Registrar-'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the first step in registering a person as dead?', 'Answer': 'receipt', 'id': 1, 'context': '(3) Upon receipt of a report under subsection (2) and after such inquiry as he may deem necessary the Registrar-General, if satisfied that the person whose death has been registered is alive, shall take such action, or make such order or give Procedure if person registered as dead is found to be alive.'}, {'Question': 'What is subsection (2) of the Act?', 'Answer': 'subsection', 'id': 2, 'context': '(3) Upon receipt of a report under subsection (2) and after such inquiry as he may deem necessary the Registrar-General, if satisfied that the person whose death has been registered is alive, shall take such action, or make such order or give Procedure if person registered as dead is found to be alive.'}, {'Question': 'What is the provisions of the Evidence Ordinance not to apply?', 'Answer': 'provisions', 'id': 3, 'context': '10 Registration of Deaths (Temporary Provisions) Act, No. Provisions of the Evidence Ordinance not to apply.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the purpose of the Births and Deaths Registration Act?', 'Answer': 'births', 'id': 1, 'context': '(4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purpose of an inquiry under this Act, exercise all the powers exercisable by him under the Births and Deaths Registration Act, in relation to an inquiry held by him under that Act. of 2010 such direction, under section 52 of the Births and Deaths Registration Act, as is appropriate in the circumstances of the case.'}, {'Question': 'What is the best way to avoid doubt?', 'Answer': 'avoidance', 'id': 2, 'context': 'For the avoidance of doubt it is he'}, {'Question': 'What is the purpose of the Births and Deaths Registration Act?', 'Answer': 'inquiry', 'id': 3, 'context': '(4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purpose of an inquiry under this Act, exercise all the powers exercisable by him under the Births and Deaths Registration Act, in relation to an inquiry held by him under that Act. (4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purpose of an inquiry under this Act, exercise all the powers exercisable by him under the Births and Deaths Registration Act, in relation to an inquiry held by him under that Act. (4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purpose of an inquiry under this Act, exercise all the powers exercisable by him under the Births and Deaths Registration Act, in relation to an inquiry held by him under that Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If the operation of this Act has lapsed upon the period specified in subsection (1) of section 1, and no Order for the extension of the period of operation of this Act is made in terms of subsection (2) of section 1; and (b) if a person has been reported as dead and the application for the issue of a Certificate of Death in relation to such person has been made in terms of the provisions of sections 2, 8, 10 and 11 of this Act prior to the period of operat, and no Order for the extension of the period', 'Answer': 'expiry', 'id': 1, 'context': 'reby declared that— (a) if the operation of this Act has lapsed upon the expiry of the period specified in subsection (1) of section 1, and no Order for the extension of the period of operation of this Act is made in terms of subsection (2) of section 1; and (b) if a person has been reported as dead and the application for the issue of a Certificate of Death in relation to such person has been made in terms of the provisions of sections 2, 8, 10 and 11 of this Act prior to the expiry of the period of operat reby declared that— (a) if the operation of this Act has lapsed upon the expiry of the period specified in subsection (1) of section 1, and no Order for the extension of the period of operation of this Act is made in terms of subsection (2) of section 1; and (b) if a person has been reported as dead and the application for the issue of a Certificate of Death in relation to such person has been made in terms of the provisions of sections 2, 8, 10 and 11 of this Act prior to the expiry of the period of operat'}, {'Question': 'If a person has been reported as dead and the application for the issue of what is in relation to such person has been made in terms of the provisions of sections 2, 8, 10 and 11 of this Act prior to the expiry of the period of operat?', 'Answer': 'certificate', 'id': 2, 'context': 'reby declared that— (a) if the operation of this Act has lapsed upon the expiry of the period specified in subsection (1) of section 1, and no Order for the extension of the period of operation of this Act is made in terms of subsection (2) of section 1; and (b) if a person has been reported as dead and the application for the issue of a Certificate of Death in relation to such person has been made in terms of the provisions of sections 2, 8, 10 and 11 of this Act prior to the expiry of the period of operat'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': \"If a person's death has been registered in what manner under this Act, is alive, fails to do what?\", 'Answer': 'pursuance', 'id': 1, 'context': 'Any person who— (a) knowingly, makes a false statement in an application made by him under this Act, or furnishes false information under this Act; or (b) being aware that a person whose death has been registered in pursuance of an application made under this Act, is alive, fails to'}, {'Question': 'What is issued in respect of a deceased person under this Act?', 'Answer': 'certificate', 'id': 2, 'context': 'ion of this Act, the Registrar-General may proceed to register the death of such person and issue the Certificate of Death in respect of such person, in terms of the provisions of Part I and Part II respectively of this Act.'}, {'Question': 'What are the provisions of Part I and Part II of this Act?', 'Answer': 'provisions', 'id': 3, 'context': 'ion of this Act, the Registrar-General may proceed to register the death of such person and issue the Certificate of Death in respect of such person, in terms of the provisions of Part I and Part II respectively of this Act.'}, {'Question': 'If a person whose death has been registered in pursuance of an application made under this Act, is alive, fails to do so?', 'Answer': 'application', 'id': 4, 'context': 'Any person who— (a) knowingly, makes a false statement in an application made by him under this Act, or furnishes false information under this Act; or (b) being aware that a person whose death has been registered in pursuance of an application made under this Act, is alive, fails to Any person who— (a) knowingly, makes a false statement in an application made by him under this Act, or furnishes false information under this Act; or (b) being aware that a person whose death has been registered in pursuance of an application made under this Act, is alive, fails to'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the term of imprisonment for a person who uses a Certificate of Death issued under the Births and Deaths Registration Act knowing or having reason to believe that the person referred to in the certificate is alive?', 'Answer': 'imprisonment', 'id': 1, 'context': '19 of 2010 (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act knowing or having reason to believe that the person referred to in such certificate is alive, shall be guilty of an offence under this Act, and shall upon conviction after trial by the High Court be sentenced to a term of imprisonment of not exce'}, {'Question': 'What is a Certificate of Death?', 'Answer': 'certificate', 'id': 2, 'context': '19 of 2010 (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act knowing or having reason to believe that the person referred to in such certificate is alive, shall be guilty of an offence under this Act, and shall upon conviction after trial by the High Court be sentenced to a term of imprisonment of not exce 19 of 2010 (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act knowing or having reason to believe that the person referred to in such certificate is alive, shall be guilty of an offence under this Act, and shall upon conviction after trial by the High Court be sentenced to a term of imprisonment of not exce'}, {'Question': 'What is the purpose of a Certificate of Death?', 'Answer': 'deaths', 'id': 3, 'context': '19 of 2010 (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act knowing or having reason to believe that the person referred to in such certificate is alive, shall be guilty of an offence under this Act, and shall upon conviction after trial by the High Court be sentenced to a term of imprisonment of not exce 11 Registration of Deaths (Temporary Provisions) Act, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the reason for the difference between the Tamil and Sinhala versions of the Act?', 'Answer': 'inconsistency', 'id': 1, 'context': 'In the event of any inconsistency between the Sinhala and Tamil texts of this Act, the Sinhala text shall prevail.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the reason for the Sinhala text to prevail?', 'Answer': 'inconsistency', 'id': 1, 'context': 'Sinhala text to prevail in case of inconsistency.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is missing person?', 'Answer': 'applicant', 'id': 1, 'context': 'Applicant’s relationship to missing person : I......................................................... of ...................................................................... do hereby state that the said........................................................... Applicant’s full name and residence : 9.'}, {'Question': 'What is the rank of a profession?', 'Answer': 'rank', 'id': 2, 'context': 'Rank or profession : 8.'}, {'Question': 'What is the last known residence?', 'Answer': 'residence', 'id': 3, 'context': 'Applicant’s full name and residence : 9. Address of last known residence: 6. Address of permanent residence : 7.'}, {'Question': 'What is the rank of a profession?', 'Answer': 'profession', 'id': 4, 'context': 'Rank or profession : 8.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the act that registers death?', 'Answer': 'births', 'id': 1, 'context': 'I therefore request that the death be registered under the Births and Deaths Registration Act (Chapter 110) and a Certificate of Death in respect of such death be issued to me.'}, {'Question': 'What is the signature of the applicant?', 'Answer': 'signature', 'id': 2, 'context': '........................................ Signature of Applicant Date'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZERO\n",
            "Unexpected structure in the 'outputs' dictionary. Check the structure and update the code.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How do I register my death?', 'Answer': 'therewith', 'id': 1, 'context': 'Registration Of Deaths (Temporary provisions) Act No 58 of 1998 AN ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING ; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERETO Preamble.'}, {'Question': 'What are the civil disturbances that took place due to terrorist and subversive activities in Sri Lanka?', 'Answer': 'deaths', 'id': 2, 'context': 'WHEREAS several persons have died in the course of the civil disturbances that took place due to terrorist and subversive activities in Sri Lanka; and whereas there are certain practical difficulties impeding the registration of such deaths under the provisions of the Births and Deaths Registration A WHEREAS several persons have died in the course of the civil disturbances that took place due to terrorist and subversive activities in Sri Lanka; and whereas there are certain practical difficulties impeding the registration of such deaths under the provisions of the Births and Deaths Registration A Registration Of Deaths (Temporary provisions) Act No 58 of 1998 AN ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING ; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERETO Preamble.'}, {'Question': 'What is the main problem with the registration of deaths under the provisions of the Births and Deaths Registration Act?', 'Answer': 'registration', 'id': 3, 'context': 'WHEREAS several persons have died in the course of the civil disturbances that took place due to terrorist and subversive activities in Sri Lanka; and whereas there are certain practical difficulties impeding the registration of such deaths under the provisions of the Births and Deaths Registration A WHEREAS several persons have died in the course of the civil disturbances that took place due to terrorist and subversive activities in Sri Lanka; and whereas there are certain practical difficulties impeding the registration of such deaths under the provisions of the Births and Deaths Registration A Registration Of Deaths (Temporary provisions) Act No 58 of 1998 AN ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING ; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERETO Preamble.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the registration of?', 'Answer': 'deaths', 'id': 1, 'context': 'ct (Chapter 110) AND WHEREAS it has now become necessary to make provision enabling the registration of such deaths: NOW THEREFORE be it enacted by the Parliament of the Democratic Socialist Republic of Sri Lanka as follows :- short title and duration of the Act. This Act may be cited as the Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What is the provision enabling the registration of such deaths?', 'Answer': 'registration', 'id': 2, 'context': 'ct (Chapter 110) AND WHEREAS it has now become necessary to make provision enabling the registration of such deaths: NOW THEREFORE be it enacted by the Parliament of the Democratic Socialist Republic of Sri Lanka as follows :- short title and duration of the Act. This Act may be cited as the Registration of Deaths (Temporary Provisions) Act, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the act that registers the death of a person?', 'Answer': 'births', 'id': 1, 'context': 'Where any person is reported missing and presumed to be dead as he has not been heard of for a period exceeding one year by those who would naturally have heard of him had he been alive, a next of kin of such person if he verily believes such person to be dead, may, apply in the manner hereinafter provided, to register the death of such person under the Births and Deaths Registration Act (Chapter 110) and to have issued to him, a Certificate of Death in respect of such person.'}, {'Question': 'What is the Births and Deaths Registration Act?', 'Answer': 'chapter', 'id': 2, 'context': 'Where any person is reported missing and presumed to be dead as he has not been heard of for a period exceeding one year by those who would naturally have heard of him had he been alive, a next of kin of such person if he verily believes such person to be dead, may, apply in the manner hereinafter provided, to register the death of such person under the Births and Deaths Registration Act (Chapter 110) and to have issued to him, a Certificate of Death in respect of such person.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the district registrar of death and births?', 'Answer': 'births', 'id': 1, 'context': 'Every application under this Act to register the death of a person shall be made either to the Registrar-General or to the District Registrar of Births and Deaths of the district in which such person was last residing, and shall be in the form set out in the Schedule to this Act.'}, {'Question': 'What is the form of the death register in this Act?', 'Answer': 'schedule', 'id': 2, 'context': 'Every application under this Act to register the death of a person shall be made either to the Registrar-General or to the District Registrar of Births and Deaths of the district in which such person was last residing, and shall be in the form set out in the Schedule to this Act.'}, {'Question': 'What is the basis for the person whose death is sought to be registered, is dead?', 'Answer': 'grounds', 'id': 3, 'context': 'Every application under this Act shall be supported by an affidavit of the applicant setting out the grounds for his belief that the person whose death is sought to be registered, is dead, a'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'When does the Registrar-General or the District Registrar cause a copy of an application under this Act?', 'Answer': 'receipt', 'id': 1, 'context': 'Upon receipt of an application under this Act, the Registrar-General or the District Registrar as the case may be shall cause a copy of such application'}, {'Question': 'What is the purpose of an application?', 'Answer': 'display', 'id': 2, 'context': 'Display of application.'}, {'Question': 'What shall the Registrar-General or the District Registrar cause a copy of?', 'Answer': 'application', 'id': 3, 'context': 'nd shall be accompanied by, a report from the Grama Niladhari of the Grama Niladhari Division in which the person whose death is sought to be registered, was last resident, confirming the fact that such person has not been seen alive or heard of, for a period of over one year, and any other evidence in support of such application. Upon receipt of an application under this Act, the Registrar-General or the District Registrar as the case may be shall cause a copy of such application Upon receipt of an application under this Act, the Registrar-General or the District Registrar as the case may be shall cause a copy of such application'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the last name of the person whose death is sought to be registered, was last resident or had his permanent residence?', 'Answer': 'resident', 'id': 1, 'context': 'to be displayed for a period of two weeks on the Notice Board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered, was last resident or had his permanent residence.'}, {'Question': 'What can a person forward within one month of the date on which a copy of an application under this Act is first displayed?', 'Answer': 'objections', 'id': 2, 'context': 'Any person may within one month of the date on which a copy of an application under this Act is first displayed as provided for in section 5, forward to the Registrar-General or the District Registrar, as the case may be, his objections in Objections to registration.'}, {'Question': 'In what division is the person whose death is sought to be registered, was last resident or had his permanent residence?', 'Answer': 'division', 'id': 3, 'context': 'to be displayed for a period of two weeks on the Notice Board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered, was last resident or had his permanent residence.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the process of submitting objections to an application?', 'Answer': 'forwarding', 'id': 1, 'context': '(1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar as the case may be shall consider the application together with the evidence in support of the appli'}, {'Question': 'What shall be supported by an affidavit of she objector and of any other person, setting out the grounds for their objections?', 'Answer': 'objections', 'id': 2, 'context': '(1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar as the case may be shall consider the application together with the evidence in support of the appli writing, to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of she objector and of any other person, setting out the grounds for their objections. writing, to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of she objector and of any other person, setting out the grounds for their objections.'}, {'Question': 'What is the process of death?', 'Answer': 'registration', 'id': 3, 'context': 'writing, to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of she objector and of any other person, setting out the grounds for their objections. Registration of death.'}, {'Question': 'How long is the period for forwarding objections to an application?', 'Answer': 'month', 'id': 4, 'context': '(1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar as the case may be shall consider the application together with the evidence in support of the appli'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is required to be registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'particulars', 'id': 1, 'context': 'cation and the objections, if any, and the evidence in support of such objections, and after such inquiry as he may deem necessary, if satisfied as to the truth of the matters stated in the application, allow such application and shall send to the Registrar-General a Certificate under his hand setting out such of the particulars of the death as are required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid.'}, {'Question': 'What is the evidence in support of the objections?', 'Answer': 'objections', 'id': 2, 'context': 'cation and the objections, if any, and the evidence in support of such objections, and after such inquiry as he may deem necessary, if satisfied as to the truth of the matters stated in the application, allow such application and shall send to the Registrar-General a Certificate under his hand setting out such of the particulars of the death as are required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid. cation and the objections, if any, and the evidence in support of such objections, and after such inquiry as he may deem necessary, if satisfied as to the truth of the matters stated in the application, allow such application and shall send to the Registrar-General a Certificate under his hand setting out such of the particulars of the death as are required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is specified in the Birth and Deaths Registration Act (Chapter i 10)?', 'Answer': 'particulars', 'id': 1, 'context': 'ceipt of she certificate under subsection (1), the Registrar- General shall, except in a case where he cancels a certificate in the exercise of powers conferred on him by section 8, make order directing the appropriate Registrar to enter in the Register of Deaths maintained by such Registrar under the Birth and Deaths Registration Act (Chapter i 10), the particulars specified in such certificate. (3) On receipt by a Registrar (2) directing him to enter the particulars the Register of Deaths maintained and D'}, {'Question': 'What is the Register of Deaths maintained by such Registrar under the Birth and Deaths Registration Act (Chapter i 10)?', 'Answer': 'deaths', 'id': 2, 'context': 'ceipt of she certificate under subsection (1), the Registrar- General shall, except in a case where he cancels a certificate in the exercise of powers conferred on him by section 8, make order directing the appropriate Registrar to enter in the Register of Deaths maintained by such Registrar under the Birth and Deaths Registration Act (Chapter i 10), the particulars specified in such certificate. ceipt of she certificate under subsection (1), the Registrar- General shall, except in a case where he cancels a certificate in the exercise of powers conferred on him by section 8, make order directing the appropriate Registrar to enter in the Register of Deaths maintained by such Registrar under the Birth and Deaths Registration Act (Chapter i 10), the particulars specified in such certificate. (3) On receipt by a Registrar (2) directing him to enter the particulars the Register of Deaths maintained and D'}, {'Question': 'What is the name of the register of death maintained by the Registrar under the Birth and Deaths Registration Act (Chapter i 10)?', 'Answer': 'register', 'id': 3, 'context': 'ceipt of she certificate under subsection (1), the Registrar- General shall, except in a case where he cancels a certificate in the exercise of powers conferred on him by section 8, make order directing the appropriate Registrar to enter in the Register of Deaths maintained by such Registrar under the Birth and Deaths Registration Act (Chapter i 10), the particulars specified in such certificate. (3) On receipt by a Registrar (2) directing him to enter the particulars the Register of Deaths maintained and D'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the proper District Registrar Registrar-General for?', 'Answer': 'custody', 'id': 1, 'context': '(4) Every written order under attached to the duplicate of the relevant shall be sent together with that the appropriate District Registrar Registrar-General for custody in his office.'}, {'Question': 'What should be entered in the register in the appropriate place?', 'Answer': 'particulars', 'id': 2, 'context': 'eaths Registration Act forthwith enter those particulars in such register in the appropriate place.'}, {'Question': 'Who is dissatisfied the District Registrar refusing to issue a certificate under section 7?', 'Answer': 'applicant', 'id': 3, 'context': 'An applicant who is dissatisfied the District Registrar refusing to issue under section 7, or a person who has to the issue of a certificate under dissatis'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What may the Registrar-General cancel under section 7?', 'Answer': 'certificate', 'id': 1, 'context': 'The Registrar-General may material before him, affirm the decision Registrar or direct the District Registrar under section 7 or cancel a certificate Registrar under section 7, as the case may be. fied with the decision of the such certificate, may within one month such refusal or issue, as the case may be Registrar-General against such refusal or may be.'}, {'Question': 'Special procedure relating to registration of what of persons in respect of whom there are findings by a Commission of Inquiry or a Special Presidential?', 'Answer': 'deaths', 'id': 2, 'context': 'Special procedure relating to registration of deaths of persons in respect of whom there are findings by a Commission of Inquiry or a Special Presidential'}, {'Question': 'What may be a refusal or issue?', 'Answer': 'refusal', 'id': 3, 'context': 'fied with the decision of the such certificate, may within one month such refusal or issue, as the case may be Registrar-General against such refusal or may be. fied with the decision of the such certificate, may within one month such refusal or issue, as the case may be Registrar-General against such refusal or may be.'}, {'Question': 'Special procedure relating to registration of deaths of what in respect of whom there are findings by a Commission of Inquiry or a Special Presidential?', 'Answer': 'persons', 'id': 4, 'context': 'Special procedure relating to registration of deaths of persons in respect of whom there are findings by a Commission of Inquiry or a Special Presidential'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZERO\n",
            "Unexpected structure in the 'outputs' dictionary. Check the structure and update the code.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the document issued to the person who died under the Births and Deaths Registration Act (Chapter (chapter 110)and to have issued to him, a Certificate of Death in respect of that person?', 'Answer': 'certificate', 'id': 1, 'context': 'the death of that Person under the Births and Deaths Registration Act (Chapter (chapter 110)and to have issued to him, a Certificate of Death in respect of that person.'}, {'Question': 'What is the commission of inquiry or special presidential commission of inquiry?', 'Answer': 'inquiry', 'id': 2, 'context': 'Every such application shall be accompanied by an affidavit of the applicant in terms of section 4 and a certified copy of the finding of the Commission of Inquiry or Special Presidential Commission of Inquiry, as the case may be, relating to that person. Every such application shall be accompanied by an affidavit of the applicant in terms of section 4 and a certified copy of the finding of the Commission of Inquiry or Special Presidential Commission of Inquiry, as the case may be, relating to that person.'}, {'Question': 'What is the commission of inquiry?', 'Answer': 'commission', 'id': 3, 'context': 'Every such application shall be accompanied by an affidavit of the applicant in terms of section 4 and a certified copy of the finding of the Commission of Inquiry or Special Presidential Commission of Inquiry, as the case may be, relating to that person. Every such application shall be accompanied by an affidavit of the applicant in terms of section 4 and a certified copy of the finding of the Commission of Inquiry or Special Presidential Commission of Inquiry, as the case may be, relating to that person.'}, {'Question': 'What is the Births and Deaths Registration Act?', 'Answer': 'chapter', 'id': 4, 'context': 'the death of that Person under the Births and Deaths Registration Act (Chapter (chapter 110)and to have issued to him, a Certificate of Death in respect of that person. the death of that Person under the Births and Deaths Registration Act (Chapter (chapter 110)and to have issued to him, a Certificate of Death in respect of that person.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How do I send the certificate under his hand, setting out the particulars of the death required to be registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'forthwith', 'id': 1, 'context': 'notwithstanding anything to contrary in the preceding provisions of this Act, forthwith send to the Registrar-General a certificate under his hand, setting out the particulars of the death required to be registered under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain from the application and the accompanying affidavit and finding.'}, {'Question': 'What is the accompanying document to the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'affidavit', 'id': 2, 'context': 'notwithstanding anything to contrary in the preceding provisions of this Act, forthwith send to the Registrar-General a certificate under his hand, setting out the particulars of the death required to be registered under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain from the application and the accompanying affidavit and finding.'}, {'Question': \"What is subsection (2) of the Registrar-General's Order to regist?\", 'Answer': 'subsection', 'id': 3, 'context': '(3) Upon receipt of a certificate under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to regist'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the Register of Deaths maintained by the Registrar under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'births', 'id': 1, 'context': '(4) Upon receipt of an order under subsection (3) directing him to enter the particulars relating to a death in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110), the Registrar shall forthwith enter such particulars in such register and sign the register in the appropriate place. er in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such certificate.'}, {'Question': 'When does the Registrar of Deaths register the death details in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'receipt', 'id': 2, 'context': '(4) Upon receipt of an order under subsection (3) directing him to enter the particulars relating to a death in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110), the Registrar shall forthwith enter such particulars in such register and sign the register in the appropriate place.'}, {'Question': 'What must the Registrar enter in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'particulars', 'id': 3, 'context': '(4) Upon receipt of an order under subsection (3) directing him to enter the particulars relating to a death in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110), the Registrar shall forthwith enter such particulars in such register and sign the register in the appropriate place. (4) Upon receipt of an order under subsection (3) directing him to enter the particulars relating to a death in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110), the Registrar shall forthwith enter such particulars in such register and sign the register in the appropriate place. er in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such certificate.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the purpose of the mad?', 'Answer': 'custody', 'id': 1, 'context': 'mad^ under subsection (3) shall be attached to the duplicate of the relevant registration entry and shall be sent together with the duplicate, by the Registrar, to the appropriate District Registrar for transmission to the Registrar-General for custody in his office.'}, {'Question': 'What is the name of the registration entry that the Registrar attaches to the mad under subsection (3)?', 'Answer': 'duplicate', 'id': 2, 'context': 'mad^ under subsection (3) shall be attached to the duplicate of the relevant registration entry and shall be sent together with the duplicate, by the Registrar, to the appropriate District Registrar for transmission to the Registrar-General for custody in his office. mad^ under subsection (3) shall be attached to the duplicate of the relevant registration entry and shall be sent together with the duplicate, by the Registrar, to the appropriate District Registrar for transmission to the Registrar-General for custody in his office.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How do I notify the Registrar-General that the person whose death has been registered is alive?', 'Answer': 'forthwith', 'id': 1, 'context': '(1) Where any death has been registered in pursuance of an application made under this Act and where any person at any time thereafter becomes aware that the person whose death has been so registered is alive, such person shall forthwith furnish such information to the Registrar-General.'}, {'Question': 'When does the Registrar-General convey information to the Officer-in-Charge of the relevant police station?', 'Answer': 'receipt', 'id': 2, 'context': '(2) The Registrar-General shall, on receipt of such information convey the information to the Officer-in-Charge of the relevant police station, w'}, {'Question': 'What is the basis of a death registered under this Act?', 'Answer': 'application', 'id': 3, 'context': '(1) Where any death has been registered in pursuance of an application made under this Act and where any person at any time thereafter becomes aware that the person whose death has been so registered is alive, such person shall forthwith furnish such information to the Registrar-General.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': \"What is the first step in registering a person's death?\", 'Answer': 'receipt', 'id': 1, 'context': '(3) Upon receipt of a report under subsection (2) and after such inquiry as he may deem necessary the Registrar-General, if satisfied that the person whose death has been registered is alive, shall take such action, or make such order or give such direction, under section 52 of the Births and Deaths Registration Act (Chapter 110)'}, {'Question': 'What is the name of the person whose death has been registered as alive?', 'Answer': 'births', 'id': 2, 'context': '(3) Upon receipt of a report under subsection (2) and after such inquiry as he may deem necessary the Registrar-General, if satisfied that the person whose death has been registered is alive, shall take such action, or make such order or give such direction, under section 52 of the Births and Deaths Registration Act (Chapter 110)'}, {'Question': 'What is subsection (2) of the Births and Deaths Registration Act?', 'Answer': 'subsection', 'id': 3, 'context': '(3) Upon receipt of a report under subsection (2) and after such inquiry as he may deem necessary the Registrar-General, if satisfied that the person whose death has been registered is alive, shall take such action, or make such order or give such direction, under section 52 of the Births and Deaths Registration Act (Chapter 110)'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the date of the inquiry held by the Registrar-General under this Act?', 'Answer': 'commencement', 'id': 1, 'context': '(4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purposes of an inquiry under this Act, exercise all the powers exercisable by him under the Births and Deaths Registration Act (Chapter 110), in relation to an inquiry held by him under that Act.'}, {'Question': 'What is the name of the births and deaths registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'births', 'id': 2, 'context': '(4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purposes of an inquiry under this Act, exercise all the powers exercisable by him under the Births and Deaths Registration Act (Chapter 110), in relation to an inquiry held by him under that Act.'}, {'Question': 'What is the purpose of the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'inquiry', 'id': 3, 'context': '(4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purposes of an inquiry under this Act, exercise all the powers exercisable by him under the Births and Deaths Registration Act (Chapter 110), in relation to an inquiry held by him under that Act. (4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purposes of an inquiry under this Act, exercise all the powers exercisable by him under the Births and Deaths Registration Act (Chapter 110), in relation to an inquiry held by him under that Act. (4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purposes of an inquiry under this Act, exercise all the powers exercisable by him under the Births and Deaths Registration Act (Chapter 110), in relation to an inquiry held by him under that Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': \"How is a person's death registered under this Act, alive, fails to furnish such information to the Registrar-General?\", 'Answer': 'pursuance', 'id': 1, 'context': 's Act, or furnishes false information under this Act; or (b) being aware that a person whose death has been registered in pursuance of an application made under this Act, is alive, fails to furnish such information to the Registrar-General; or (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act knowing, or having reason to believe that the person referred to in such certificate is alive, shall be guilty of an offence under this Act, and shall upon'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the reason for the Sinhala text to prevail in the case of inconsistency between the Tamil and Sinhala texts?', 'Answer': 'inconsistency', 'id': 1, 'context': 'In the event of any inconsistency between the Sinhala and Tamil texts of this Act, the sinhala text shall prevail. Sinhala text to prevail in case of inconsistency.'}, {'Question': 'What is the maximum term of imprisonment after a conviction by the High Court?', 'Answer': 'net', 'id': 2, 'context': 'conviction after trial by the High Court be sentenced to a term of imprisonment of not less than three years and net exceeding five years.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the births and deaths registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'deaths', 'id': 1, 'context': 's and Deaths Registration Act (Chapter 110); \"District Registrar\" means a District Registrar of Birth and Deaths appointed under the Births and Deaths Registration Act (Chapter 10); \"Registrar-General\" means the Registrar-General of Births and Deaths appointed under the Births and Deaths Registration Act (Chapter 110) and includes a Deputy Registrar-General. s and Deaths Registration Act (Chapter 110); \"District Registrar\" means a District Registrar of Birth and Deaths appointed under the Births and Deaths Registration Act (Chapter 10); \"Registrar-General\" means the Registrar-General of Births and Deaths appointed under the Births and Deaths Registration Act (Chapter 110) and includes a Deputy Registrar-General. s and Deaths Registration Act (Chapter 110); \"District Registrar\" means a District Registrar of Birth and Deaths appointed under the Births and Deaths Registration Act (Chapter 10); \"Registrar-General\" means the Registrar-General of Births and Deaths appointed under the Births and Deaths Registration Act (Chapter 110) and includes a Deputy Registrar-General.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the political party of Sri Lanka?', 'Answer': 'socialist republic', 'id': 1, 'context': '5.00 Published as a Supplement to Part II of the Gazette of the Democratic Socialist Republic of Sri Lanka of June 17, 2005 1 Registration of Deaths (Temporary Pr PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLIC OF SRI LANKA REGISTRATION OF DEATHS (TEMPORARY PROVISIONS) ACT, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the natural disaster or calamity that has seroius consequences at the national level?', 'Answer': 'calamity', 'id': 1, 'context': 'An Act to provide for the registration of deaths of persons reported missing as a result of terrorist or subversive activity or civil commotion and of persons whose death is directly attributable to any natural disaster or calamity which has seroius consequences at the national level ; and for matters connected therewith or incidental thereto.'}, {'Question': 'What is the cause of the death of persons reported missing?', 'Answer': 'commotion', 'id': 2, 'context': 'An Act to provide for the registration of deaths of persons reported missing as a result of terrorist or subversive activity or civil commotion and of persons whose death is directly attributable to any natural disaster or calamity which has seroius consequences at the national level ; and for matters connected therewith or incidental thereto.'}, {'Question': 'What is the Act to register of persons reported missing as a result of terrorist or subversive activity or civil commotion and of persons whose death is directly attributable to any natural disaster or calamity which has seroius consequences at the national level?', 'Answer': 'deaths', 'id': 3, 'context': 'An Act to provide for the registration of deaths of persons reported missing as a result of terrorist or subversive activity or civil commotion and of persons whose death is directly attributable to any natural disaster or calamity which has seroius consequences at the national level ; and for matters connected therewith or incidental thereto.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where have there been many deaths due to natural disasters or calamities of national proportions and where the number of persons dead has reached alarming proportions?', 'Answer': 'sri lanka', 'id': 1, 'context': 'ng in the course of the civil distrubances that have taken place due to terrorist or subversive activities or civil commotion in Sri Lanka : And Whereas several people have died due to being exposed to natural disasters or calamities of national proportions and where the number of persons dead has reached alarming proportions : And Whereas there are certain practical difficulties impeding the registration of such deaths in both situations enumerated above under the provisions of the Births and Deaths Regist'}, {'Question': 'What are the natural disasters or the number of people dead in Sri Lanka?', 'Answer': 'calamities', 'id': 2, 'context': 'ng in the course of the civil distrubances that have taken place due to terrorist or subversive activities or civil commotion in Sri Lanka : And Whereas several people have died due to being exposed to natural disasters or calamities of national proportions and where the number of persons dead has reached alarming proportions : And Whereas there are certain practical difficulties impeding the registration of such deaths in both situations enumerated above under the provisions of the Births and Deaths Regist'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the country that passed the ration act?', 'Answer': 'sri lanka', 'id': 1, 'context': 'ration Act (Chapter 110) : And Whereas it has now become necessary to make temporary provision enabling the registration of such deaths : Now Therefore be it enacted by the Parliament of the Democratic Socialist Republic of Sri Lanka as follows :— 1.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the registration of death?', 'Answer': 'deaths', 'id': 1, 'context': '2 Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What is the purpose of the Deaths Act, No. 2?', 'Answer': 'registration', 'id': 2, 'context': '2 Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What is the short title of the Act?', 'Answer': 'title', 'id': 3, 'context': 'Short title and duration and extension of the Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where is a person reported missing and he has not been heard of for a period exceeding one year by those who would naturally have heard of him had he been alive?', 'Answer': 'sri lanka', 'id': 1, 'context': '(1) Where any person is reported missing and he has not been heard of for a period exceeding one year by those who would naturally have heard of him had he been alive and his disappearance is attributable to any terrorist or subversive activity or civil commotion which has been taking place within Sri Lanka, a next of kin of such person if he verily believes such person to be dead, may apply in the manner hereinafter provided, to register the death of such person under the Births and De'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the last missing person in the district where the missing person was last residing?', 'Answer': 'births', 'id': 1, 'context': '(2) Every application under this section shall be substantially in the Form specified in the Schedule to this Act and shall be forwarded to the Registrar-General or the District Registrar of Births and Deaths of the district in which such missing person was last residing.'}, {'Question': 'What is the name of the certificate of death issued to him in respect of such person?', 'Answer': 'certificate', 'id': 2, 'context': 'aths Registration Act (Chapter 110) and to have issued to him, a Certificate of Death in respect of such person.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'When does the Registrar-Gene process an application under the Act?', 'Answer': 'receipt', 'id': 1, 'context': 'Upon receipt of an application under this Act, the Registrar-Gene'}, {'Question': 'What is the Registrar-Gene of the Grama Niladhari Division notified of the death of the person whose death is sought to be registered?', 'Answer': 'application', 'id': 2, 'context': 'that the person whose death is sought to be registered, is dead, and shall be accompanied by a report from the Grama Niladhari of the Grama Niladhari Division in which the person whose death is sought to be registered was last resident or had his permanant residence, confirming the fact that such person has not been seen alive or heard of, for a period of over one year, and accompanied by any other evidence in support of such application. Upon receipt of an application under this Act, the Registrar-Gene'}, {'Question': 'What is the Registrar-Gene?', 'Answer': 'act', 'id': 3, 'context': 'Upon receipt of an application under this Act, the Registrar-Gene'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where is the copy of the application displayed for a period of two weeks?', 'Answer': 'notice board', 'id': 1, 'context': 'ral or the District Registrar as the case may be, shall cause a copy of such application to be displayed for a period of two weeks on the Notice Board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered, was last resident or had his permanent residence.'}, {'Question': 'What is the last name of the person whose death is sought to be registered, or had his permanent residence?', 'Answer': 'resident', 'id': 2, 'context': 'ral or the District Registrar as the case may be, shall cause a copy of such application to be displayed for a period of two weeks on the Notice Board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered, was last resident or had his permanent residence.'}, {'Question': 'What is displayed on the Notice Board for two weeks?', 'Answer': 'application', 'id': 3, 'context': 'ral or the District Registrar as the case may be, shall cause a copy of such application to be displayed for a period of two weeks on the Notice Board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered, was last resident or had his permanent residence. Display of application.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the registration of death?', 'Answer': 'deaths', 'id': 1, 'context': '3 Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'What shall be supported by an affidavit of the objector and of any other person, setting out cl?', 'Answer': 'objections', 'id': 2, 'context': 'Any person may within one month of the date on which a copy of an application under this Act is first displayed as provided for in section 4, forward to the Registrar-General or the District Registrar, as the case may be, his objections in writing to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of the objector and of any other person, setting out cl Any person may within one month of the date on which a copy of an application under this Act is first displayed as provided for in section 4, forward to the Registrar-General or the District Registrar, as the case may be, his objections in writing to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of the objector and of any other person, setting out cl'}, {'Question': 'What is the process of registering the death of the person to whom the application relates?', 'Answer': 'registration', 'id': 3, 'context': 'Any person may within one month of the date on which a copy of an application under this Act is first displayed as provided for in section 4, forward to the Registrar-General or the District Registrar, as the case may be, his objections in writing to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of the objector and of any other person, setting out cl 3 Registration of Deaths (Temporary Provisions) Act, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'When is the period of one month allowed for the forwarding of objections to an application?', 'Answer': 'expiry', 'id': 1, 'context': '(1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar as the case may be, shall consider the application together with the evidence in support of the application and the objections, if any, and the evidence tendered in support of such objections, and after such inquiry as he may deem necessary, if satisfied as to the truth of the matters stated in the application, all'}, {'Question': 'What is the process of removing objections to an application?', 'Answer': 'forwarding', 'id': 2, 'context': '(1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar as the case may be, shall consider the application together with the evidence in support of the application and the objections, if any, and the evidence tendered in support of such objections, and after such inquiry as he may deem necessary, if satisfied as to the truth of the matters stated in the application, all'}, {'Question': 'What is the evidence tendered in support of an application?', 'Answer': 'objections', 'id': 3, 'context': '(1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar as the case may be, shall consider the application together with the evidence in support of the application and the objections, if any, and the evidence tendered in support of such objections, and after such inquiry as he may deem necessary, if satisfied as to the truth of the matters stated in the application, all (1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar as the case may be, shall consider the application together with the evidence in support of the application and the objections, if any, and the evidence tendered in support of such objections, and after such inquiry as he may deem necessary, if satisfied as to the truth of the matters stated in the application, all (1) On the expiry of the period of one month allowed for the forwarding of objections to an application, the Registrar-General or the District Registrar as the case may be, shall consider the application together with the evidence in support of the application and the objections, if any, and the evidence tendered in support of such objections, and after such inquiry as he may deem necessary, if satisfied as to the truth of the matters stated in the application, all'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the procedure for registering a death under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'aforesaid', 'id': 1, 'context': 'ow such application and shall forward to the Registrar-General a Report under his hand setting out such of the particulars of the death as is required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid.'}, {'Question': 'On what date shall the Registrar-General make an order directing the appropr?', 'Answer': 'receipt', 'id': 2, 'context': '(2) On receipt of the Report under subsection (1), the Registrar-General shall, except in a case where he disallows a Report in the exercise of the powers conferred on him by section 7, make order directing the appropr'}, {'Question': 'What is the name of the birth and death registration act?', 'Answer': 'births', 'id': 3, 'context': 'ow such application and shall forward to the Registrar-General a Report under his hand setting out such of the particulars of the death as is required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid.'}, {'Question': 'What is required to be registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'particulars', 'id': 4, 'context': 'ow such application and shall forward to the Registrar-General a Report under his hand setting out such of the particulars of the death as is required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the Register of Deaths maintained by Registrar under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'births', 'id': 1, 'context': '(3) On receipt by a Registrar of an order under subsection (2) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him, under the Births and Deaths Registration Act (Chapter 110) and issue in respect of such person iate Registrar to enter in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death.'}, {'Question': 'What is required of a Registrar to enter in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110) and issue in respect of such person a Certificate of Death?', 'Answer': 'particulars', 'id': 2, 'context': '(3) On receipt by a Registrar of an order under subsection (2) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him, under the Births and Deaths Registration Act (Chapter 110) and issue in respect of such person iate Registrar to enter in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death.'}, {'Question': 'What is the name of the register of death maintained by Registrar under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'register', 'id': 3, 'context': '(3) On receipt by a Registrar of an order under subsection (2) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him, under the Births and Deaths Registration Act (Chapter 110) and issue in respect of such person iate Registrar to enter in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is attached to the registration entry, the written order of the Registrar-General made under subsection (2) and such duplicate and order shall be sent together by the Regis 17 of 2005 (4) There shall be attached to the relevant registration entry, the written order of the Registrar-General made under subsection (2) and such duplicate and order shall be sent together by the Regis 17 of 2005 (4)', 'Answer': 'duplicate', 'id': 1, 'context': '17 of 2005 (4) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (2) and such duplicate and order shall be sent together by the Regis 17 of 2005 (4) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (2) and such duplicate and order shall be sent together by the Regis'}, {'Question': 'What are the reasons for registration?', 'Answer': 'objections', 'id': 2, 'context': 'Objections to registration.'}, {'Question': 'What is the place where the Certificate of Death is issued?', 'Answer': 'register', 'id': 3, 'context': 'a Certificate of Death, the Registrar shall forthwith enter those particulars in such Register and sign the Register in the appropriate place and issue the Certificate of Death. a Certificate of Death, the Registrar shall forthwith enter those particulars in such Register and sign the Register in the appropriate place and issue the Certificate of Death.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the process of a refusal of a certificate under this Act?', 'Answer': 'notification', 'id': 1, 'context': 'An applicant who is dissatisfied with the decision of the District Registrar refusing to issue a certificate to him under section 6, or a person who has objected under section 5 to the issue of a certificate under this Act and who is dissatisfied with the decision of the District Registrar to issue such certificate, may within one month of the notification of such refusal or issue, as the case'}, {'Question': 'If an applicant is dissatisfied with the decision of the District Registrar to issue a certificate under section 6, or a person who has objected under section 5 to the issue of a certificate under this Act and who is dissatisfied with the decision of the District Registrar to issue a certificate under section 6, or a person who has objected under section 5 to the issue of such certificate and who is dissatisfied with the decision of the District Registrar to issue', 'Answer': 'refusal', 'id': 2, 'context': 'An applicant who is dissatisfied with the decision of the District Registrar refusing to issue a certificate to him under section 6, or a person who has objected under section 5 to the issue of a certificate under this Act and who is dissatisfied with the decision of the District Registrar to issue such certificate, may within one month of the notification of such refusal or issue, as the case'}, {'Question': 'What is the purpose of trar to the District Registrar for custody?', 'Answer': 'transmission', 'id': 3, 'context': 'trar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What may the Registrar-General issue under section 6 or disallow the report issued by the District Registrar under section 6?', 'Answer': 'certificate', 'id': 1, 'context': 'The Registrar-General may after review of the material before him, either affirm the decision of the District Registrar or direct the District Registrar to issue a certificate under section 6 or disallow the report issued by that District Registrar under section 6, as the case may be.'}, {'Question': 'What is a special commission of inquiry?', 'Answer': 'commission', 'id': 2, 'context': '(1) Where a Commission appointed under the Commissions of Inquiry Act (Chapter 393) or a Special Presidential Commission of Inquiry (1) Where a Commission appointed under the Commissions of Inquiry Act (Chapter 393) or a Special Presidential Commission of Inquiry'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If 7 of 1978 finds that a person has disappeared or is missing, the next of kin of that person may apply to the Registrar-General or to the District Registrar of what?', 'Answer': 'births', 'id': 1, 'context': '7 of 1978 finds that a person has disappeared or is missing, the next of kin of that person may, apply to the Registrar-General or to the District Registrar of Births and Deaths of the district in which that person was last residing or had his permanant residence, substantially in the Form set out in the Schedule to this Act, to register the death of that person under the Births and Deaths Registration Act (Chapter 110) and to have issued to hi 7 of 1978 finds that a person has disappeared or is missing, the next of kin of that person may, apply to the Registrar-General or to the District Registrar of Births and Deaths of the district in which that person was last residing or had his permanant residence, substantially in the Form set out in the Schedule to this Act, to register the death of that person under the Births and Deaths Registration Act (Chapter 110) and to have issued to hi'}, {'Question': 'What is the form for registering the death of a person under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'schedule', 'id': 2, 'context': '7 of 1978 finds that a person has disappeared or is missing, the next of kin of that person may, apply to the Registrar-General or to the District Registrar of Births and Deaths of the district in which that person was last residing or had his permanant residence, substantially in the Form set out in the Schedule to this Act, to register the death of that person under the Births and Deaths Registration Act (Chapter 110) and to have issued to hi'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the commission that finds the death of a person?', 'Answer': 'inquiry', 'id': 1, 'context': 'Every such application shall be accompanied by an affidavit of the applicant in terms of section 3 and a certified copy of the findings of the Commission of Inquiry or Special Presidential Commission of Inquiry, as the case may be, relating to the death of such person. Every such application shall be accompanied by an affidavit of the applicant in terms of section 3 and a certified copy of the findings of the Commission of Inquiry or Special Presidential Commission of Inquiry, as the case may be, relating to the death of such person. Special procedure relating to registration of deaths of persons in respect of whom there are findings by a Commission of Inquiry or a Special Presidential Commission of Inquiry'}, {'Question': 'What is the special procedure relating to the death of persons in respect of whom there are findings by a Commission of Inquiry or a Special Presidential Commission of Inquiry?', 'Answer': 'registration', 'id': 2, 'context': 'Special procedure relating to registration of deaths of persons in respect of whom there are findings by a Commission of Inquiry or a Special Presidential Commission of Inquiry'}, {'Question': 'What is the result of the Commission of Inquiry or Special Presidential Commission of Inquiry relating to the death of a person?', 'Answer': 'findings', 'id': 3, 'context': 'Every such application shall be accompanied by an affidavit of the applicant in terms of section 3 and a certified copy of the findings of the Commission of Inquiry or Special Presidential Commission of Inquiry, as the case may be, relating to the death of such person. Special procedure relating to registration of deaths of persons in respect of whom there are findings by a Commission of Inquiry or a Special Presidential Commission of Inquiry'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How do I send the Report to the Registrar-General?', 'Answer': 'forthwith', 'id': 1, 'context': '17 of 2005 (2) Upon receipt of an application under subsection (1), the District Registrar shall, notwithstanding anything to contrary in the preceding provisions of this Act, forthwith send to the Registrar-General a Report under his hand, setting out the particulars of the death required to be registered under the Births and Deaths Registration Act (Chapter 110) as he has been ab'}, {'Question': 'What is the first step in registering a death under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'receipt', 'id': 2, 'context': '17 of 2005 (2) Upon receipt of an application under subsection (1), the District Registrar shall, notwithstanding anything to contrary in the preceding provisions of this Act, forthwith send to the Registrar-General a Report under his hand, setting out the particulars of the death required to be registered under the Births and Deaths Registration Act (Chapter 110) as he has been ab'}, {'Question': 'What is required to be registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'deaths', 'id': 3, 'context': '17 of 2005 (2) Upon receipt of an application under subsection (1), the District Registrar shall, notwithstanding anything to contrary in the preceding provisions of this Act, forthwith send to the Registrar-General a Report under his hand, setting out the particulars of the death required to be registered under the Births and Deaths Registration Act (Chapter 110) as he has been ab 5 Registration of Deaths (Temporary Provisions) Act, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is responsible for registering a person in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'registrar', 'id': 1, 'context': '(3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death. (3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death. (3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death.'}, {'Question': 'What is issued in respect of a person who dies under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'certificate', 'id': 2, 'context': '(3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death.'}, {'Question': 'What is the name of the register maintained by the Registrar under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'deaths', 'id': 3, 'context': '(3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death. (3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death.'}, {'Question': 'What is subsection (3) directing the Registrar-General to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110) the particulars specified in such Report and issue in respect of such person a Certificate of Death?', 'Answer': 'subsection', 'id': 4, 'context': '(3) Upon receipt of the Report under subsection (2), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110), the particulars specified in such Report and issue in respect of such person a Certificate of Death. (4) Upon receipt of an order under subsection (3) directing him to enter th'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the births and deaths registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'births', 'id': 1, 'context': 'e particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110), the Registrar shall forthwith enter such particulars in such register and sign the register in the appropriate place.'}, {'Question': 'What is attached to the registration entry?', 'Answer': 'duplicate', 'id': 2, 'context': '(5) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (3) and such duplicate and order shall be sent together, by the Registrar to the appropriate Distri (5) There shall be attached to the duplicate of the relevant registration entry, the written order of the Registrar-General made under subsection (3) and such duplicate and order shall be sent together, by the Registrar to the appropriate Distri'}, {'Question': 'What shall the Registrar forthwith enter in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110) and sign the register in the appropriate place?', 'Answer': 'particulars', 'id': 3, 'context': 'e particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110), the Registrar shall forthwith enter such particulars in such register and sign the register in the appropriate place. e particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chapter 110), the Registrar shall forthwith enter such particulars in such register and sign the register in the appropriate place.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where the application under subsection (1) is made to the Registrar-General, the provisions of subsections (2) and (5) shall mutatis mutandis apply as if the reference in those sections to the District Registrar is a reference to the Registrar- General?', 'Answer': 'registrar', 'id': 1, 'context': '(6) Where the application under subsection (1) is made to the Registrar-General, the provisions of subsections (2) and (5) shall mutatis mutandis apply as if the reference in those sections to the District Registrar is a reference to the Registrar- General. (6) Where the application under subsection (1) is made to the Registrar-General, the provisions of subsections (2) and (5) shall mutatis mutandis apply as if the reference in those sections to the District Registrar is a reference to the Registrar- General. (6) Where the application under subsection (1) is made to the Registrar-General, the provisions of subsections (2) and (5) shall mutatis mutandis apply as if the reference in those sections to the District Registrar is a reference to the Registrar- General.'}, {'Question': \"What is the Registrar-General's office for?\", 'Answer': 'custody', 'id': 2, 'context': 'ct Registrar for transmission to the Registrar-General for custody in his office.'}, {'Question': 'What is the registration of death?', 'Answer': 'deaths', 'id': 3, 'context': '6 Registration of Deaths (Temporary Provisions) Act, No.'}, {'Question': 'Where an application under subsection (1) is made to the Registrar-General, the provisions of subsections (2) and (5) shall mutatis mutandis apply as if the reference in those sections to the District Registrar is a reference to the Registrar-General?', 'Answer': 'subsection', 'id': 4, 'context': '(6) Where the application under subsection (1) is made to the Registrar-General, the provisions of subsections (2) and (5) shall mutatis mutandis apply as if the reference in those sections to the District Registrar is a reference to the Registrar- General.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where has the number of persons dead as a result of a natural disaster or calamity caused either to the whole of Sri Lanka or to certain areas thereof, destruction to persons and property, which has had far reaching effects at the national level, making the application of the provisions of the Births and Deaths Registration Act (Chapter 110) to the registration of the deaths of such persons impractical?', 'Answer': 'sri lanka', 'id': 1, 'context': 're has been within Sri Lanka a natural disaster or calamity which has caused either to the whole of Sri Lanka or to certain areas thereof, destruction to persons and property, which has had far reaching effects at the national level, and where the number of persons dead as a result of such disaster or calamity has reached alarming proportions thereby making the application of the provisions of the Births and Deaths Registration Act (Chapter 110) to the registration of the deaths of such persons impractical, re has been within Sri Lanka a natural disaster or calamity which has caused either to the whole of Sri Lanka or to certain areas thereof, destruction to persons and property, which has had far reaching effects at the national level, and where the number of persons dead as a result of such disaster or calamity has reached alarming proportions thereby making the application of the provisions of the Births and Deaths Registration Act (Chapter 110) to the registration of the deaths of such persons impractical,'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the case of a natural disaster?', 'Answer': 'calamity', 'id': 1, 'context': 'the Registrar- General may, upon verification of the fact that a natural disaster or calamity has occurred, declare any Administrative District, Divisional Secretaries Division or Grama Niladhari Division as the case may be affected by such disaster or calamity, as a “National Disaster Area”. the Registrar- General may, upon verification of the fact that a natural disaster or calamity has occurred, declare any Administrative District, Divisional Secretaries Division or Grama Niladhari Division as the case may be affected by such disaster or calamity, as a “National Disaster Area”.'}, {'Question': 'What section of the Code declares a National Disaster Area?', 'Answer': 'section', 'id': 2, 'context': '(1) Where any person or persons— (a) who had been resident within an area declared to be a National Disaster Area under section 9 ; or (b) who have been resident within any other area but was at the time of the oc'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the reason for the disappearance of a natural disaster or calamity?', 'Answer': 'intents', 'id': 1, 'context': 'currence of such natural disaster or calamity known to have gone to or to have been within any area declared to be a National Disaster Area under section 9, cannot be found subsequent to such natural disaster or calamity and has for all intents and purposes disappeared due to the effects of the disaster or calamity, a next of kin of such person or persons or where no members of the family have survived the natural disaster or calamity, any person having knowledge of such person or persons may, if he verily'}, {'Question': 'If a natural disaster or calamity has gone to or has been within any area declared to be a National Disaster Area under section 9, cannot be found subsequent to such natural disaster or calamity and has for all intents and purposes disappeared due to the effects of the disaster or calamity, a next of kin of such person or persons or where no members of the family have survived the natural disaster or calamity, any person having knowledge of such person or persons may, if he verily', 'Answer': 'calamity', 'id': 2, 'context': 'currence of such natural disaster or calamity known to have gone to or to have been within any area declared to be a National Disaster Area under section 9, cannot be found subsequent to such natural disaster or calamity and has for all intents and purposes disappeared due to the effects of the disaster or calamity, a next of kin of such person or persons or where no members of the family have survived the natural disaster or calamity, any person having knowledge of such person or persons may, if he verily currence of such natural disaster or calamity known to have gone to or to have been within any area declared to be a National Disaster Area under section 9, cannot be found subsequent to such natural disaster or calamity and has for all intents and purposes disappeared due to the effects of the disaster or calamity, a next of kin of such person or persons or where no members of the family have survived the natural disaster or calamity, any person having knowledge of such person or persons may, if he verily currence of such natural disaster or calamity known to have gone to or to have been within any area declared to be a National Disaster Area under section 9, cannot be found subsequent to such natural disaster or calamity and has for all intents and purposes disappeared due to the effects of the disaster or calamity, a next of kin of such person or persons or where no members of the family have survived the natural disaster or calamity, any person having knowledge of such person or persons may, if he verily'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the cause of death of a person?', 'Answer': 'calamity', 'id': 1, 'context': 'believes such person or persons to be dead, apply in the manner hereinafter provided, to register the death of such Who may apply for the issue of a Death Certificate in case of persons believed to be dead as a result of any natural disaster or calamity, and procedure.'}, {'Question': 'What is the cause of death of a person?', 'Answer': 'disaster', 'id': 2, 'context': 'believes such person or persons to be dead, apply in the manner hereinafter provided, to register the death of such Who may apply for the issue of a Death Certificate in case of persons believed to be dead as a result of any natural disaster or calamity, and procedure. Registrar- General to declare “National Disaster Areas”.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the person whose death is sought to be registered?', 'Answer': 'description', 'id': 1, 'context': '(3) Every such application shall be submitted in any form whatsoever, containing wherever possible at least some of the information set out in the Schedule hereto, which information would as far as practicable be a description of the person whose death is sought to be registered.'}, {'Question': 'What is the e of Death in relation to the death of such person or persons?', 'Answer': 'respect', 'id': 2, 'context': 'e of Death in respect of the death of such person or persons.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is required to support a claim?', 'Answer': 'affidavit', 'id': 1, 'context': 'ery such application shall be accompanied by an Affidavit in support of such facts.'}, {'Question': 'When will the Grama Niladhari recommend the application and forward it along with a report certifying to the best of his knowledge the accuracy of the facts stated therein?', 'Answer': 'receipt', 'id': 2, 'context': 'The Grama Niladhari shall as soon as possible upon the receipt of such application, and after such inquiry as he deems necessary, recommend the same and forward it along with a report certifying to the best of his knowledge the accuracy of the facts stated therein, to the Divisional Secretary of the division within which his Division is situated.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is required to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110) the particulars specified in such application and issue in respect of such person, a Certificate of Death?', 'Answer': 'registrar', 'id': 1, 'context': '(4) Upon receipt of an application under subsection (2), duly recommended and endorsed in terms of the provisions of subsection (3), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110), the particulars specified in such application and issue in respect of such person, a Certificate of Death. (4) Upon receipt of an application under subsection (2), duly recommended and endorsed in terms of the provisions of subsection (3), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110), the particulars specified in such application and issue in respect of such person, a Certificate of Death. (4) Upon receipt of an application under subsection (2), duly recommended and endorsed in terms of the provisions of subsection (3), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110), the particulars specified in such application and issue in respect of such person, a Certificate of Death.'}, {'Question': 'What is issued in respect of a person who died under the Births and Deaths Registration Act (Chaper 110)?', 'Answer': 'certificate', 'id': 2, 'context': '(4) Upon receipt of an application under subsection (2), duly recommended and endorsed in terms of the provisions of subsection (3), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110), the particulars specified in such application and issue in respect of such person, a Certificate of Death.'}, {'Question': 'What is the name of the person who is registered in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110)?', 'Answer': 'deaths', 'id': 3, 'context': '(4) Upon receipt of an application under subsection (2), duly recommended and endorsed in terms of the provisions of subsection (3), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110), the particulars specified in such application and issue in respect of such person, a Certificate of Death. (4) Upon receipt of an application under subsection (2), duly recommended and endorsed in terms of the provisions of subsection (3), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110), the particulars specified in such application and issue in respect of such person, a Certificate of Death.'}, {'Question': 'What is subsection (3) of the Births and Deaths Registration Act?', 'Answer': 'subsection', 'id': 4, 'context': '(4) Upon receipt of an application under subsection (2), duly recommended and endorsed in terms of the provisions of subsection (3), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110), the particulars specified in such application and issue in respect of such person, a Certificate of Death. (4) Upon receipt of an application under subsection (2), duly recommended and endorsed in terms of the provisions of subsection (3), the Registrar-General shall make order directing the appropriate Registrar to register in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chaper 110), the particulars specified in such application and issue in respect of such person, a Certificate of Death.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is chaper 110?', 'Answer': 'chaper', 'id': 1, 'context': 'tion (4) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chaper 110), the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate place.'}, {'Question': 'What is the name of the register of death maintained by the Registrar under the Births and Deaths Registration Act (Chaper 110)?', 'Answer': 'births', 'id': 2, 'context': 'tion (4) directing him to enter the particulars relating to the relevant death in the Register of Deaths maintained by him under the Births and Deaths Registration Act (Chaper 110), the Registrar shall forthwith enter such particulars in such Register and sign the Register in the appropriate place.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the Registrar-General responsible for?', 'Answer': 'custody', 'id': 1, 'context': 'n (4) and such duplicate and order shall be sent together by the Registrar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office.'}, {'Question': 'What is the name of the duplicate order?', 'Answer': 'duplicate', 'id': 2, 'context': 'n (4) and such duplicate and order shall be sent together by the Registrar to the appropriate District Registrar for transmission to the Registrar-General for custody in his office.'}, {'Question': 'Where the application under subsection (1) is made directly to the Registrar-General, the provisions of subsections (2) to (6) shall mutatis mutandis apply as if the reference in those sections to the District Registrar is a reference to the Registrar-General.', 'Answer': 'subsection', 'id': 3, 'context': '(7) Where the application under subsection (1) is made directly to the Registrar-General, the provisions of subsections (2) to (6) shall mutatis mutandis apply as if the reference in those sections to the District Registrar is a reference to the Registrar-General.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person has died as a result of a natural disaster or calamity in question, then any person having knowledge of these facts may apply for a Certificate of Death in respect of such person to be issued to him.', 'Answer': 'sri lanka', 'id': 1, 'context': 'ate had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply for a Certificate of Death in respect of such person to be issued to him. Every such application shall be authenticated by the representative of the country of which such person was a citizen, present in Sri Lanka, an'}, {'Question': 'If a person has died as a result of a natural disaster or what is the cause of death?', 'Answer': 'calamity', 'id': 2, 'context': 'ate had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply for a Certificate of Death in respect of such person to be issued to him.'}, {'Question': 'If a person has died as a result of a natural disaster or calamity in question, then any person having knowledge of these facts can apply for what?', 'Answer': 'certificate', 'id': 3, 'context': 'ate had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply for a Certificate of Death in respect of such person to be issued to him.'}, {'Question': 'If a person has died as a result of a natural disaster or calamity in question, then any person having knowledge of these facts may apply for a Certificate of Death in respect of such person to be issued to him.', 'Answer': 'disaster', 'id': 4, 'context': 'ate had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply for a Certificate of Death in respect of such person to be issued to him. ate had been in Sri Lanka and temporarily resident within an area declared as a National Disaster Area in terms of section 9, and that it is apparent that such person has died as a result of the natural disaster or calamity in question, then any person having knowledge of these facts may apply for a Certificate of Death in respect of such person to be issued to him.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the death certificate for a person attributable to?', 'Answer': 'calamity', 'id': 1, 'context': '10 of 1988, be applicable to the issue of death certificates in respect of persons whose death is attributable to any natural disaster or calamity and the death in questio'}, {'Question': 'What is the evidence (Amendment) Act, No. 108?', 'Answer': 'amendment', 'id': 2, 'context': 'The provisions of this Part of this Act, shall notwithstanding the provisions of section 108 of the Evidence Ordinance as amended by the Evidence (Amendment) Act, No.'}, {'Question': 'What shall notwithstanding the provisions of this Part of this Act, as amended by the Evidence (Amendment) Act, No. 108?', 'Answer': 'provisions', 'id': 3, 'context': 'The provisions of this Part of this Act, shall notwithstanding the provisions of section 108 of the Evidence Ordinance as amended by the Evidence (Amendment) Act, No. The provisions of this Part of this Act, shall notwithstanding the provisions of section 108 of the Evidence Ordinance as amended by the Evidence (Amendment) Act, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is registered as dead?', 'Answer': 'nationals', 'id': 1, 'context': 'Registration of deaths of foreign nationals.'}, {'Question': 'What is the registration of foreign nationals?', 'Answer': 'deaths', 'id': 2, 'context': '9 Registration of Deaths (Temporary Provisions) Act, No. Registration of deaths of foreign nationals.'}, {'Question': 'What is the process of death of foreign nationals?', 'Answer': 'registration', 'id': 3, 'context': '9 Registration of Deaths (Temporary Provisions) Act, No. Registration of deaths of foreign nationals.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who shall investigate the truth of the information and make a report to the Registrar-General?', 'Answer': 'police station', 'id': 1, 'context': '(2) The Registrar-General shall, on receipt of such information convey the information to the Officer-in-Charge of the relevant police station, who shall investigate the truth of such information and make a report to the Registrar- General, within four weeks of the date on which such information is conveyed to such officer.'}, {'Question': 'How do I furnish the information to the Registrar-General?', 'Answer': 'forthwith', 'id': 2, 'context': 'stered is alive, such person shall forthwith furnish such information to the Registrar-General.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is chaper 110 of the Births and Deaths Registration Act?', 'Answer': 'chaper', 'id': 1, 'context': 'cessary the Registrar-General, if satisfied that the person whose death has been registered is alive, shall take such action, or make such order or give such direction, under section 52 of the Births and Deaths Registration Act, (Chaper 110), as is appropriate in the circumstances of the case.'}, {'Question': 'What is the name of the births and deaths registered under the Births and Deaths Registration Act, (Chaper 110)?', 'Answer': 'births', 'id': 2, 'context': 'cessary the Registrar-General, if satisfied that the person whose death has been registered is alive, shall take such action, or make such order or give such direction, under section 52 of the Births and Deaths Registration Act, (Chaper 110), as is appropriate in the circumstances of the case.'}, {'Question': \"What is the Registrar-General's power under this Act?\", 'Answer': 'inquiry', 'id': 3, 'context': '(4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purposes of an inquiry under this Act, exercise all the power (4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-General may, for the purposes of an inquiry under this Act, exercise all the power'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the registration of death under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'births', 'id': 1, 'context': 's exercisable by him under the Births and Deaths Registration Act (Chapter 110), in relation to an inquiry held by him under that Act.'}, {'Question': 'What is held by him under the Births and Deaths Registration Act (Chapter 110) in relation to an inquiry held by him under that Act?', 'Answer': 'inquiry', 'id': 2, 'context': 's exercisable by him under the Births and Deaths Registration Act (Chapter 110), in relation to an inquiry held by him under that Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who will convict a person who uses a Certificate of Death issued under the Births and Deaths Registration Act (Chapter 110) knowing, or having reason to believe that the person referred to in such certificate is alive, and shall upon conviction after trial be sentenced to a term of imprisonment of not less than three years and not exceed?', 'Answer': 'high court', 'id': 1, 'context': 'pplication made under this Act, is alive, fails to furnish such information to the Registrar-General ; or (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act (Chapter 110) knowing, or having reason to believe that the person referred to in such certificate is alive, shall be guilty of an offence under this Act, and shall upon conviction after trial by the High Court be sentenced to a term of imprisonment of not less than three years and not exceedi'}, {'Question': 'What is dishonestly or fraudulently using a Certificate of Death issued under the Births and Deaths Registration Act (Chapter 110) knowing, or having reason to believe that the person referred to in such certificate is alive, shall be guilty of?', 'Answer': 'offence', 'id': 2, 'context': 'pplication made under this Act, is alive, fails to furnish such information to the Registrar-General ; or (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act (Chapter 110) knowing, or having reason to believe that the person referred to in such certificate is alive, shall be guilty of an offence under this Act, and shall upon conviction after trial by the High Court be sentenced to a term of imprisonment of not less than three years and not exceedi'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZERO\n",
            "Unexpected structure in the 'outputs' dictionary. Check the structure and update the code.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the reason for the Sinhala text to prevail?', 'Answer': 'inconsistency', 'id': 1, 'context': 'Sinhala text to prevail in case of inconsistency.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the birth and death registration act?', 'Answer': 'births', 'id': 1, 'context': 'I therefore request that the death be registered under the Births and Deaths Registration Act (Chapter 11'}, {'Question': 'Who is the missing person?', 'Answer': 'applicant', 'id': 2, 'context': 'Applicant ’s relationship to missing person : I …… of …… do hereby state that the said …… …… (name of person missing) ………… has been missing for a period of over one year, and I verily believe that the said ………… is dead. Applicant’s full name and residence : 9.'}, {'Question': 'What is the rank of a profession?', 'Answer': 'rank', 'id': 3, 'context': 'Rank or profession : 8.'}, {'Question': 'What is the last known residence?', 'Answer': 'residence', 'id': 4, 'context': 'Applicant’s full name and residence : 9. Address of last known residence : 6. Address of permanant residence : 7.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the city in which the TRANSWORKS HOUSE is located?', 'Answer': 'colombo', 'id': 1, 'context': '32, TRANSWORKS HOUSE, LOTUS ROAD, COLOMBO 01 before 15th December each year in respect of the year following.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the country that enacted the BE?', 'Answer': 'sri lanka', 'id': 1, 'context': 'BE it enacted by the Parliament of the Democratic Socialist Republic of Sri Lanka as follows: Short title.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who remains itution, for subsection (1) thereof, of the following subsection : \" (1) Every person who is in, or enters, Sri Lanka on or after the appointed date, and has attained, or attains, the age of sixteen years, not being a person who is not liable to registration by virtue of the operation of the provisions of subsection (2) ; or (b) who has entered, or enters, Sri Lanka before or on or after that date in contravention of the provisions of section 10 of the Immigran', 'Answer': 'sri lanka', 'id': 1, 'context': 'itution, for subsection (1) thereof, of the following subsection : \" (1) Every person who is in, or enters, Sri Lanka on or after the appointed date, and has attained, or attains, the age of sixteen years, not being a person (a) who is not liable to registration by virtue of the operation of the provisions of subsection (2) ; or (b) who has entered, or enters, Sri Lanka before or on or after that date in contravention of the provisions of section 10 of the Immigrants and Emigrants Act; or ; (c) who remains itution, for subsection (1) thereof, of the following subsection : \" (1) Every person who is in, or enters, Sri Lanka on or after the appointed date, and has attained, or attains, the age of sixteen years, not being a person (a) who is not liable to registration by virtue of the operation of the provisions of subsection (2) ; or (b) who has entered, or enters, Sri Lanka before or on or after that date in contravention of the provisions of section 10 of the Immigrants and Emigrants Act; or ; (c) who remains'}, {'Question': 'What is the reason for entering Sri Lanka before or after the appointed date?', 'Answer': 'contravention', 'id': 2, 'context': 'itution, for subsection (1) thereof, of the following subsection : \" (1) Every person who is in, or enters, Sri Lanka on or after the appointed date, and has attained, or attains, the age of sixteen years, not being a person (a) who is not liable to registration by virtue of the operation of the provisions of subsection (2) ; or (b) who has entered, or enters, Sri Lanka before or on or after that date in contravention of the provisions of section 10 of the Immigrants and Emigrants Act; or ; (c) who remains'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where is India liable to remove to India under section 15 of the Indo-Ceylon Agreement (Implementation) Act, No.?', 'Answer': 'sri lanka', 'id': 1, 'context': 'in Sri Lanka on or after that date in contravention of the provisions of section 15 of that Act; or (d) who is liable to removal to India from Sri Lanka under section 15 of the Indo-Ceylon Agreement (Implementation) Act, No. in Sri Lanka on or after that date in contravention of the provisions of section 15 of that Act; or (d) who is liable to removal to India from Sri Lanka under section 15 of the Indo-Ceylon Agreement (Implementation) Act, No.'}, {'Question': 'Who is liable to be removed to India under section 15 of the Indo-Ceylon Agreement (Implementation) Act, No.?', 'Answer': 'india', 'id': 2, 'context': 'in Sri Lanka on or after that date in contravention of the provisions of section 15 of that Act; or (d) who is liable to removal to India from Sri Lanka under section 15 of the Indo-Ceylon Agreement (Implementation) Act, No.'}, {'Question': 'What is the purpose of the Indo-Ceylon Agreement, No. 15?', 'Answer': 'implementation', 'id': 3, 'context': 'in Sri Lanka on or after that date in contravention of the provisions of section 15 of that Act; or (d) who is liable to removal to India from Sri Lanka under section 15 of the Indo-Ceylon Agreement (Implementation) Act, No.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person is not liable to registration under subsection (1) of section 2 of the principal enactment and on such date becomes so liable by virtue of that section as amended by this Act, shall be deemed not to be guilty of what under section 44 of the principal enactment?', 'Answer': 'offence', 'id': 1, 'context': 'ttained the age of eighteen years and was therefore not a person liable to registration under subsection (1) of section 2 of the principal enactment, and on such date becomes so liable by virtue of the provisions of that section as amended by this Act, shall be deemed not to be guilty of an offence under section 44 of the principal enactment, provided that such person makes an application within the prescribed period for such registration under and in accordance with the provisions of that enactment.'}, {'Question': 'If a person is not liable to registration under subsection (1) of section 2 of the principal enactment and on such date becomes so liable by virtue of the provisions of that section as amended by this Act, shall be deemed not guilty of an offence under section 44 of the principal enactment, provided that such person makes an application within the prescribed period for such registration under and in accordance with the provisions of that section?', 'Answer': 'enactment', 'id': 2, 'context': 'ttained the age of eighteen years and was therefore not a person liable to registration under subsection (1) of section 2 of the principal enactment, and on such date becomes so liable by virtue of the provisions of that section as amended by this Act, shall be deemed not to be guilty of an offence under section 44 of the principal enactment, provided that such person makes an application within the prescribed period for such registration under and in accordance with the provisions of that enactment. ttained the age of eighteen years and was therefore not a person liable to registration under subsection (1) of section 2 of the principal enactment, and on such date becomes so liable by virtue of the provisions of that section as amended by this Act, shall be deemed not to be guilty of an offence under section 44 of the principal enactment, provided that such person makes an application within the prescribed period for such registration under and in accordance with the provisions of that enactment. ttained the age of eighteen years and was therefore not a person liable to registration under subsection (1) of section 2 of the principal enactment, and on such date becomes so liable by virtue of the provisions of that section as amended by this Act, shall be deemed not to be guilty of an offence under section 44 of the principal enactment, provided that such person makes an application within the prescribed period for such registration under and in accordance with the provisions of that enactment.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the prescribed period under section 52?', 'Answer': 'enactment', 'id': 1, 'context': 'tills section, \" prescribed period \" means the period within which any person referred to in subsection (1) is required by virtue of any regulation made under section 52, read with subsection (4) of section 7, of the principal enactment, to apply for registration under and in accordance with the provisions of that enactment. tills section, \" prescribed period \" means the period within which any person referred to in subsection (1) is required by virtue of any regulation made under section 52, read with subsection (4) of section 7, of the principal enactment, to apply for registration under and in accordance with the provisions of that enactment.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the country where a person is registered to be in Sri Lanka?', 'Answer': 'sri lanka', 'id': 1, 'context': 'REGISTRATION OF PERSONS AN ACT TO PROVIDE FOR THE REGISTRATION OF CERTAIN PERSONS WHO ARE IN SRI LANKA, FOR THE ISSUE OF IDENTITY CARDS TO THE PERSONS SO REGISTERED, AND FOR PURPOSES CONNECTED THEREWITH OR INCIDENTAL THERETO. (1) Every person who is in, or enters, Sri Lanka on or after the appointed date, and has attained, or attains, the age of sixteen years, not b'}, {'Question': 'What is the ISSUE OF IDENTITY CARDS TO THE PERSONS SO REGISTERED, AND FOR PURPOSES CONNECTED THEREWITH OR INCIDENTAL THERETO?', 'Answer': 'identity cards', 'id': 2, 'context': 'REGISTRATION OF PERSONS AN ACT TO PROVIDE FOR THE REGISTRATION OF CERTAIN PERSONS WHO ARE IN SRI LANKA, FOR THE ISSUE OF IDENTITY CARDS TO THE PERSONS SO REGISTERED, AND FOR PURPOSES CONNECTED THEREWITH OR INCIDENTAL THERETO.'}, {'Question': 'How can I get a IDENTITY CARD?', 'Answer': 'therewith', 'id': 3, 'context': 'REGISTRATION OF PERSONS AN ACT TO PROVIDE FOR THE REGISTRATION OF CERTAIN PERSONS WHO ARE IN SRI LANKA, FOR THE ISSUE OF IDENTITY CARDS TO THE PERSONS SO REGISTERED, AND FOR PURPOSES CONNECTED THEREWITH OR INCIDENTAL THERETO.'}, {'Question': 'What is the process of registering a person in SRI LANKA?', 'Answer': 'registered', 'id': 4, 'context': 'REGISTRATION OF PERSONS AN ACT TO PROVIDE FOR THE REGISTRATION OF CERTAIN PERSONS WHO ARE IN SRI LANKA, FOR THE ISSUE OF IDENTITY CARDS TO THE PERSONS SO REGISTERED, AND FOR PURPOSES CONNECTED THEREWITH OR INCIDENTAL THERETO.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is liable to remove to India from Sri Lanka under section 15 of the Indo-Ceylon Agreeme?', 'Answer': 'sri lanka', 'id': 1, 'context': 'eing a person (a) who is not liable to registration by virtue of the operation of the provisions of subsection (2) ; or (b) who has entered, or enters, Sri Lanka before or on or after that date in contravention of the provisions of section 10 of the Immigrants and Emigrants Act; or ; (c) who remains in Sri Lanka on or after that date in contravention of the provisions of section 15 of that Act; or [2,37 of 1971] (d) who is liable to removal to India from Sri Lanka under section 15 of the Indo-Ceylon Agreeme eing a person (a) who is not liable to registration by virtue of the operation of the provisions of subsection (2) ; or (b) who has entered, or enters, Sri Lanka before or on or after that date in contravention of the provisions of section 10 of the Immigrants and Emigrants Act; or ; (c) who remains in Sri Lanka on or after that date in contravention of the provisions of section 15 of that Act; or [2,37 of 1971] (d) who is liable to removal to India from Sri Lanka under section 15 of the Indo-Ceylon Agreeme eing a person (a) who is not liable to registration by virtue of the operation of the provisions of subsection (2) ; or (b) who has entered, or enters, Sri Lanka before or on or after that date in contravention of the provisions of section 10 of the Immigrants and Emigrants Act; or ; (c) who remains in Sri Lanka on or after that date in contravention of the provisions of section 15 of that Act; or [2,37 of 1971] (d) who is liable to removal to India from Sri Lanka under section 15 of the Indo-Ceylon Agreeme'}, {'Question': 'What is the reason for entering Sri Lanka before or on or after that date?', 'Answer': 'contravention', 'id': 2, 'context': 'eing a person (a) who is not liable to registration by virtue of the operation of the provisions of subsection (2) ; or (b) who has entered, or enters, Sri Lanka before or on or after that date in contravention of the provisions of section 10 of the Immigrants and Emigrants Act; or ; (c) who remains in Sri Lanka on or after that date in contravention of the provisions of section 15 of that Act; or [2,37 of 1971] (d) who is liable to removal to India from Sri Lanka under section 15 of the Indo-Ceylon Agreeme eing a person (a) who is not liable to registration by virtue of the operation of the provisions of subsection (2) ; or (b) who has entered, or enters, Sri Lanka before or on or after that date in contravention of the provisions of section 10 of the Immigrants and Emigrants Act; or ; (c) who remains in Sri Lanka on or after that date in contravention of the provisions of section 15 of that Act; or [2,37 of 1971] (d) who is liable to removal to India from Sri Lanka under section 15 of the Indo-Ceylon Agreeme'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the valid visa or what is granted to him under the Immigrants and Emigrants Act?', 'Answer': 'endorsement', 'id': 1, 'context': '(2) The following persons shall not be liable to registration : (a) a person who is the holder of a valid visa or endorsement granted to him under the Immigrants and Emigrants Act; or (b) a person who is exempted from the operation of Part 111 of that Act by, or by virtue of, an Order made under section 2 (1) of that Act; or [2,37 of (c) a person who is the holder of a Act Nos, 32 of 1971 28 of 1971 37 of 1971 11 of 1981 [ 27'}, {'Question': 'What is the valid visa or endorsement granted to him under the Immigrants and Emigrants Act?', 'Answer': 'visa', 'id': 2, 'context': '(2) The following persons shall not be liable to registration : (a) a person who is the holder of a valid visa or endorsement granted to him under the Immigrants and Emigrants Act; or (b) a person who is exempted from the operation of Part 111 of that Act by, or by virtue of, an Order made under section 2 (1) of that Act; or [2,37 of (c) a person who is the holder of a Act Nos, 32 of 1971 28 of 1971 37 of 1971 11 of 1981 [ 27'}, {'Question': 'Who is exempted from the operation of Part 111 by, or by virtue of, an Order made under section 2 (1) of that Act?', 'Answer': 'immigrants', 'id': 3, 'context': '(2) The following persons shall not be liable to registration : (a) a person who is the holder of a valid visa or endorsement granted to him under the Immigrants and Emigrants Act; or (b) a person who is exempted from the operation of Part 111 of that Act by, or by virtue of, an Order made under section 2 (1) of that Act; or [2,37 of (c) a person who is the holder of a Act Nos, 32 of 1971 28 of 1971 37 of 1971 11 of 1981 [ 27'}, {'Question': 'What are the persons who are not liable to a valid visa or endorsement granted to him under the Immigrants and Emigrants Act?', 'Answer': 'registration', 'id': 4, 'context': '(2) The following persons shall not be liable to registration : (a) a person who is the holder of a valid visa or endorsement granted to him under the Immigrants and Emigrants Act; or (b) a person who is exempted from the operation of Part 111 of that Act by, or by virtue of, an Order made under section 2 (1) of that Act; or [2,37 of (c) a person who is the holder of a Act Nos, 32 of 1971 28 of 1971 37 of 1971 11 of 1981 [ 27 14 of 1967, shall be a person liable to registration.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the purpose of the Indo-Ceylon Agreement?', 'Answer': 'implementation', 'id': 1, 'context': 'th February , 1981 ] 1971] valid residence permit issued under the Indo-Ceylon Agreement (Implementation) Act.'}, {'Question': 'Who are the officers and what are the servants?', 'Answer': 'servants', 'id': 2, 'context': 'PART I ADMINISTRATION Appointment of officers and servants.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'In the exercise, performance or what of the powers, duties or functions conferred, imposed or assigned b?', 'Answer': 'discharge', 'id': 1, 'context': 'In the exercise, performance or discharge of the powers, duties or functions, conferred, imposed or assigned b'}, {'Question': 'What is the purpose of the Act?', 'Answer': 'registration', 'id': 2, 'context': '(2) For the purposes of this Act, there may be appointed such number of persons, by name or by office, to be or to act as Registration Officers and Certifying Officers, and such number of other officers and servants, as may be necessary for such purposes. more persons, by name or by office, to be or to act as Assistant Commissioners for the Registration of Persons.'}, {'Question': 'What are the powers, duties and functions conferred, imposed or assigned by the officers?', 'Answer': 'duties', 'id': 3, 'context': 'In the exercise, performance or discharge of the powers, duties or functions, conferred, imposed or assigned b Powers and duties of officers.'}, {'Question': 'In what is the performance of powers, duties or functions conferred, imposed or assigned?', 'Answer': 'exercise', 'id': 4, 'context': 'In the exercise, performance or discharge of the powers, duties or functions, conferred, imposed or assigned b'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How do I delegate the powers of the Commissioner 5?', 'Answer': 'delegation', 'id': 1, 'context': 'Delegation of powers of the Commissioner 5.'}, {'Question': 'Who is the Commissioner subject to the general or special directions of?', 'Answer': 'minister', 'id': 2, 'context': 'y or under this Act (a) the Commissioner shall be subject to the general or special directions of the Minister; and (b) any Deputy Commissioner, any Assistant Commissioner, any Certifying Officer and any Registration Officer shall be subject to the general or special directions of the Commissioner.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the powers conferred upon the Commissioner by section 51?', 'Answer': 'offences', 'id': 1, 'context': 'xercise, perform or discharge any power, duty or function conferred or imposed upon, or assigned to, the Commissioner by or under this Act: Provided, however, that the preceding provisions of this section shall not apply to the power to compound offences conferred upon the Commissioner by section 51.'}, {'Question': 'Who is the Commissioner?', 'Answer': 'commissioner', 'id': 2, 'context': 'xercise, perform or discharge any power, duty or function conferred or imposed upon, or assigned to, the Commissioner by or under this Act: Provided, however, that the preceding provisions of this section shall not apply to the power to compound offences conferred upon the Commissioner by section 51. xercise, perform or discharge any power, duty or function conferred or imposed upon, or assigned to, the Commissioner by or under this Act: Provided, however, that the preceding provisions of this section shall not apply to the power to compound offences conferred upon the Commissioner by section 51. (2) Any Government Agent may, subject to the general direction and control of the Commissioner, exercise, perform or discharge any power, duty or function conferred or imposed upon, or assigned to, the Commissi'}, {'Question': 'What is the power conferred upon the Commissioner by this Act?', 'Answer': 'duty', 'id': 3, 'context': 'xercise, perform or discharge any power, duty or function conferred or imposed upon, or assigned to, the Commissioner by or under this Act: Provided, however, that the preceding provisions of this section shall not apply to the power to compound offences conferred upon the Commissioner by section 51. (2) Any Government Agent may, subject to the general direction and control of the Commissioner, exercise, perform or discharge any power, duty or function conferred or imposed upon, or assigned to, the Commissi'}, {'Question': 'What is the power of the Commissioner?', 'Answer': 'exercise', 'id': 4, 'context': '(2) Any Government Agent may, subject to the general direction and control of the Commissioner, exercise, perform or discharge any power, duty or function conferred or imposed upon, or assigned to, the Commissi'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is responsible for opening and maintaining the office of the Commissioner?', 'Answer': 'commissioner', 'id': 1, 'context': 'For the purposes of this Act, the Commissioner shall open and maintain, or Persons.'}, {'Question': 'What is the period within which persons liable to registration are required to apply for such registration?', 'Answer': 'registration', 'id': 2, 'context': 'Order appointing the period within which persons liable to registration are required to apply for such registration, 7. Order appointing the period within which persons liable to registration are required to apply for such registration, 7. PART II REGISTRATION OF PERSONS Register of 6.'}, {'Question': 'What is the Register of Persons?', 'Answer': 'act', 'id': 3, 'context': 'cause to be opened and maintained, a book to be called the \" Register of Persons \", in the prescribed form, in which persons shall be registered from time to time, under and in accordance with the provisions of this Act. For the purposes of this Act, the Commissioner shall open and maintain, or Persons. oner by or under this Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where can ter appoint a period within which persons liable to registration who are in any such district are required to apply for such registration under and in accordance with the provisions of this Act?', 'Answer': 'gazette', 'id': 1, 'context': 'ter may, by Order published in the Gazette, appoint, in respect of all districts, a period within which persons liable to registration who are in any such district are required to apply for such registration under and in accordance with the provisions of this Act.'}, {'Question': 'What may ter do in respect of all districts, a period within which persons liable to registration who are in any such district are required to apply for such registration under and in accordance with the provisions of this Act?', 'Answer': 'appoint', 'id': 2, 'context': 'ter may, by Order published in the Gazette, appoint, in respect of all districts, a period within which persons liable to registration who are in any such district are required to apply for such registration under and in accordance with the provisions of this Act.'}, {'Question': 'What is required of a person in any district to apply for?', 'Answer': 'registration', 'id': 3, 'context': 'ter may, by Order published in the Gazette, appoint, in respect of all districts, a period within which persons liable to registration who are in any such district are required to apply for such registration under and in accordance with the provisions of this Act. ter may, by Order published in the Gazette, appoint, in respect of all districts, a period within which persons liable to registration who are in any such district are required to apply for such registration under and in accordance with the provisions of this Act.'}, {'Question': 'What is the act that requires registration of persons in a district to apply under and in accordance with the provisions of?', 'Answer': 'act', 'id': 4, 'context': 'ter may, by Order published in the Gazette, appoint, in respect of all districts, a period within which persons liable to registration who are in any such district are required to apply for such registration under and in accordance with the provisions of this Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the language of the Tamil language?', 'Answer': 'tamil', 'id': 1, 'context': '(3) The Minister shall cause copies of any Order made under the preceding provisions of this section to be published in such Sinhala, Tamil and English newspapers, and to be exhibited in such conspicuous place or places in all or any districts, as he may deem best calculated to give publicity thereto.'}, {'Question': 'What shall be published in the Tamil and English newspapers?', 'Answer': 'copies', 'id': 2, 'context': '(3) The Minister shall cause copies of any Order made under the preceding provisions of this section to be published in such Sinhala, Tamil and English newspapers, and to be exhibited in such conspicuous place or places in all or any districts, as he may deem best calculated to give publicity thereto.'}, {'Question': 'What are the preceding provisions of this section?', 'Answer': 'provisions', 'id': 3, 'context': '(3) The Minister shall cause copies of any Order made under the preceding provisions of this section to be published in such Sinhala, Tamil and English newspapers, and to be exhibited in such conspicuous place or places in all or any districts, as he may deem best calculated to give publicity thereto.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How shall a person liable to registration apply for such registration under and in accordance with the provisions of this Act?', 'Answer': 'accordance', 'id': 1, 'context': 'e under this Act prescribing the period within which persons who are not liable to registration, but who subsequently become so liable, shall apply for such registration under and in accordance with the provisions of this Act. A person liable to registration shall, within the appropriate appointed period, apply for such registration under and in accordance with the provisions of this Act.'}, {'Question': 'Who is not liable to registration, but who subsequently become so liable, shall apply for such registration under and in accordance with the provisions of this Act?', 'Answer': 'persons', 'id': 2, 'context': 'e under this Act prescribing the period within which persons who are not liable to registration, but who subsequently become so liable, shall apply for such registration under and in accordance with the provisions of this Act.'}, {'Question': 'What is the period within which persons who are not liable to registration, but who subsequently become so liable, shall apply for such registration under and in accordance with the provisions of this Act?', 'Answer': 'act', 'id': 3, 'context': 'e under this Act prescribing the period within which persons who are not liable to registration, but who subsequently become so liable, shall apply for such registration under and in accordance with the provisions of this Act. e under this Act prescribing the period within which persons who are not liable to registration, but who subsequently become so liable, shall apply for such registration under and in accordance with the provisions of this Act. A person liable to registration shall, within the appropriate appointed period, apply for such registration under and in accordance with the provisions of this Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If the Minister is hereby authorized to fix by notification publishe what is the certificate of?', 'Answer': 'waiver', 'id': 1, 'context': '(2) Every application for registration (a) shall be in writing; (b) shall be in the prescribed form and shall contain the prescribed particulars; [2,28 of 1971] (bb) shall,- (i) if no certificate of waiver in respect of the fee for such registration which the Minister is hereby authorized to fix by notification publishe'}, {'Question': 'Who is the Commissioner?', 'Answer': 'government agent', 'id': 2, 'context': 'ry application for registration shall be addressed to the Commissioner, and shall be delivered to the appropriate Certifying Officer for transmission to the Commissioner or Government Agent.'}, {'Question': 'How is the application for registration delivered to the Commissioner or Government Agent?', 'Answer': 'transmission', 'id': 3, 'context': 'ry application for registration shall be addressed to the Commissioner, and shall be delivered to the appropriate Certifying Officer for transmission to the Commissioner or Government Agent.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What shall the Certifying Officer bear under the hand of the applicant?', 'Answer': 'endorsements', 'id': 1, 'context': 'd in the Gazette has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (c) shall be signed by the applicant; and (d) shall bear the prescribed endorsements under the hand of such Certifying Officer.'}, {'Question': 'Who shall be signed by the applicant?', 'Answer': 'applicant', 'id': 2, 'context': 'd in the Gazette has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (c) shall be signed by the applicant; and (d) shall bear the prescribed endorsements under the hand of such Certifying Officer. d in the Gazette has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (c) shall be signed by the applicant; and (d) shall bear the prescribed endorsements under the hand of such Certifying Officer. d in the Gazette has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (c) shall be signed by the applicant; and (d) shall bear the prescribed endorsements under the hand of such Certifying Officer.'}, {'Question': 'What should the applicant bear when a certificate has been issued to the applicant under this Act?', 'Answer': 'stamp', 'id': 3, 'context': 'd in the Gazette has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (c) shall be signed by the applicant; and (d) shall bear the prescribed endorsements under the hand of such Certifying Officer.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the care of a guardian or other person having the care and custody of a person?', 'Answer': 'custody', 'id': 1, 'context': 'made and signed on his behalf by his guardian or other person having the care and custody of such person.'}, {'Question': 'What are the dimensions, standards and quality of the photograph of the applicant?', 'Answer': 'specifications', 'id': 2, 'context': '(3) An application for registration shall be accompanied by three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality.'}, {'Question': 'What must be accompanied by three unmounted copies of an application for registration?', 'Answer': 'photograph', 'id': 3, 'context': '(3) An application for registration shall be accompanied by three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality.'}, {'Question': 'What are the dimensions, specifications, and quality of the photograph of the applicant?', 'Answer': 'standards', 'id': 4, 'context': '(3) An application for registration shall be accompanied by three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If an application is not returned to the applicant as required by paragraph (c) of this subsection, make a written what of the receipt of such application to the applicant?', 'Answer': 'acknowledgment', 'id': 1, 'context': 'ion, the appropriate Certifying Officer shall, (a) if such application is not returned to the applicant as required by paragraph (c) of this subsection, make a written acknowledgment of the receipt of such application to the applicant; and (b) if such application has been duly made under and in accordance with the provisions of this Act or any regulation made thereunder, transmit such application, within seven days of its receipt, to the Commissioner; or (c) if such application has not been so made, return'}, {'Question': 'If an application is not returned to the applicant as required by paragraph (c) of this subsection, make a written acknowledgment of what?', 'Answer': 'receipt', 'id': 2, 'context': 'ion, the appropriate Certifying Officer shall, (a) if such application is not returned to the applicant as required by paragraph (c) of this subsection, make a written acknowledgment of the receipt of such application to the applicant; and (b) if such application has been duly made under and in accordance with the provisions of this Act or any regulation made thereunder, transmit such application, within seven days of its receipt, to the Commissioner; or (c) if such application has not been so made, return ion, the appropriate Certifying Officer shall, (a) if such application is not returned to the applicant as required by paragraph (c) of this subsection, make a written acknowledgment of the receipt of such application to the applicant; and (b) if such application has been duly made under and in accordance with the provisions of this Act or any regulation made thereunder, transmit such application, within seven days of its receipt, to the Commissioner; or (c) if such application has not been so made, return'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who can reject an application for registration if it is not made under and in accordance with the provisions of this Act, or any regulation made thereunder?', 'Answer': 'commissioner', 'id': 1, 'context': '(1) An application for registration may be rejected by the Commissioner (a) if the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder; or [4,37 of 1971] (b) if the applicant is not a person liable to registration under this Act, or is not a person liable to such registration by virtue of paragraph (b) o Grounds on which application for registration may be rejected by the Commissioner.'}, {'Question': 'Who is not liable to registration under this Act?', 'Answer': 'applicant', 'id': 2, 'context': '(1) An application for registration may be rejected by the Commissioner (a) if the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder; or [4,37 of 1971] (b) if the applicant is not a person liable to registration under this Act, or is not a person liable to such registration by virtue of paragraph (b) o it to the applicant for compliance with such provisions.'}, {'Question': 'What is the only paragraph in this Act that can be used to determine whether an applicant is liable to registration under this Act?', 'Answer': 'paragraph', 'id': 3, 'context': '(1) An application for registration may be rejected by the Commissioner (a) if the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder; or [4,37 of 1971] (b) if the applicant is not a person liable to registration under this Act, or is not a person liable to such registration by virtue of paragraph (b) o'}, {'Question': 'If an application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder, or is not a person liable to such registration by virtue of paragraph (b) o (1) An application for what may be rejected by the Commissioner if the applicant is not a person liable under this Act, or is not a person liable to such registration by virtue of paragraph (b) o', 'Answer': 'registration', 'id': 4, 'context': '(1) An application for registration may be rejected by the Commissioner (a) if the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder; or [4,37 of 1971] (b) if the applicant is not a person liable to registration under this Act, or is not a person liable to such registration by virtue of paragraph (b) o (1) An application for registration may be rejected by the Commissioner (a) if the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder; or [4,37 of 1971] (b) if the applicant is not a person liable to registration under this Act, or is not a person liable to such registration by virtue of paragraph (b) o (1) An application for registration may be rejected by the Commissioner (a) if the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder; or [4,37 of 1971] (b) if the applicant is not a person liable to registration under this Act, or is not a person liable to such registration by virtue of paragraph (b) o'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who shall reject an application under section 37 if the applicant is already a registered person?', 'Answer': 'commissioner', 'id': 1, 'context': 'r paragraph (c) or paragraph (d) of subsection (1) of section 2, or paragraph (a) or paragraph (b) or paragraph (c) of subsection (2) of x that section; or [4,37 of 1971] (c) if the applicant is already a registered person; or (d) on the ground specified in section 37, and accordingly, no such application shall be rejected by the Commissioner except in any of the circumstances referred to in the preceding provisions of this section.'}, {'Question': 'Who is already a registered person?', 'Answer': 'applicant', 'id': 2, 'context': 'r paragraph (c) or paragraph (d) of subsection (1) of section 2, or paragraph (a) or paragraph (b) or paragraph (c) of subsection (2) of x that section; or [4,37 of 1971] (c) if the applicant is already a registered person; or (d) on the ground specified in section 37, and accordingly, no such application shall be rejected by the Commissioner except in any of the circumstances referred to in the preceding provisions of this section.'}, {'Question': 'What paragraph of subsection (1) of section 2 is a reference to the applicant being already a registered person?', 'Answer': 'paragraph', 'id': 3, 'context': 'r paragraph (c) or paragraph (d) of subsection (1) of section 2, or paragraph (a) or paragraph (b) or paragraph (c) of subsection (2) of x that section; or [4,37 of 1971] (c) if the applicant is already a registered person; or (d) on the ground specified in section 37, and accordingly, no such application shall be rejected by the Commissioner except in any of the circumstances referred to in the preceding provisions of this section. r paragraph (c) or paragraph (d) of subsection (1) of section 2, or paragraph (a) or paragraph (b) or paragraph (c) of subsection (2) of x that section; or [4,37 of 1971] (c) if the applicant is already a registered person; or (d) on the ground specified in section 37, and accordingly, no such application shall be rejected by the Commissioner except in any of the circumstances referred to in the preceding provisions of this section. r paragraph (c) or paragraph (d) of subsection (1) of section 2, or paragraph (a) or paragraph (b) or paragraph (c) of subsection (2) of x that section; or [4,37 of 1971] (c) if the applicant is already a registered person; or (d) on the ground specified in section 37, and accordingly, no such application shall be rejected by the Commissioner except in any of the circumstances referred to in the preceding provisions of this section.'}, {'Question': 'What section of section 2 is referred to as subsection (1) of section 2?', 'Answer': 'subsection', 'id': 4, 'context': 'r paragraph (c) or paragraph (d) of subsection (1) of section 2, or paragraph (a) or paragraph (b) or paragraph (c) of subsection (2) of x that section; or [4,37 of 1971] (c) if the applicant is already a registered person; or (d) on the ground specified in section 37, and accordingly, no such application shall be rejected by the Commissioner except in any of the circumstances referred to in the preceding provisions of this section. r paragraph (c) or paragraph (d) of subsection (1) of section 2, or paragraph (a) or paragraph (b) or paragraph (c) of subsection (2) of x that section; or [4,37 of 1971] (c) if the applicant is already a registered person; or (d) on the ground specified in section 37, and accordingly, no such application shall be rejected by the Commissioner except in any of the circumstances referred to in the preceding provisions of this section.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is responsible for a duplicate of an identity card being rejected by?', 'Answer': 'commissioner', 'id': 1, 'context': 'a duplicate of an identity card being rejected by the Commissioner it shall be his duty to inform the applicant in writing that such application has been rejected and such written information shall Include a statement of the grounds for such rejection. (3) Where the Commissioner rejects an application for registration in the circumstances specified in paragraph (a) or paragraph (d) of subsection (1), the applicant shall be entitled to make a fresh application for such registration under this Act.'}, {'Question': 'Who is required to inform the Commissioner in writing that the application has been rejected?', 'Answer': 'applicant', 'id': 2, 'context': 'a duplicate of an identity card being rejected by the Commissioner it shall be his duty to inform the applicant in writing that such application has been rejected and such written information shall Include a statement of the grounds for such rejection. (3) Where the Commissioner rejects an application for registration in the circumstances specified in paragraph (a) or paragraph (d) of subsection (1), the applicant shall be entitled to make a fresh application for such registration under this Act.'}, {'Question': 'If the Commissioner rejects an application for registration in the circumstances specified in paragraph (a) or paragraph (d) of subsection (1), the applicant shall be entitled to make a fresh application for registration under this Act.', 'Answer': 'paragraph', 'id': 3, 'context': '(3) Where the Commissioner rejects an application for registration in the circumstances specified in paragraph (a) or paragraph (d) of subsection (1), the applicant shall be entitled to make a fresh application for such registration under this Act. (3) Where the Commissioner rejects an application for registration in the circumstances specified in paragraph (a) or paragraph (d) of subsection (1), the applicant shall be entitled to make a fresh application for such registration under this Act.'}, {'Question': 'What is the reason for the rejection of a duplicate identity card?', 'Answer': 'rejection', 'id': 4, 'context': 'a duplicate of an identity card being rejected by the Commissioner it shall be his duty to inform the applicant in writing that such application has been rejected and such written information shall Include a statement of the grounds for such rejection.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'When can the Commissioner reject an application for registration?', 'Answer': 'receipt', 'id': 1, 'context': '(1) Upon the receipt of an application for registration, the Commissioner- (a) may reject the application on any ground referred to in section 10; or (b) if he does not so reject it, shall allow the application.'}, {'Question': 'What is prescribed in the Register of Persons?', 'Answer': 'particulars', 'id': 2, 'context': '(2) Where the Commissioner allows an application for registration, he shall register the applicant in the Register of Persons by entering in such Register the prescribed particulars relating to the applicant.'}, {'Question': 'What is the application for?', 'Answer': 'registration', 'id': 3, 'context': '(1) Upon the receipt of an application for registration, the Commissioner- (a) may reject the application on any ground referred to in section 10; or (b) if he does not so reject it, shall allow the application. (2) Where the Commissioner allows an application for registration, he shall register the applicant in the Register of Persons by entering in such Register the prescribed particulars relating to the applicant. of application for registration by the Commissioner.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What section of the Act is referred to as a registered person?', 'Answer': 'subsection', 'id': 1, 'context': 'A person registered under this subsection is in this Act referred to as a \" registered person \". f Persons under this subsection is in this Act referred to as a \"registration entry\".'}, {'Question': 'What is the process of a decision of the Commissi?', 'Answer': 'appeals', 'id': 2, 'context': 'Appeals to an appropriate against decisions of the Commissi'}, {'Question': 'What is served on the applicant if the Commissioner has not registered the applicant?', 'Answer': 'copy', 'id': 3, 'context': '(3) Where the Commissioner has, in consequence of his decision on any application for registration, registered the applicant, the Commissioner shall cause a copy of the registration entry relating to the applicant certified under his hand to be served on the applicant.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the term for application on registration?', 'Answer': 'oner', 'id': 1, 'context': 'oner on applications for registration.'}, {'Question': \"What is the finality of the Commissioner's decisions on applications for registration?\", 'Answer': 'finality', 'id': 2, 'context': 'Finality of decisions of the Commissioner on applications for registration.'}, {'Question': 'Any applicant who is aggrieved by the decision of the Commissioner on his application for registration may appeal that decision to any appropriate?', 'Answer': 'tribunal', 'id': 3, 'context': 'Any applicant for registration who is aggrieved by the decision of the Commissioner on his application for registration may, within a period of three weeks reckoned from the date on which for registration notice of such decision was served on such applicant, appeal against that decision to any appropriate Tribunal.'}, {'Question': 'Any applicant who is aggrieved by the decision of the Commissioner on his application for what may appeal against that decision to any appropriate Tribunal?', 'Answer': 'registration', 'id': 4, 'context': 'Any applicant for registration who is aggrieved by the decision of the Commissioner on his application for registration may, within a period of three weeks reckoned from the date on which for registration notice of such decision was served on such applicant, appeal against that decision to any appropriate Tribunal. Any applicant for registration who is aggrieved by the decision of the Commissioner on his application for registration may, within a period of three weeks reckoned from the date on which for registration notice of such decision was served on such applicant, appeal against that decision to any appropriate Tribunal. Any applicant for registration who is aggrieved by the decision of the Commissioner on his application for registration may, within a period of three weeks reckoned from the date on which for registration notice of such decision was served on such applicant, appeal against that decision to any appropriate Tribunal.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What does the Commissioner issue to a registered person as soon as practicable?', 'Answer': 'identity card', 'id': 1, 'context': 'The Commissioner shall, as soon as to practicable after a person becomes a registered person, issue to that person an identity card.'}, {'Question': 'If no appeal is preferred to an appropriate Tribunal within the period allowed by this Act, be final and conclusive?', 'Answer': 'therefor', 'id': 2, 'context': 'll, where no appeal against such decision is preferred to an appropriate Tribunal within the period allowed therefor by this Act, be final and conclusive.'}, {'Question': 'Where no appeal is preferred to an appropriate, judicial body within the period allowed by this Act, be final and conclusive?', 'Answer': 'tribunal', 'id': 3, 'context': 'll, where no appeal against such decision is preferred to an appropriate Tribunal within the period allowed therefor by this Act, be final and conclusive.'}, {'Question': 'Who issues an identity card to a registered person?', 'Answer': 'commissioner', 'id': 4, 'context': 'The Commissioner shall, as soon as to practicable after a person becomes a registered person, issue to that person an identity card.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the holder of an identity card?', 'Answer': 'identity card', 'id': 1, 'context': '(1) The holder of an identity card shall, on a Identity card to be produced when required.'}, {'Question': 'What is the signature of the Commissioner, the Deputy Commissioner, an Assistant Commissioner, or a Registration Officer?', 'Answer': 'facsimile', 'id': 2, 'context': 'rnished by that person along with his application for registration; and (c) shall bear the signature, or a facsimile of the signature, of the Commissioner, the Deputy Commissioner, an Assistant Commissioner, or a Registration Officer or, in lieu of, or in addition to, such signature or facsimile, a distinguishing mark imposed on that card by a machine or other device by or under the authority of the Commissioner. rnished by that person along with his application for registration; and (c) shall bear the signature, or a facsimile of the signature, of the Commissioner, the Deputy Commissioner, an Assistant Commissioner, or a Registration Officer or, in lieu of, or in addition to, such signature or facsimile, a distinguishing mark imposed on that card by a machine or other device by or under the authority of the Commissioner.'}, {'Question': 'Who is responsible for imposing a distinguishing mark on a card by a machine or other device?', 'Answer': 'commissioner', 'id': 3, 'context': 'rnished by that person along with his application for registration; and (c) shall bear the signature, or a facsimile of the signature, of the Commissioner, the Deputy Commissioner, an Assistant Commissioner, or a Registration Officer or, in lieu of, or in addition to, such signature or facsimile, a distinguishing mark imposed on that card by a machine or other device by or under the authority of the Commissioner. rnished by that person along with his application for registration; and (c) shall bear the signature, or a facsimile of the signature, of the Commissioner, the Deputy Commissioner, an Assistant Commissioner, or a Registration Officer or, in lieu of, or in addition to, such signature or facsimile, a distinguishing mark imposed on that card by a machine or other device by or under the authority of the Commissioner. rnished by that person along with his application for registration; and (c) shall bear the signature, or a facsimile of the signature, of the Commissioner, the Deputy Commissioner, an Assistant Commissioner, or a Registration Officer or, in lieu of, or in addition to, such signature or facsimile, a distinguishing mark imposed on that card by a machine or other device by or under the authority of the Commissioner.'}, {'Question': 'What shall a person bear along with his application for registration?', 'Answer': 'signature', 'id': 4, 'context': 'rnished by that person along with his application for registration; and (c) shall bear the signature, or a facsimile of the signature, of the Commissioner, the Deputy Commissioner, an Assistant Commissioner, or a Registration Officer or, in lieu of, or in addition to, such signature or facsimile, a distinguishing mark imposed on that card by a machine or other device by or under the authority of the Commissioner. rnished by that person along with his application for registration; and (c) shall bear the signature, or a facsimile of the signature, of the Commissioner, the Deputy Commissioner, an Assistant Commissioner, or a Registration Officer or, in lieu of, or in addition to, such signature or facsimile, a distinguishing mark imposed on that card by a machine or other device by or under the authority of the Commissioner. rnished by that person along with his application for registration; and (c) shall bear the signature, or a facsimile of the signature, of the Commissioner, the Deputy Commissioner, an Assistant Commissioner, or a Registration Officer or, in lieu of, or in addition to, such signature or facsimile, a distinguishing mark imposed on that card by a machine or other device by or under the authority of the Commissioner.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is responsible for obtaining the identity card at the time of the request?', 'Answer': 'commissioner', 'id': 1, 'context': 'request made by the Commissioner or any other prescribed officer, produce that card at such time and place as shall be specified in such request, and permit it to be inspected : Provided, however, that no person shall be deemed to have contravened the preceding provisions of this section, if his identity card had, at the time of the alleged contravention, been lost and he has complied with the provisions of subsection (1) of section 16 relating to the reporting of such loss to the nearest police station, an'}, {'Question': 'What section of section 16 relates to the reporting of loss of identity card to the nearest police station?', 'Answer': 'subsection', 'id': 2, 'context': 'request made by the Commissioner or any other prescribed officer, produce that card at such time and place as shall be specified in such request, and permit it to be inspected : Provided, however, that no person shall be deemed to have contravened the preceding provisions of this section, if his identity card had, at the time of the alleged contravention, been lost and he has complied with the provisions of subsection (1) of section 16 relating to the reporting of such loss to the nearest police station, an'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the rank of an officer not below that of an Assistant Superintendent?', 'Answer': 'police officer', 'id': 1, 'context': '(2) If in any prosecution against any person for an offence under this Act by reason of a contravention of the provisions of subsection (1), there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent or any such public officer as may be notified for such purpose by the Minister from time to time in the Gazette,'}, {'Question': 'What is the reason for prosecution under this Act?', 'Answer': 'contravention', 'id': 2, 'context': '(2) If in any prosecution against any person for an offence under this Act by reason of a contravention of the provisions of subsection (1), there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent or any such public officer as may be notified for such purpose by the Minister from time to time in the Gazette,'}, {'Question': 'What is a violation of subsection (1) of the Act?', 'Answer': 'offence', 'id': 3, 'context': '(2) If in any prosecution against any person for an offence under this Act by reason of a contravention of the provisions of subsection (1), there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent or any such public officer as may be notified for such purpose by the Minister from time to time in the Gazette,'}, {'Question': 'Who is responsible for a prosecution under this Act by reason of a contravention of subsection (1)?', 'Answer': 'commissioner', 'id': 4, 'context': '(2) If in any prosecution against any person for an offence under this Act by reason of a contravention of the provisions of subsection (1), there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent or any such public officer as may be notified for such purpose by the Minister from time to time in the Gazette, (2) If in any prosecution against any person for an offence under this Act by reason of a contravention of the provisions of subsection (1), there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent or any such public officer as may be notified for such purpose by the Minister from time to time in the Gazette, (2) If in any prosecution against any person for an offence under this Act by reason of a contravention of the provisions of subsection (1), there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent or any such public officer as may be notified for such purpose by the Minister from time to time in the Gazette,'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person is satisfied that he is the holder of an identity card, it shall be presumed, until the contrary is proved by such person, that such person is the holder of such card- issue of duplicate identity card in case of loss of original.', 'Answer': 'identity card', 'id': 1, 'context': 'to the effect that he is satisfied that such person is the holder of an identity card, it shall be presumed, until the contrary is proved by such person, that such person is the holder of such card- issue of duplicate identity card in case of loss of original. to the effect that he is satisfied that such person is the holder of an identity card, it shall be presumed, until the contrary is proved by such person, that such person is the holder of such card- issue of duplicate identity card in case of loss of original. (1) Any person who has lost his identity card shall immediately report such loss to the nearest police station, and shall thereafter forthwith apply to the Commissioner for a duplicate of that identity card.'}, {'Question': 'Who must a person who lost his identity card immediately report the loss to?', 'Answer': 'police station', 'id': 2, 'context': '(1) Any person who has lost his identity card shall immediately report such loss to the nearest police station, and shall thereafter forthwith apply to the Commissioner for a duplicate of that identity card.'}, {'Question': 'Who can a person who lost his identity card apply to for a duplicate of his identity card?', 'Answer': 'commissioner', 'id': 3, 'context': '(1) Any person who has lost his identity card shall immediately report such loss to the nearest police station, and shall thereafter forthwith apply to the Commissioner for a duplicate of that identity card.'}, {'Question': 'If a person is satisfied that he is the holder of an identity card, it shall be presumed, until the contrary is proved by such person, that such person is the holder of such card- issue of duplicate identity card in case of loss of original.', 'Answer': 'holder', 'id': 4, 'context': 'to the effect that he is satisfied that such person is the holder of an identity card, it shall be presumed, until the contrary is proved by such person, that such person is the holder of such card- issue of duplicate identity card in case of loss of original. to the effect that he is satisfied that such person is the holder of an identity card, it shall be presumed, until the contrary is proved by such person, that such person is the holder of such card- issue of duplicate identity card in case of loss of original.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If no certificate of what in respect of the fee for the issue of such duplicate has been issued to the applicant under this Act, bear a stamp or stamps of such fee; or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; or (c) shall be signed by what in respect of the fee for the issue of such duplicate which the Minister is hereby authorized to fix by notification published in the Gazette; or (ii) if no certificate of such fee has', 'Answer': 'waiver', 'id': 1, 'context': 'n identity card under this section (a) shall be made in the prescribed form: [ 3, 28 of 1971] (b) shall (i) if no certificate of waiver in respect of the fee for the issue of such duplicate which the Minister is hereby authorized to fix by notification published in the Gazette has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee; or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (c) shall be signed by'}, {'Question': 'If no certificate of waiver in respect of the fee for the issue of such duplicate which the Minister is hereby authorized to fix by notification published in the Gazette has been issued to the applicant under this Act, bear a stamp or stamps of such value; or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; or (c) shall be signed by?', 'Answer': 'duplicate', 'id': 2, 'context': 'n identity card under this section (a) shall be made in the prescribed form: [ 3, 28 of 1971] (b) shall (i) if no certificate of waiver in respect of the fee for the issue of such duplicate which the Minister is hereby authorized to fix by notification published in the Gazette has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee; or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (c) shall be signed by'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the prescribed dimensions, standards and quality of the photograph of the applicant?', 'Answer': 'specifications', 'id': 1, 'context': 'the applicant; and (d) shall be accompanied by a certified copy of the relevant extract of the information book of the police station to which the loss of the original of such card was reported by the applicant, and three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality.'}, {'Question': 'What is the photograph of the applicant of the prescribed dimensions, specifications, standards and quality?', 'Answer': 'photograph', 'id': 2, 'context': 'the applicant; and (d) shall be accompanied by a certified copy of the relevant extract of the information book of the police station to which the loss of the original of such card was reported by the applicant, and three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality.'}, {'Question': 'What is the original of the identity card?', 'Answer': 'card', 'id': 3, 'context': 'the applicant; and (d) shall be accompanied by a certified copy of the relevant extract of the information book of the police station to which the loss of the original of such card was reported by the applicant, and three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality. [3,28 of 1971] (3) Upon the receipt of an application for the issue of a duplicate of an identity card made under and in accordance with the preceding provisions of this s'}, {'Question': 'What is the original of the police station card that the applicant lost?', 'Answer': 'copy', 'id': 4, 'context': 'the applicant; and (d) shall be accompanied by a certified copy of the relevant extract of the information book of the police station to which the loss of the original of such card was reported by the applicant, and three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How do you report an identity card that is damaged, defaced, or illegible?', 'Answer': 'forthwith', 'id': 1, 'context': '(1) Where an identity card is damaged, defaced, or illegible or in danger of becoming illegible, the holder of that card shall forthwith (a) report that fact in writing to the Commissioner; and (b) ap'}, {'Question': 'Who shall issue duplicate ID cards to applicants unless he rejects them on the ground that the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder?', 'Answer': 'commissioner', 'id': 2, 'context': 'ection, the Commissioner shall issue such duplicate to the applicant unless he rejects such application upon the ground that the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder. (1) Where an identity card is damaged, defaced, or illegible or in danger of becoming illegible, the holder of that card shall forthwith (a) report that fact in writing to the Commissioner; and (b) ap'}, {'Question': 'Who is the applicant unless the Commissioner rejects the application on the ground that the application is not made under and in accordance with the provisions of this Act?', 'Answer': 'applicant', 'id': 3, 'context': 'ection, the Commissioner shall issue such duplicate to the applicant unless he rejects such application upon the ground that the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder.'}, {'Question': 'If an identity card is damaged, defaced, or illegible or in danger of becoming illegible, the holder of that card shall forthwith (a) report that fact in writing to the Commissioner; and (b) ap Issue of duplicate case of card in damage, amp c, of original?', 'Answer': 'card', 'id': 4, 'context': '(1) Where an identity card is damaged, defaced, or illegible or in danger of becoming illegible, the holder of that card shall forthwith (a) report that fact in writing to the Commissioner; and (b) ap (1) Where an identity card is damaged, defaced, or illegible or in danger of becoming illegible, the holder of that card shall forthwith (a) report that fact in writing to the Commissioner; and (b) ap Issue of duplicate case of card in damage, amp c, of original.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If no certificate of what in respect of the fee for the issue of a duplicate of an identity card has been issued to the applicant under this Act, bear a stamp or stamps the value of such fee; or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; or (b) shall be a certificate of what in respect of the fee for the issue of a duplicate of such card; or (ii) if no certificate has been issued to the applicant,', 'Answer': 'waiver', 'id': 1, 'context': '(2) An application for a duplicate of an identity card under this section (a) shall be in the prescribed form; [4,28 of 1971] (aa) shall, (i) if no certificate of waiver in respect of the fee for the issue of a duplicate of such card has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee; or(ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (b) shall be s'}, {'Question': 'What is the fee for the issue of a duplicate card under this section?', 'Answer': 'duplicate', 'id': 2, 'context': '(2) An application for a duplicate of an identity card under this section (a) shall be in the prescribed form; [4,28 of 1971] (aa) shall, (i) if no certificate of waiver in respect of the fee for the issue of a duplicate of such card has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee; or(ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (b) shall be s (2) An application for a duplicate of an identity card under this section (a) shall be in the prescribed form; [4,28 of 1971] (aa) shall, (i) if no certificate of waiver in respect of the fee for the issue of a duplicate of such card has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee; or(ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (b) shall be s ply to the Commissioner for a duplicate of that card.'}, {'Question': 'If no certificate of waiver in respect of the fee for the issue of a duplicate of such card has been issued to the applicant under this Act, bear a what?', 'Answer': 'stamp', 'id': 3, 'context': '(2) An application for a duplicate of an identity card under this section (a) shall be in the prescribed form; [4,28 of 1971] (aa) shall, (i) if no certificate of waiver in respect of the fee for the issue of a duplicate of such card has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee; or(ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (b) shall be s'}, {'Question': 'If no certificate of waiver in respect of the issue of a duplicate of an identity card has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee; or (ii) if such certificate has been issued to the applicant, have such certificate attached to the application; or (b) shall be s (2) An application for a duplicate of an identity card under this section shall be in the prescribed form; [4,28 of 1971] (aa) shall bear a stamp or', 'Answer': 'fee', 'id': 4, 'context': '(2) An application for a duplicate of an identity card under this section (a) shall be in the prescribed form; [4,28 of 1971] (aa) shall, (i) if no certificate of waiver in respect of the fee for the issue of a duplicate of such card has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee; or(ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (b) shall be s (2) An application for a duplicate of an identity card under this section (a) shall be in the prescribed form; [4,28 of 1971] (aa) shall, (i) if no certificate of waiver in respect of the fee for the issue of a duplicate of such card has been issued to the applicant under this Act, bear a stamp or stamps of the value of such fee; or(ii) if such certificate has been issued to the applicant, have such certificate attached to the application; (b) shall be s'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the dimensions of the photograph of the applicant, standards and quality, and the original of the card?', 'Answer': 'specifications', 'id': 1, 'context': 'igned by the applicant; and [4,28 of 1971] (c) shall be accompanied by three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality, and the original of that card.'}, {'Question': \"What must be accompanied by three unmounted copies of the applicant's photograph of the prescribed dimensions, specifications, standards and quality, and the original of that card?\", 'Answer': 'photograph', 'id': 2, 'context': 'igned by the applicant; and [4,28 of 1971] (c) shall be accompanied by three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality, and the original of that card.'}, {'Question': 'What is the original of the identity card?', 'Answer': 'card', 'id': 3, 'context': '[6,37 of 1971] (3) No application for the issue of a duplicate identity card shall be refused by the Commissioner except upon the ground that the application is not made under and in accordance with the provisions of this Act, or any regulation made thereunder. igned by the applicant; and [4,28 of 1971] (c) shall be accompanied by three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality, and the original of that card.'}, {'Question': 'What is the original of the card?', 'Answer': 'original', 'id': 4, 'context': 'igned by the applicant; and [4,28 of 1971] (c) shall be accompanied by three unmounted copies of a photograph of the applicant of the prescribed dimensions, specifications, standards and quality, and the original of that card.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the new identity cards that replace existing cards?', 'Answer': 'identity cards', 'id': 1, 'context': 'made under this Act providing for the issue by the Commissioner upon the expiration of each such period of time as may be specified therein to the holders of existing identity cards of new identity cards in replacement of such existing cards. made under this Act providing for the issue by the Commissioner upon the expiration of each such period of time as may be specified therein to the holders of existing identity cards of new identity cards in replacement of such existing cards. Such regulations may contain provisions similar or substantially similar to the provisions made by this Act in relation to the issue of duplicate identity cards.'}, {'Question': 'What is the purpose of new identity cards?', 'Answer': 'replacement', 'id': 2, 'context': 'made under this Act providing for the issue by the Commissioner upon the expiration of each such period of time as may be specified therein to the holders of existing identity cards of new identity cards in replacement of such existing cards.'}, {'Question': 'What may be similar or substantially similar to the provisions made by this Act in relation to the issue of duplicate identity cards?', 'Answer': 'provisions', 'id': 3, 'context': 'Such regulations may contain provisions similar or substantially similar to the provisions made by this Act in relation to the issue of duplicate identity cards. Such regulations may contain provisions similar or substantially similar to the provisions made by this Act in relation to the issue of duplicate identity cards.'}, {'Question': 'What is the purpose of the new identity cards?', 'Answer': 'issue', 'id': 4, 'context': 'made under this Act providing for the issue by the Commissioner upon the expiration of each such period of time as may be specified therein to the holders of existing identity cards of new identity cards in replacement of such existing cards. Such regulations may contain provisions similar or substantially similar to the provisions made by this Act in relation to the issue of duplicate identity cards.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How do you inform the police station referred to in section 16 and the Commissioner of the fact of such recovery?', 'Answer': 'forthwith', 'id': 1, 'context': 's possession of that card, such person shall, (a) if the provisions of subsection (1) of section 16 have been complied with by such person prior to such recovery, forthwith inform the police station referred to in that subsection, and the Commissioner of the fact of such recovery; and (b) if a duplicate of that card had been issued to him prior to such recovery, surrender the original of that card to the Commissioner for cancellation within the prescribed period.'}, {'Question': 'If a person has a duplicate of a card issued to him prior to recovery, where do they notify the Commissioner of the fact of such recovery?', 'Answer': 'police station', 'id': 2, 'context': 's possession of that card, such person shall, (a) if the provisions of subsection (1) of section 16 have been complied with by such person prior to such recovery, forthwith inform the police station referred to in that subsection, and the Commissioner of the fact of such recovery; and (b) if a duplicate of that card had been issued to him prior to such recovery, surrender the original of that card to the Commissioner for cancellation within the prescribed period.'}, {'Question': 'Who must surrender the original of a card if a duplicate of the card has been issued to him prior to recovery?', 'Answer': 'commissioner', 'id': 3, 'context': 's possession of that card, such person shall, (a) if the provisions of subsection (1) of section 16 have been complied with by such person prior to such recovery, forthwith inform the police station referred to in that subsection, and the Commissioner of the fact of such recovery; and (b) if a duplicate of that card had been issued to him prior to such recovery, surrender the original of that card to the Commissioner for cancellation within the prescribed period. s possession of that card, such person shall, (a) if the provisions of subsection (1) of section 16 have been complied with by such person prior to such recovery, forthwith inform the police station referred to in that subsection, and the Commissioner of the fact of such recovery; and (b) if a duplicate of that card had been issued to him prior to such recovery, surrender the original of that card to the Commissioner for cancellation within the prescribed period.'}, {'Question': 'If a duplicate of that card had been issued to him prior to such recovery, surrender the original of that card to the Commissioner for cancellation within the prescribed period.', 'Answer': 'card', 'id': 4, 'context': 's possession of that card, such person shall, (a) if the provisions of subsection (1) of section 16 have been complied with by such person prior to such recovery, forthwith inform the police station referred to in that subsection, and the Commissioner of the fact of such recovery; and (b) if a duplicate of that card had been issued to him prior to such recovery, surrender the original of that card to the Commissioner for cancellation within the prescribed period. s possession of that card, such person shall, (a) if the provisions of subsection (1) of section 16 have been complied with by such person prior to such recovery, forthwith inform the police station referred to in that subsection, and the Commissioner of the fact of such recovery; and (b) if a duplicate of that card had been issued to him prior to such recovery, surrender the original of that card to the Commissioner for cancellation within the prescribed period. s possession of that card, such person shall, (a) if the provisions of subsection (1) of section 16 have been complied with by such person prior to such recovery, forthwith inform the police station referred to in that subsection, and the Commissioner of the fact of such recovery; and (b) if a duplicate of that card had been issued to him prior to such recovery, surrender the original of that card to the Commissioner for cancellation within the prescribed period.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the card that is surrendered in the event of the death of the holder of?', 'Answer': 'identity card', 'id': 1, 'context': '(1) In the event of the death of the holder of an identity card, the person having the custody of that card shall forthwith surrender it to the Registrar of Deaths to whom the occurrence of that death is reported, and such Registrar shall, upon such surrender, transmit that card to the Commissioner. Surrender of an identity card.'}, {'Question': 'Where can I surrender my card to?', 'Answer': 'police station', 'id': 2, 'context': 'ich was not issued to him shall forthwith surrender that card to the Commissioner or the nearest police station.'}, {'Question': 'What is the person who has custody of the identity card?', 'Answer': 'custody', 'id': 3, 'context': '(1) In the event of the death of the holder of an identity card, the person having the custody of that card shall forthwith surrender it to the Registrar of Deaths to whom the occurrence of that death is reported, and such Registrar shall, upon such surrender, transmit that card to the Commissioner.'}, {'Question': 'Who shall the Registrar of Deaths transmit the card to upon the surrender?', 'Answer': 'commissioner', 'id': 4, 'context': '(1) In the event of the death of the holder of an identity card, the person having the custody of that card shall forthwith surrender it to the Registrar of Deaths to whom the occurrence of that death is reported, and such Registrar shall, upon such surrender, transmit that card to the Commissioner. ich was not issued to him shall forthwith surrender that card to the Commissioner or the nearest police station.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the duplicates of?', 'Answer': 'identity cards', 'id': 1, 'context': 'Appeals to an appropriate Tribunal against decisions of the Commissioner on applications for duplicates of identity cards. rrender of identity cards by persons leaving Sri Lanka permanently.'}, {'Question': 'Where can I get my identity card from if I leave Sri Lanka permanently?', 'Answer': 'sri lanka', 'id': 2, 'context': 'rrender of identity cards by persons leaving Sri Lanka permanently.'}, {'Question': 'Who is aggrieved by the decision of the applicant for the duplicate of an identity card?', 'Answer': 'commissioner', 'id': 3, 'context': 'An applicant for the duplicate of an identity card who is aggrieved by the decision of the Commissioner on such application may, within a period of three weeks reckoned from the date on which notice of such decision was served on such applicant, appeal against that decision to an appropriate Tribunal. Appeals to an appropriate Tribunal against decisions of the Commissioner on applications for duplicates of identity cards.'}, {'Question': \"What is the process of a Commissioner's decision on duplicate identity cards?\", 'Answer': 'appeals', 'id': 4, 'context': 'Appeals to an appropriate Tribunal against decisions of the Commissioner on applications for duplicates of identity cards.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are duplicates of?', 'Answer': 'identity cards', 'id': 1, 'context': 'cisions of the Commissioner on applications for duplicates of identity cards.'}, {'Question': 'If no appeal is preferred to an appropriate Tribunal within the period allowed by this Act, the decision of the Commissioner on any application for a duplicate of an identity card shall be final and conclusive.', 'Answer': 'therefor', 'id': 2, 'context': 'The decision of the Commissioner on any application for a duplicate of an identity card shall, where no appeal against such decision is preferred to an appropriate Tribunal within the period allowed therefor by this Act, be final and conclusive.'}, {'Question': 'Where no appeal is preferred against the decision of the Commissioner on any application for a duplicate of an identity card, the decision of the Commissioner shall be final and conclusive and shall be final and conclusive?', 'Answer': 'tribunal', 'id': 3, 'context': 'The decision of the Commissioner on any application for a duplicate of an identity card shall, where no appeal against such decision is preferred to an appropriate Tribunal within the period allowed therefor by this Act, be final and conclusive.'}, {'Question': 'Who makes decisions on duplicate identity cards?', 'Answer': 'commissioner', 'id': 4, 'context': 'The decision of the Commissioner on any application for a duplicate of an identity card shall, where no appeal against such decision is preferred to an appropriate Tribunal within the period allowed therefor by this Act, be final and conclusive. cisions of the Commissioner on applications for duplicates of identity cards.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is a transferor or transferee, assignor or assignee of under subsection (1)?', 'Answer': 'identity card', 'id': 1, 'context': '[5, 28 of 1971] (3) Any transferor or transferee, assignor or assignee of an identity card under subsection (1), or any person who has damaged or defaced or in any way altered or changed the character thereof, or made any unauthorized duplicate thereof, un [5,28 of 1971] (2) No person shall cause damage to, or deface, or in any way alter or change the character of, any identity card, or make any unauthorized duplicate of such card.'}, {'Question': 'Who is the transferor or transferee of an identity card under subsection (1), or any person who has damaged or defaced or in any way altered or changed the character thereof, or made any unauthorized duplicate thereof?', 'Answer': 'transferee', 'id': 2, 'context': '[5, 28 of 1971] (3) Any transferor or transferee, assignor or assignee of an identity card under subsection (1), or any person who has damaged or defaced or in any way altered or changed the character thereof, or made any unauthorized duplicate thereof, un'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the newest identity card?', 'Answer': 'identity card', 'id': 1, 'context': 'Alteration of identity card 23.'}, {'Question': 'What is the term for a mark, end?', 'Answer': 'endorsement', 'id': 2, 'context': '(1) No person, other than the Commissioner or any other officer, acting in the course of his duty as such, shall make any mark, endorsement, or entry upon, or erase, cancel or alter any such mark, end'}, {'Question': 'What is the purpose of identity card 23?', 'Answer': 'alteration', 'id': 3, 'context': 'Alteration of identity card 23.'}, {'Question': 'What is a mark?', 'Answer': 'mark', 'id': 4, 'context': '(1) No person, other than the Commissioner or any other officer, acting in the course of his duty as such, shall make any mark, endorsement, or entry upon, or erase, cancel or alter any such mark, end (1) No person, other than the Commissioner or any other officer, acting in the course of his duty as such, shall make any mark, endorsement, or entry upon, or erase, cancel or alter any such mark, end'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the card that the Commissioner may issue to a person?', 'Answer': 'identity card', 'id': 1, 'context': 'The Commissioner shall not issue more than one identity card to any person, notwithstanding that such person, whether by inadvertence or otherwise, is re orsement or entry contained in, any identity card, or otherwise deface or destroy such card. Not more than one identity card to be issued to any person.'}, {'Question': 'What is the term for a deletion, cancellation, or alteration of a mark, endorsement, or entry?', 'Answer': 'erasure', 'id': 2, 'context': '(2) Any mark, endorsement, or entry, or any erasure, cancellation or alteration, referred to in subsection (1) shall be properly authenticated by the Commissioner or other officer responsible therefor.'}, {'Question': 'What is the purpose of the erasure, cancellation or alteration of any mark, endorsement, or entry, or any erasure, cancellation or alteration, referred to in subsection (1)?', 'Answer': 'therefor', 'id': 3, 'context': '(2) Any mark, endorsement, or entry, or any erasure, cancellation or alteration, referred to in subsection (1) shall be properly authenticated by the Commissioner or other officer responsible therefor.'}, {'Question': 'What is the process of erasure, alteration, or erasure referred to in subsection (1)?', 'Answer': 'cancellation', 'id': 4, 'context': '(2) Any mark, endorsement, or entry, or any erasure, cancellation or alteration, referred to in subsection (1) shall be properly authenticated by the Commissioner or other officer responsible therefor.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the reason for the invalidity of a card issued by the Commissioner in the Register of Persons?', 'Answer': 'contravention', 'id': 1, 'context': 'gistered more than once in the Register of Persons; and accordingly any such card issued by the Commissioner in contravention of the preceding provisions of this section shall be invalid and of no effect for the purposes of this Act.'}, {'Question': 'Who issued the card that is invalid and of no effect for the purposes of this Act?', 'Answer': 'commissioner', 'id': 2, 'context': 'gistered more than once in the Register of Persons; and accordingly any such card issued by the Commissioner in contravention of the preceding provisions of this section shall be invalid and of no effect for the purposes of this Act.'}, {'Question': 'What is invalid and of no effect for the purposes of this Act?', 'Answer': 'card', 'id': 3, 'context': 'gistered more than once in the Register of Persons; and accordingly any such card issued by the Commissioner in contravention of the preceding provisions of this section shall be invalid and of no effect for the purposes of this Act.'}, {'Question': 'Who is registered in the Register of Persons?', 'Answer': 'persons', 'id': 4, 'context': 'gistered more than once in the Register of Persons; and accordingly any such card issued by the Commissioner in contravention of the preceding provisions of this section shall be invalid and of no effect for the purposes of this Act. PART IV REGISTRATION OF PERSONS TRIBUNALS Registration of persons Tribunals. PART IV REGISTRATION OF PERSONS TRIBUNALS Registration of persons Tribunals.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the tribunals that are necessary for the purposes of this Act?', 'Answer': 'tribunals', 'id': 1, 'context': 'ns Tribunals as may be necessary for the purposes of this Act.'}, {'Question': \"What is the reason for an appeal against the Commissioner's decision on any application for registration?\", 'Answer': 'duplicate', 'id': 2, 'context': 'Every appeal against the decision of the Commissioner on any application for registration, or for the duplicate of an identity card, made to any app'}, {'Question': 'Who decides whether or not to issue a duplicate identity card?', 'Answer': 'commissioner', 'id': 3, 'context': 'Every appeal against the decision of the Commissioner on any application for registration, or for the duplicate of an identity card, made to any app'}, {'Question': 'What is the application for a duplicate identity card?', 'Answer': 'registration', 'id': 4, 'context': 'Every appeal against the decision of the Commissioner on any application for registration, or for the duplicate of an identity card, made to any app'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How does the record of the proceedings before the Tribunal relate to the entertaining, hearing and deciding of every appeal made to the Tribunal under this Act?', 'Answer': 'relate', 'id': 1, 'context': 'A Tribunal shall keep a record of all such proceedings before the Tribunal as relate to the entertaining, hearing and deciding of every appeal made to the Tribunal under this Act.'}, {'Question': 'What is the record of all the proceedings before the Tribunal that relate to the entertaining, hearing and deciding of every appeal made to the Tribunal under this Act?', 'Answer': 'proceedings', 'id': 2, 'context': 'A Tribunal shall keep a record of all such proceedings before the Tribunal as relate to the entertaining, hearing and deciding of every appeal made to the Tribunal under this Act. Record of proceedings before a Tribunal., 27.'}, {'Question': 'Who is summoned?', 'Answer': 'witnesses', 'id': 3, 'context': 'Power to summon witnesses.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the most common oath that a witness can take?', 'Answer': 'affirmation', 'id': 1, 'context': 'summon and compel the attendance of witnesses; (b) to compel the production of documents; and (c) to administer any oath or affirmation to witnesses.'}, {'Question': 'Who shall be bound to slate the truth on any matter before a tribunal under this Act?', 'Answer': 'tribunal', 'id': 2, 'context': 'Every person giving evidence on any matter before a Tribunal shall be bound to slate the truth on such matter. Every decision of a Tribunal on any appeal made to the Tribunal under this Act shall con Every decision of a Tribunal on any appeal made to the Tribunal under this Act shall con'}, {'Question': 'What is the most important oath that a witness can take?', 'Answer': 'oath', 'id': 3, 'context': 'summon and compel the attendance of witnesses; (b) to compel the production of documents; and (c) to administer any oath or affirmation to witnesses.'}, {'Question': 'Who do I summon and compel to attend?', 'Answer': 'witnesses', 'id': 4, 'context': 'summon and compel the attendance of witnesses; (b) to compel the production of documents; and (c) to administer any oath or affirmation to witnesses. summon and compel the attendance of witnesses; (b) to compel the production of documents; and (c) to administer any oath or affirmation to witnesses.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who determines the amount of the costs of an appeal made to the Tribunal under this Act?', 'Answer': 'tribunal', 'id': 1, 'context': 'The decision of a Tribunal on any appeal made to the Tribunal under this Act shall, unless for special reason the Tribunal directs otherwise, contain an order as to the person who is to pay the cost of the proceedings relating to the appeal and shall determine the amount of such costs. The decision of a Tribunal on any appeal made to the Tribunal under this Act shall, unless for special reason the Tribunal directs otherwise, contain an order as to the person who is to pay the cost of the proceedings relating to the appeal and shall determine the amount of such costs. The decision of a Tribunal on any appeal made to the Tribunal under this Act shall, unless for special reason the Tribunal directs otherwise, contain an order as to the person who is to pay the cost of the proceedings relating to the appeal and shall determine the amount of such costs.'}, {'Question': 'What are the costs of an appeal before a Tribunal under this Act?', 'Answer': 'proceedings', 'id': 2, 'context': 'The decision of a Tribunal on any appeal made to the Tribunal under this Act shall, unless for special reason the Tribunal directs otherwise, contain an order as to the person who is to pay the cost of the proceedings relating to the appeal and shall determine the amount of such costs. (1) The proceedings before a Tribunal on any appeal made to the Tribunal under this Act shall as far as poss Costs of proceedings before a Tribunal.'}, {'Question': 'The decision of a Tribunal on any appeal made to the Tribunal under this Act shall, unless for special reason the Tribunal directs otherwise, contain an order as to the person who is to pay the cost of the proceedings relating to the appeal and shall determine the amount of such costs.', 'Answer': 'appeal', 'id': 3, 'context': 'The decision of a Tribunal on any appeal made to the Tribunal under this Act shall, unless for special reason the Tribunal directs otherwise, contain an order as to the person who is to pay the cost of the proceedings relating to the appeal and shall determine the amount of such costs. The decision of a Tribunal on any appeal made to the Tribunal under this Act shall, unless for special reason the Tribunal directs otherwise, contain an order as to the person who is to pay the cost of the proceedings relating to the appeal and shall determine the amount of such costs. (1) The proceedings before a Tribunal on any appeal made to the Tribunal under this Act shall as far as poss'}, {'Question': 'What is the order of the person who is to pay the costs of the proceedings relating to the appeal?', 'Answer': 'decision', 'id': 4, 'context': 'The decision of a Tribunal on any appeal made to the Tribunal under this Act shall, unless for special reason the Tribunal directs otherwise, contain an order as to the person who is to pay the cost of the proceedings relating to the appeal and shall determine the amount of such costs.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the formalities and the rules of procedure and evidence normally applicable to a court of law?', 'Answer': 'technicalities', 'id': 1, 'context': 'ible be free from the formalities and technicalities of the rules of procedure and evidence ordinarily or normally applicable to a court of law, and may be conducted by the Tribunal in any manner, not inconsistent with the principles of natural justice, which to the Tribunal may seem best adapted to elicit proof concerning the matters that are being investigated.'}, {'Question': 'What is the best way to conduct a case under this Act?', 'Answer': 'tribunal', 'id': 2, 'context': 'ible be free from the formalities and technicalities of the rules of procedure and evidence ordinarily or normally applicable to a court of law, and may be conducted by the Tribunal in any manner, not inconsistent with the principles of natural justice, which to the Tribunal may seem best adapted to elicit proof concerning the matters that are being investigated. ible be free from the formalities and technicalities of the rules of procedure and evidence ordinarily or normally applicable to a court of law, and may be conducted by the Tribunal in any manner, not inconsistent with the principles of natural justice, which to the Tribunal may seem best adapted to elicit proof concerning the matters that are being investigated. (2) Subject to the provisions of this Act, the practice and procedure to be followed in the making of any appeal to a Tribunal under this Act, and'}, {'Question': 'What are the procedures and practices to be followed in the making of any appeal to a Tribunal under this Act?', 'Answer': 'provisions', 'id': 3, 'context': '(2) Subject to the provisions of this Act, the practice and procedure to be followed in the making of any appeal to a Tribunal under this Act, and'}, {'Question': 'What is the procedure to be followed in the making of any appeal to a Tribunal under this Act?', 'Answer': 'procedure', 'id': 4, 'context': 'ible be free from the formalities and technicalities of the rules of procedure and evidence ordinarily or normally applicable to a court of law, and may be conducted by the Tribunal in any manner, not inconsistent with the principles of natural justice, which to the Tribunal may seem best adapted to elicit proof concerning the matters that are being investigated. (2) Subject to the provisions of this Act, the practice and procedure to be followed in the making of any appeal to a Tribunal under this Act, and'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is an offence?', 'Answer': 'offence', 'id': 1, 'context': 'Every offence of contem'}, {'Question': 'Who shall serve notice of its decision on any appeal made to the Tribunal under this Act to the Commissioner, and also on the appellant, through the Commissioner?', 'Answer': 'tribunal', 'id': 2, 'context': '(2) A Tribunal shall cause notice of its decision on any appeal made to the Tribunal under this Act to be served on the Commissioner, and also on the appellant, through the Commissioner. (2) A Tribunal shall cause notice of its decision on any appeal made to the Tribunal under this Act to be served on the Commissioner, and also on the appellant, through the Commissioner. by a Tribunal in the entertaining, hearing and deciding of such appeal, shall be as prescribed by regulations made under this Act.'}, {'Question': \"Who is the person who serves notice of a Tribunal's decision on an appeal under this Act?\", 'Answer': 'commissioner', 'id': 3, 'context': '(2) A Tribunal shall cause notice of its decision on any appeal made to the Tribunal under this Act to be served on the Commissioner, and also on the appellant, through the Commissioner. (2) A Tribunal shall cause notice of its decision on any appeal made to the Tribunal under this Act to be served on the Commissioner, and also on the appellant, through the Commissioner.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is contempt of the authority of a Tribunal punishable by the Court of Appeal under Article 105(3) of the Constitution as if it were an offence of disrespect of the authority of the Tribunal?', 'Answer': 'offence', 'id': 1, 'context': 'pt committed against or in disrespect of the authority of a Tribunal shall be punishable by the Court of Appeal under Article 105(3) of the Constitution as though it were an offence of contempt committed against or in disrespect of the authority of that Court.'}, {'Question': 'What is the term for a summons served by a Tribunal?', 'Answer': 'summons', 'id': 2, 'context': 'Failure to obey 35. summons, to give evidence, amp c. (1) If any person upon whom a summons is served, or caused to be served, by a Tribunal— (a) fails without cause, which in the opinion of the Tribunal is reasonable, to appear before the Tribunal at Failure to obey 35. summons, to give evidence, amp c. (1) If any person upon whom a summons is served, or caused to be served, by a Tribunal— (a) fails without cause, which in the opinion of the Tribunal is reasonable, to appear before the Tribunal at'}, {'Question': 'What is the offence of contempt committed against the authority of a Tribunal?', 'Answer': 'disrespect', 'id': 3, 'context': 'pt committed against or in disrespect of the authority of a Tribunal shall be punishable by the Court of Appeal under Article 105(3) of the Constitution as though it were an offence of contempt committed against or in disrespect of the authority of that Court. pt committed against or in disrespect of the authority of a Tribunal shall be punishable by the Court of Appeal under Article 105(3) of the Constitution as though it were an offence of contempt committed against or in disrespect of the authority of that Court.'}, {'Question': 'If a person upon whom a summons is served fails to appear before the Tribunal, what is the reason for the failure?', 'Answer': 'tribunal', 'id': 4, 'context': 'pt committed against or in disrespect of the authority of a Tribunal shall be punishable by the Court of Appeal under Article 105(3) of the Constitution as though it were an offence of contempt committed against or in disrespect of the authority of that Court. Failure to obey 35. summons, to give evidence, amp c. (1) If any person upon whom a summons is served, or caused to be served, by a Tribunal— (a) fails without cause, which in the opinion of the Tribunal is reasonable, to appear before the Tribunal at Failure to obey 35. summons, to give evidence, amp c. (1) If any person upon whom a summons is served, or caused to be served, by a Tribunal— (a) fails without cause, which in the opinion of the Tribunal is reasonable, to appear before the Tribunal at'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is reasonable to produce and show to the Tribunal any document or other thing which is in his possession or power and which is in the opi the time and place mentioned in the summons?', 'Answer': 'tribunal', 'id': 1, 'context': 'the time and place mentioned in the summons ; or (b) refuses to be sworn or, having been duly sworn, refuses or fails without cause, which in the opinion of the Tribunal is reasonable, to answer any question put to him during the proceedings on any appeal relating to matters relevant to the appeal; (c) refuses or fails without cause, which in the opinion of the Tribunal is reasonable, to produce and show to the Tribunal any document or other thing which is in his possession or power and which is in the opi the time and place mentioned in the summons ; or (b) refuses to be sworn or, having been duly sworn, refuses or fails without cause, which in the opinion of the Tribunal is reasonable, to answer any question put to him during the proceedings on any appeal relating to matters relevant to the appeal; (c) refuses or fails without cause, which in the opinion of the Tribunal is reasonable, to produce and show to the Tribunal any document or other thing which is in his possession or power and which is in the opi the time and place mentioned in the summons ; or (b) refuses to be sworn or, having been duly sworn, refuses or fails without cause, which in the opinion of the Tribunal is reasonable, to answer any question put to him during the proceedings on any appeal relating to matters relevant to the appeal; (c) refuses or fails without cause, which in the opinion of the Tribunal is reasonable, to produce and show to the Tribunal any document or other thing which is in his possession or power and which is in the opi'}, {'Question': 'What is in his possession or power and which is in the opi?', 'Answer': 'document', 'id': 2, 'context': 'the time and place mentioned in the summons ; or (b) refuses to be sworn or, having been duly sworn, refuses or fails without cause, which in the opinion of the Tribunal is reasonable, to answer any question put to him during the proceedings on any appeal relating to matters relevant to the appeal; (c) refuses or fails without cause, which in the opinion of the Tribunal is reasonable, to produce and show to the Tribunal any document or other thing which is in his possession or power and which is in the opi'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person interferes with the lawful process of the Tribunal, such person shall be guilty of what offence?', 'Answer': 'offence', 'id': 1, 'context': 'nion of the Tribunal necessary for arriving at the truth of the matters relevant to the appeal; or (d) interferes with the lawful process of the Tribunal, such person shall be guilty of the offence of contempt against or in disrespect of the authority of the Tribunal. (2) Where a Tribunal determines that a person has committed any offence of contempt (referred to in subsection (1)) against or in disrespect of its authority, the Tribunal may transmit, or cause to be transmitted, to the Court of Appeal a cert'}, {'Question': 'If a person interferes with the lawful process of the Tribunal, such person shall be guilty of the offence of contempt against or in what manner of the authority of the Tribunal?', 'Answer': 'disrespect', 'id': 2, 'context': 'nion of the Tribunal necessary for arriving at the truth of the matters relevant to the appeal; or (d) interferes with the lawful process of the Tribunal, such person shall be guilty of the offence of contempt against or in disrespect of the authority of the Tribunal. (2) Where a Tribunal determines that a person has committed any offence of contempt (referred to in subsection (1)) against or in disrespect of its authority, the Tribunal may transmit, or cause to be transmitted, to the Court of Appeal a cert'}, {'Question': 'If a person interferes with the lawful process of the Tribunal, such person shall be guilty of the offence of contempt against the authority of what?', 'Answer': 'tribunal', 'id': 3, 'context': 'nion of the Tribunal necessary for arriving at the truth of the matters relevant to the appeal; or (d) interferes with the lawful process of the Tribunal, such person shall be guilty of the offence of contempt against or in disrespect of the authority of the Tribunal. nion of the Tribunal necessary for arriving at the truth of the matters relevant to the appeal; or (d) interferes with the lawful process of the Tribunal, such person shall be guilty of the offence of contempt against or in disrespect of the authority of the Tribunal. nion of the Tribunal necessary for arriving at the truth of the matters relevant to the appeal; or (d) interferes with the lawful process of the Tribunal, such person shall be guilty of the offence of contempt against or in disrespect of the authority of the Tribunal.'}, {'Question': 'If a person interferes with the lawful process of the Tribunal, such person shall be guilty of the offence of what?', 'Answer': 'contempt', 'id': 4, 'context': 'nion of the Tribunal necessary for arriving at the truth of the matters relevant to the appeal; or (d) interferes with the lawful process of the Tribunal, such person shall be guilty of the offence of contempt against or in disrespect of the authority of the Tribunal. (2) Where a Tribunal determines that a person has committed any offence of contempt (referred to in subsection (1)) against or in disrespect of its authority, the Tribunal may transmit, or cause to be transmitted, to the Court of Appeal a cert'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is contempt?', 'Answer': 'offence', 'id': 1, 'context': '(3) In any proceedings for the punishment of an offence of contempt which the Court of Appeal may think fit to take cognizance of as provided in section 34, any document purporting to be a certificate signed and transmitted to the Court under subsection (2) shall (a) be received in evidence, and be deemed to be such a certificate without further proof unless the contrary is proved; and (b) be conclusive evidence'}, {'Question': 'What is a document that is deemed to be a certificate or a certificate of contempt?', 'Answer': 'certificate', 'id': 2, 'context': '(3) In any proceedings for the punishment of an offence of contempt which the Court of Appeal may think fit to take cognizance of as provided in section 34, any document purporting to be a certificate signed and transmitted to the Court under subsection (2) shall (a) be received in evidence, and be deemed to be such a certificate without further proof unless the contrary is proved; and (b) be conclusive evidence (3) In any proceedings for the punishment of an offence of contempt which the Court of Appeal may think fit to take cognizance of as provided in section 34, any document purporting to be a certificate signed and transmitted to the Court under subsection (2) shall (a) be received in evidence, and be deemed to be such a certificate without further proof unless the contrary is proved; and (b) be conclusive evidence Every such certificate shall be signed by the Tribunal.'}, {'Question': 'What section of the Code provides that a certificate signed and transmitted to the Court under subsection (2) shall be deemed to be a certificate without further proof?', 'Answer': 'subsection', 'id': 3, 'context': '(3) In any proceedings for the punishment of an offence of contempt which the Court of Appeal may think fit to take cognizance of as provided in section 34, any document purporting to be a certificate signed and transmitted to the Court under subsection (2) shall (a) be received in evidence, and be deemed to be such a certificate without further proof unless the contrary is proved; and (b) be conclusive evidence'}, {'Question': 'What is the offence of which the Court of Appeal may think fit to take cognizance of as provided in section 34?', 'Answer': 'contempt', 'id': 4, 'context': '(3) In any proceedings for the punishment of an offence of contempt which the Court of Appeal may think fit to take cognizance of as provided in section 34, any document purporting to be a certificate signed and transmitted to the Court under subsection (2) shall (a) be received in evidence, and be deemed to be such a certificate without further proof unless the contrary is proved; and (b) be conclusive evidence'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is contempt against the authority of a Tribunal?', 'Answer': 'offence', 'id': 1, 'context': '(4) In any proceedings taken as provided in section 34 for the punishment of any alleged offence of contempt against or in disrespect of the authority of a Tribunal, the member of the Tribunal shall not, except with his own consent, be summoned or examined as a witness.'}, {'Question': 'What is the offence of contempt against the authority of a Tribunal?', 'Answer': 'disrespect', 'id': 2, 'context': '(4) In any proceedings taken as provided in section 34 for the punishment of any alleged offence of contempt against or in disrespect of the authority of a Tribunal, the member of the Tribunal shall not, except with his own consent, be summoned or examined as a witness.'}, {'Question': 'Who makes the determination set out in the certificate?', 'Answer': 'tribunal', 'id': 3, 'context': '(4) In any proceedings taken as provided in section 34 for the punishment of any alleged offence of contempt against or in disrespect of the authority of a Tribunal, the member of the Tribunal shall not, except with his own consent, be summoned or examined as a witness. (4) In any proceedings taken as provided in section 34 for the punishment of any alleged offence of contempt against or in disrespect of the authority of a Tribunal, the member of the Tribunal shall not, except with his own consent, be summoned or examined as a witness. that the determination set out in the certificate was made by the Tribunal and of the facts stated in the determination.'}, {'Question': 'What is the offence of disrespecting the authority of a Tribunal?', 'Answer': 'contempt', 'id': 4, 'context': '(4) In any proceedings taken as provided in section 34 for the punishment of any alleged offence of contempt against or in disrespect of the authority of a Tribunal, the member of the Tribunal shall not, except with his own consent, be summoned or examined as a witness.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How is the maximum charge for three copies of a photograph referred to in subsection (1) fixed by the Minister?', 'Answer': 'notification', 'id': 1, 'context': '(2) The maximum charge that may be made for three copies of the photograph referred to in subsection (1) by a registered photographer shall be fixed by the Minister by notification published in the Gazette.'}, {'Question': 'What is required to accompany any application for registration or for the issue of a duplicate of an identity card?', 'Answer': 'photograph', 'id': 2, 'context': '(2) The maximum charge that may be made for three copies of the photograph referred to in subsection (1) by a registered photographer shall be fixed by the Minister by notification published in the Gazette. s of the photograph which are required to accompany any application for registration or for the issue of the duplicate of an identity card shall be paid by the applicant. (3) Notwithstanding anything to the contrary in subsection (1), the cost of the three copies of the photograph of any person referred'}, {'Question': 'What is the maximum charge for three copies of a photograph referred to in subsection (1) by a registered photographer?', 'Answer': 'copies', 'id': 3, 'context': '(2) The maximum charge that may be made for three copies of the photograph referred to in subsection (1) by a registered photographer shall be fixed by the Minister by notification published in the Gazette. (3) Notwithstanding anything to the contrary in subsection (1), the cost of the three copies of the photograph of any person referred'}, {'Question': 'Who shall determine the maximum charge for three copies of a photograph referred to in subsection (1) by a registered photographer?', 'Answer': 'minister', 'id': 4, 'context': '(2) The maximum charge that may be made for three copies of the photograph referred to in subsection (1) by a registered photographer shall be fixed by the Minister by notification published in the Gazette.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who may waive the fee payable by a person for registration or the issue of a duplicate of an identity card?', 'Answer': 'commissioner', 'id': 1, 'context': 'The Commissioner, a Government Agent or any divisional Assistant Government Agent (a) may, on the ground of the poverty of any person, waive the fee payable by that person for registration or the issue of a duplicate of an identity card; and (b) shall, if such fee is so waived, issue to that person a certificate'}, {'Question': 'What is issued to the person who waives the fee payable by that person for registration or the issue of a duplicate of an identity card?', 'Answer': 'certificate', 'id': 2, 'context': 'The Commissioner, a Government Agent or any divisional Assistant Government Agent (a) may, on the ground of the poverty of any person, waive the fee payable by that person for registration or the issue of a duplicate of an identity card; and (b) shall, if such fee is so waived, issue to that person a certificate to in subsection (1) to whom a certificate of waiver has been issued shall be paid by the Government, and accordingly shall be a charge on the Consolidated Fund.'}, {'Question': 'What is waived by the Commissioner, a Government Agent or any divisional Assistant Government Agent (a) for registration or the issue of a duplicate of an identity card?', 'Answer': 'fee', 'id': 3, 'context': 'The Commissioner, a Government Agent or any divisional Assistant Government Agent (a) may, on the ground of the poverty of any person, waive the fee payable by that person for registration or the issue of a duplicate of an identity card; and (b) shall, if such fee is so waived, issue to that person a certificate The Commissioner, a Government Agent or any divisional Assistant Government Agent (a) may, on the ground of the poverty of any person, waive the fee payable by that person for registration or the issue of a duplicate of an identity card; and (b) shall, if such fee is so waived, issue to that person a certificate'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What do you need to furnish information on?', 'Answer': 'identity cards', 'id': 1, 'context': 'Power of Commissioner, amp c, to require applicants for registration or duplicate identity cards to furnish information.'}, {'Question': 'Who may direct an applicant for registration to furnish information?', 'Answer': 'commissioner', 'id': 2, 'context': '(1) The Commissioner or any other authorized officer may direct an applicant for registration, or for a duplicate of an identity card, to furnish, within such period as may be specified in the direction, the Commissioner or such other officer with such information or documents indicated in the direction relating to the prescribed particulars specifie (1) The Commissioner or any other authorized officer may direct an applicant for registration, or for a duplicate of an identity card, to furnish, within such period as may be specified in the direction, the Commissioner or such other officer with such information or documents indicated in the direction relating to the prescribed particulars specifie Power of Commissioner, amp c, to require applicants for registration or duplicate identity cards to furnish information.'}, {'Question': 'Who is required to furnish information for registration or duplicate identity cards?', 'Answer': 'applicants', 'id': 3, 'context': 'Power of Commissioner, amp c, to require applicants for registration or duplicate identity cards to furnish information.'}, {'Question': 'What is the waiver of a fee?', 'Answer': 'fee', 'id': 4, 'context': 'of waiver in respect of such fee.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the term for a government agent?', 'Answer': 'government agent', 'id': 1, 'context': '(2) For the purposes of subsection (1) and of sections 38 and 39, the expression \" authorized officer\" means any Deputy Commissioner, any Assistant Commissioner, any Government Agent, or Assistant Government Agent or divisional Assistant Government Agent. (2) For the purposes of subsection (1) and of sections 38 and 39, the expression \" authorized officer\" means any Deputy Commissioner, any Assistant Commissioner, any Government Agent, or Assistant Government Agent or divisional Assistant Government Agent. (2) For the purposes of subsection (1) and of sections 38 and 39, the expression \" authorized officer\" means any Deputy Commissioner, any Assistant Commissioner, any Government Agent, or Assistant Government Agent or divisional Assistant Government Agent.'}, {'Question': 'For the purposes of subsection (1) and of sections 38 and 39, the expression authorized officer means any Deputy Commissioner, any Assistant Commissioner, any Government Agent, or Assistant Government Agent or divisional Assistant Government Agent.', 'Answer': 'subsection', 'id': 2, 'context': '(2) For the purposes of subsection (1) and of sections 38 and 39, the expression \" authorized officer\" means any Deputy Commissioner, any Assistant Commissioner, any Government Agent, or Assistant Government Agent or divisional Assistant Government Agent.'}, {'Question': 'What is the term for any Deputy Commissioner, any Assistant Commissioner, any Government Agent, or Assistant Government Agent or divisional Assistant Government Agent?', 'Answer': 'officer', 'id': 3, 'context': '(2) For the purposes of subsection (1) and of sections 38 and 39, the expression \" authorized officer\" means any Deputy Commissioner, any Assistant Commissioner, any Government Agent, or Assistant Government Agent or divisional Assistant Government Agent.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is required of an employer to furnish to the Commissioner or any other officer a return containing all such information relating to the persons in the employment of such employer as may be indicated in the direction?', 'Answer': 'particulars', 'id': 1, 'context': 'For the purpose of ensuring that the provisions of this Act are being complied with, the Commissioner or any other authorized officer may, from time to time, by general or special direction, require any employer to furnish, within such period as may be specified in the direction, to the Commissioner or such other officer a return containing all such particulars relating to the persons in the employment of such employer as may be indicated in the direction'}, {'Question': 'Who may require an employer to furnish a return containing all the details relating to the persons in the employment of such employer as may be indicated in the return?', 'Answer': 'commissioner', 'id': 2, 'context': 'For the purpose of ensuring that the provisions of this Act are being complied with, the Commissioner or any other authorized officer may, from time to time, by general or special direction, require any employer to furnish, within such period as may be specified in the direction, to the Commissioner or such other officer a return containing all such particulars relating to the persons in the employment of such employer as may be indicated in the direction For the purpose of ensuring that the provisions of this Act are being complied with, the Commissioner or any other authorized officer may, from time to time, by general or special direction, require any employer to furnish, within such period as may be specified in the direction, to the Commissioner or such other officer a return containing all such particulars relating to the persons in the employment of such employer as may be indicated in the direction'}, {'Question': 'What is the purpose of the return?', 'Answer': 'employment', 'id': 3, 'context': 'For the purpose of ensuring that the provisions of this Act are being complied with, the Commissioner or any other authorized officer may, from time to time, by general or special direction, require any employer to furnish, within such period as may be specified in the direction, to the Commissioner or such other officer a return containing all such particulars relating to the persons in the employment of such employer as may be indicated in the direction h returns regarding persons in their employment.'}, {'Question': 'Who is required to furnish a return to the Commissioner or any other officer containing all such particulars relating to the persons in the employment of such employer as may be indicated in the direction h returns regarding persons in their employment?', 'Answer': 'persons', 'id': 4, 'context': 'For the purpose of ensuring that the provisions of this Act are being complied with, the Commissioner or any other authorized officer may, from time to time, by general or special direction, require any employer to furnish, within such period as may be specified in the direction, to the Commissioner or such other officer a return containing all such particulars relating to the persons in the employment of such employer as may be indicated in the direction h returns regarding persons in their employment.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who may direct any person to furnish, within such period as shall be specified in the direction, the Commissioner or such other officer with such information within his knowledge as shall be so specified relating to any other person referred to in the direction?', 'Answer': 'commissioner', 'id': 1, 'context': '(1) The Commissioner, or any other authorized officer, (a) may direct any person to furnish, within such period as shall be specified in the direction, the Commissioner or such other officer with such information within his knowledge as shall be so specified relating to any other person referred to in the direction, b (1) The Commissioner, or any other authorized officer, (a) may direct any person to furnish, within such period as shall be specified in the direction, the Commissioner or such other officer with such information within his knowledge as shall be so specified relating to any other person referred to in the direction, b Power of Commissioner or 39. authorized officer to require information from persons generally, and to hold inquiries.'}, {'Question': 'What is the power of Commissioner or 39. authorized officer to hold?', 'Answer': 'inquiries', 'id': 2, 'context': 'Power of Commissioner or 39. authorized officer to require information from persons generally, and to hold inquiries.'}, {'Question': 'What is it of an employer to comply with the direction of the employer?', 'Answer': 'duty', 'id': 3, 'context': ', and it shall be the duty of such employer to comply with that direction.'}, {'Question': 'Who does the Commissioner require information from?', 'Answer': 'persons', 'id': 4, 'context': 'Power of Commissioner or 39. authorized officer to require information from persons generally, and to hold inquiries.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the verification of the particulars specified in any such application?', 'Answer': 'correctness', 'id': 1, 'context': \"eing information which is necessary for the following purposes, namely, the disposal of any application made by such other person under this Act, or for the verification of the correctness of any ' particulars specified in any such application, or of any return or information made or furnished by such other person under this Act; and (b) may, from time to time, hold all such inquiries as he may deem necessary for any of such purposes.\"}, {'Question': 'What is the purpose of the disclosure of the correctness of any particulars specified in any such application?', 'Answer': 'verification', 'id': 2, 'context': \"eing information which is necessary for the following purposes, namely, the disposal of any application made by such other person under this Act, or for the verification of the correctness of any ' particulars specified in any such application, or of any return or information made or furnished by such other person under this Act; and (b) may, from time to time, hold all such inquiries as he may deem necessary for any of such purposes.\"}, {'Question': 'What may a person hold from time to time?', 'Answer': 'inquiries', 'id': 3, 'context': \"eing information which is necessary for the following purposes, namely, the disposal of any application made by such other person under this Act, or for the verification of the correctness of any ' particulars specified in any such application, or of any return or information made or furnished by such other person under this Act; and (b) may, from time to time, hold all such inquiries as he may deem necessary for any of such purposes.\"}, {'Question': 'What is the purpose of disposal of any application made by such other person under this Act?', 'Answer': 'purposes', 'id': 4, 'context': \"eing information which is necessary for the following purposes, namely, the disposal of any application made by such other person under this Act, or for the verification of the correctness of any ' particulars specified in any such application, or of any return or information made or furnished by such other person under this Act; and (b) may, from time to time, hold all such inquiries as he may deem necessary for any of such purposes. eing information which is necessary for the following purposes, namely, the disposal of any application made by such other person under this Act, or for the verification of the correctness of any ' particulars specified in any such application, or of any return or information made or furnished by such other person under this Act; and (b) may, from time to time, hold all such inquiries as he may deem necessary for any of such purposes. (2) For the purposes of any inquiry held under subsection (1), the Commis\"}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who has the power to summon and compel the attendance of witnesses?', 'Answer': 'district court', 'id': 1, 'context': 'sioner or any other authorized officer, shall have all the powers of a District Court (a) to summon and compel the attendance of witnesses; (b) to compel the production of documents; and (c) to administer any oath or affirmation to witnesses.'}, {'Question': 'What is the most common oath that a District Court officer may administer to witnesses?', 'Answer': 'affirmation', 'id': 2, 'context': 'sioner or any other authorized officer, shall have all the powers of a District Court (a) to summon and compel the attendance of witnesses; (b) to compel the production of documents; and (c) to administer any oath or affirmation to witnesses.'}, {'Question': 'What is the most important oath that a District Court officer may administer to witnesses?', 'Answer': 'oath', 'id': 3, 'context': 'sioner or any other authorized officer, shall have all the powers of a District Court (a) to summon and compel the attendance of witnesses; (b) to compel the production of documents; and (c) to administer any oath or affirmation to witnesses.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a certificate is produced by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent, to the effect that the person is liable to registration, it shall be presumed, If in any prosecution for an offence under this Act, there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent, to the effect that the person either against', 'Answer': 'offence', 'id': 1, 'context': 'If in any prosecution for an offence under this Act, there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent, to the effect that he is satisfied that the person either against whom the prosecution is instituted, or in respect of whom such offence is alleged to have been committed, is a person (a) who is liable to registration, it shall be presumed, If in any prosecution for an offence under this Act, there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent, to the effect that he is satisfied that the person either against whom the prosecution is instituted, or in respect of whom such offence is alleged to have been committed, is a person (a) who is liable to registration, it shall be presumed,'}, {'Question': 'What is the rank of an Assistant Superintendent?', 'Answer': 'police officer', 'id': 2, 'context': 'If in any prosecution for an offence under this Act, there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent, to the effect that he is satisfied that the person either against whom the prosecution is instituted, or in respect of whom such offence is alleged to have been committed, is a person (a) who is liable to registration, it shall be presumed,'}, {'Question': 'Who is responsible for a prosecution under this Act?', 'Answer': 'commissioner', 'id': 3, 'context': 'If in any prosecution for an offence under this Act, there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent, to the effect that he is satisfied that the person either against whom the prosecution is instituted, or in respect of whom such offence is alleged to have been committed, is a person (a) who is liable to registration, it shall be presumed, If in any prosecution for an offence under this Act, there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent, to the effect that he is satisfied that the person either against whom the prosecution is instituted, or in respect of whom such offence is alleged to have been committed, is a person (a) who is liable to registration, it shall be presumed, If in any prosecution for an offence under this Act, there is produced a certificate issued by the Commissioner, a Deputy Commissioner, an Assistant Commissioner, or a police officer of a rank not below that of Assistant Superintendent, to the effect that he is satisfied that the person either against whom the prosecution is instituted, or in respect of whom such offence is alleged to have been committed, is a person (a) who is liable to registration, it shall be presumed,'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person was in any district on a date specified in a certificate, it shall be presumed, until the contrary is proved by who, that such person was in that district on that date- Limitation in regard to prosecutions?', 'Answer': 'defence', 'id': 1, 'context': 'until the contrary is proved by the defence, that such person is a person of the description referred to in that certificate ; or (b) who was in any district on a date specified in that certificate, it shall be presumed, until the contrary is proved by the defence, that such person was in that district on that date- Limitation in regard to prosecutions. until the contrary is proved by the defence, that such person is a person of the description referred to in that certificate ; or (b) who was in any district on a date specified in that certificate, it shall be presumed, until the contrary is proved by the defence, that such person was in that district on that date- Limitation in regard to prosecutions.'}, {'Question': 'What is the limitation in regard to?', 'Answer': 'prosecutions', 'id': 2, 'context': 'until the contrary is proved by the defence, that such person is a person of the description referred to in that certificate ; or (b) who was in any district on a date specified in that certificate, it shall be presumed, until the contrary is proved by the defence, that such person was in that district on that date- Limitation in regard to prosecutions.'}, {'Question': 'If the defence proves that a person is a person of the description referred to in a certificate, it shall be presumed, until the contrary is proved by the defence, that such person was in that district on that date- Limitation in regard to prosecutions.', 'Answer': 'contrary', 'id': 3, 'context': 'until the contrary is proved by the defence, that such person is a person of the description referred to in that certificate ; or (b) who was in any district on a date specified in that certificate, it shall be presumed, until the contrary is proved by the defence, that such person was in that district on that date- Limitation in regard to prosecutions. until the contrary is proved by the defence, that such person is a person of the description referred to in that certificate ; or (b) who was in any district on a date specified in that certificate, it shall be presumed, until the contrary is proved by the defence, that such person was in that district on that date- Limitation in regard to prosecutions.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the purpose of any provision of this Act?', 'Answer': 'pursuance', 'id': 1, 'context': '(1) Every document purporting to be an instrument made or issued by the Commissioner, in pursuance of any provision of this Act, or any regulation made thereunder, and to be signed by him or on his behalf, shall be received in evidence and shall, until the contrary is proved, be deemed to be an instrument made or issued by him.'}, {'Question': 'Who is responsible for the rumor that a document is made or issued by?', 'Answer': 'commissioner', 'id': 2, 'context': '(1) Every document purporting to be an instrument made or issued by the Commissioner, in pursuance of any provision of this Act, or any regulation made thereunder, and to be signed by him or on his behalf, shall be received in evidence and shall, until the contrary is proved, be deemed to be an instrument made or issued by him. rument issued by the commissioner.'}, {'Question': 'What is made under this Act?', 'Answer': 'regulation', 'id': 3, 'context': '(1) Every document purporting to be an instrument made or issued by the Commissioner, in pursuance of any provision of this Act, or any regulation made thereunder, and to be signed by him or on his behalf, shall be received in evidence and shall, until the contrary is proved, be deemed to be an instrument made or issued by him.'}, {'Question': 'What is a document purporting to be made or issued by the Commissioner, in pursuance of any provision of this Act, or any regulation made thereunder, and to be signed by him or on his behalf, shall be received in evidence and shall, until the contrary is proved, be deemed to be an instrument made or issued by him?', 'Answer': 'instrument', 'id': 4, 'context': '(1) Every document purporting to be an instrument made or issued by the Commissioner, in pursuance of any provision of this Act, or any regulation made thereunder, and to be signed by him or on his behalf, shall be received in evidence and shall, until the contrary is proved, be deemed to be an instrument made or issued by him. (1) Every document purporting to be an instrument made or issued by the Commissioner, in pursuance of any provision of this Act, or any regulation made thereunder, and to be signed by him or on his behalf, shall be received in evidence and shall, until the contrary is proved, be deemed to be an instrument made or issued by him. (2) Prima facie evidence of any instrument referred to in subsection (1) may, in any legal proceedings, be given by the production of a documen'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the role of the commissioner, amp c.?', 'Answer': 'peace officers', 'id': 1, 'context': 'Commissioner, amp c. deemed to be peace officers.'}, {'Question': 'What is an instrument?', 'Answer': 'identity card', 'id': 2, 'context': '(3) In this section, the expression \"instrument\" includes any identity card, certificate, direction or other instrument.'}, {'Question': 'What is the name of every government agent?', 'Answer': 'government agent', 'id': 3, 'context': 'The Commissioner, each Deputy Commissioner, each Assistant Commissioner, every Government Agent, every Registration Officer, every Certifying Officer and every other officer acting under the authority of the Commissioner, shall be de'}, {'Question': 'Who is responsible for the authority of every registration officer?', 'Answer': 'commissioner', 'id': 4, 'context': 'The Commissioner, each Deputy Commissioner, each Assistant Commissioner, every Government Agent, every Registration Officer, every Certifying Officer and every other officer acting under the authority of the Commissioner, shall be de The Commissioner, each Deputy Commissioner, each Assistant Commissioner, every Government Agent, every Registration Officer, every Certifying Officer and every other officer acting under the authority of the Commissioner, shall be de The Commissioner, each Deputy Commissioner, each Assistant Commissioner, every Government Agent, every Registration Officer, every Certifying Officer and every other officer acting under the authority of the Commissioner, shall be de'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the meaning of the Code of Criminal Procedure Act?', 'Answer': 'peace officer', 'id': 1, 'context': 'emed to be a peace officer within the meaning of the Code of Criminal Procedure Act for the purpose of exercising any power conferred upon a peace officer by that Act. emed to be a peace officer within the meaning of the Code of Criminal Procedure Act for the purpose of exercising any power conferred upon a peace officer by that Act.'}, {'Question': 'What is the purpose of section 8?', 'Answer': 'compliance', 'id': 2, 'context': '(1) Any person who (a) fails to make an application for registration in compliance with the provisions of section 8 ; (b) gives any incorrect information in such application or in response to any inquiry; or (c) makes more than one such application; or (d) obtains an identity card by fraud ; or (e) notwithstanding the provisions'}, {'Question': 'What is the Code of Criminal Procedure Act?', 'Answer': 'code', 'id': 3, 'context': 'emed to be a peace officer within the meaning of the Code of Criminal Procedure Act for the purpose of exercising any power conferred upon a peace officer by that Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is it that a person who abets or incites any other person liable to registration not to make an application for registration as required by this Act shall be guilty of?', 'Answer': 'offence', 'id': 1, 'context': '(2) Any person who abets or incites any other person liable to registration not to make an application for registration as required by this Act shall be guilty of an offence under this Act, and shall be liable to rigorous imprisonment for a term of one year. of sections 24 and 47, obtains by fraud or otherwise or is in possession of or uses more than one identity card, shall be guilty of an offence under this Act, and shall be liable to a fine not exceeding five hundred rupees.'}, {'Question': 'Who is guilty of fraud or misuse of more than one identity card?', 'Answer': 'obtains', 'id': 2, 'context': 'of sections 24 and 47, obtains by fraud or otherwise or is in possession of or uses more than one identity card, shall be guilty of an offence under this Act, and shall be liable to a fine not exceeding five hundred rupees.'}, {'Question': 'What is the punishment for abets or incites other persons liable to registration not to make an application for registration as required by this Act?', 'Answer': 'imprisonment', 'id': 3, 'context': '(2) Any person who abets or incites any other person liable to registration not to make an application for registration as required by this Act shall be guilty of an offence under this Act, and shall be liable to rigorous imprisonment for a term of one year.'}, {'Question': 'What is the offence of obtaining more than one identity card?', 'Answer': 'fraud', 'id': 4, 'context': 'of sections 24 and 47, obtains by fraud or otherwise or is in possession of or uses more than one identity card, shall be guilty of an offence under this Act, and shall be liable to a fine not exceeding five hundred rupees.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who furnishes any return that is untrue or incorrect, shall be guilty of what under this Act?', 'Answer': 'offence', 'id': 1, 'context': 'ls to carry out the duty imposed on him by section 38 to comply with any direction issued to him under that section to furnish a return relating to any person or persons in his employment; or (b) who furnishes any such return containing any particular regarding such person or persons that is untrue or incorrect, shall be guilty of an offence under this Act, and shall be liable to a fine of one thousand rupees, (i) in the case referred to in paragraph (a) of this subsection, in respect of each such person or'}, {'Question': 'What is the case referred to in paragraph (a) of this section?', 'Answer': 'paragraph', 'id': 2, 'context': 'ls to carry out the duty imposed on him by section 38 to comply with any direction issued to him under that section to furnish a return relating to any person or persons in his employment; or (b) who furnishes any such return containing any particular regarding such person or persons that is untrue or incorrect, shall be guilty of an offence under this Act, and shall be liable to a fine of one thousand rupees, (i) in the case referred to in paragraph (a) of this subsection, in respect of each such person or'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'In the case referred to in paragraph (b) of this subsection, in respect of each such person or persons to whom such untrue or incorrect particular relates, what is the case?', 'Answer': 'paragraph', 'id': 1, 'context': 'persons in relation to whom he has omitted to furnish such return; and (ii) in the case referred to in paragraph (b) of this subsection, in respect of each such person or persons to whom such untrue or incorrect particular relates.'}, {'Question': 'In the case referred to in paragraph (b) of this section, in respect of each such person or persons to whom such untrue or incorrect particular relates, what is the purpose of the return?', 'Answer': 'subsection', 'id': 2, 'context': 'persons in relation to whom he has omitted to furnish such return; and (ii) in the case referred to in paragraph (b) of this subsection, in respect of each such person or persons to whom such untrue or incorrect particular relates.'}, {'Question': 'Any person who contravenes or fails to comply with any provision of this Act, other than any such provision as is referred to in subsections (1) to (3), or any regulation made thereunder, shall be guilty of an offence under this Act and shall be liable to a fine not exceedin what?', 'Answer': 'provision', 'id': 3, 'context': '(4) Any person who contravenes or fails to comply with any provision of this Act, other than any such provision as is referred to in subsections (1) to (3), or any regulation made thereunder, shall be guilty of an offence under this Act and shall be liable to a fine not exceedin (4) Any person who contravenes or fails to comply with any provision of this Act, other than any such provision as is referred to in subsections (1) to (3), or any regulation made thereunder, shall be guilty of an offence under this Act and shall be liable to a fine not exceedin'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the burden of proving the truth or accuracy of any information furnished, or statement made, in connection with an application made for registration?', 'Answer': 'particulars', 'id': 1, 'context': 'Upon an application made for registration, the burden of proving the truth or accuracy of any particulars furnished, or statement made, in connexion with such application shall lie on the applicant.'}, {'Question': 'What is the fine of a person for a term of not less than three months but not more than one year?', 'Answer': 'imprisonment', 'id': 2, 'context': 'g one thousand rupees, or to imprisonment of either description for a term of not less than three months but not more than one year, or to both such fine and imprisonment. g one thousand rupees, or to imprisonment of either description for a term of not less than three months but not more than one year, or to both such fine and imprisonment.'}, {'Question': 'Who is burdened by proof cast for registration?', 'Answer': 'applicants', 'id': 3, 'context': 'Burden of proof cast on applicants for registration.'}, {'Question': 'What is the burden of proof cast on an applicant for?', 'Answer': 'registration', 'id': 4, 'context': 'Upon an application made for registration, the burden of proving the truth or accuracy of any particulars furnished, or statement made, in connexion with such application shall lie on the applicant. Burden of proof cast on applicants for registration.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person has entered or is remaining in Sri Lanka in contravention of the provisions of the Immigrants and Emigrants Act, be deemed or construed to make lawful his entry or residence in what country?', 'Answer': 'sri lanka', 'id': 1, 'context': '(1) The provisions of this Act shall be without prejudice to the operation of the Immigrants and Emigrants Act, and accordingly the fact that a person has applied for registration or is registered in the Register of Persons or is the holder of an identity card shall not, if that person has entered or is remaining in Sri Lanka in contravention of the provisions of the Immigrants and Emigrants Act, be deemed or construed to make lawful his entry or residence in Sri Lanka. (1) The provisions of this Act shall be without prejudice to the operation of the Immigrants and Emigrants Act, and accordingly the fact that a person has applied for registration or is registered in the Register of Persons or is the holder of an identity card shall not, if that person has entered or is remaining in Sri Lanka in contravention of the provisions of the Immigrants and Emigrants Act, be deemed or construed to make lawful his entry or residence in Sri Lanka.'}, {'Question': 'What is the reason for a person entering Sri Lanka?', 'Answer': 'contravention', 'id': 2, 'context': '(1) The provisions of this Act shall be without prejudice to the operation of the Immigrants and Emigrants Act, and accordingly the fact that a person has applied for registration or is registered in the Register of Persons or is the holder of an identity card shall not, if that person has entered or is remaining in Sri Lanka in contravention of the provisions of the Immigrants and Emigrants Act, be deemed or construed to make lawful his entry or residence in Sri Lanka.'}, {'Question': 'Who is not allowed to enter Sri Lanka in contravention of the provisions of the Immigrants and Emigrants Act?', 'Answer': 'immigrants', 'id': 3, 'context': '(1) The provisions of this Act shall be without prejudice to the operation of the Immigrants and Emigrants Act, and accordingly the fact that a person has applied for registration or is registered in the Register of Persons or is the holder of an identity card shall not, if that person has entered or is remaining in Sri Lanka in contravention of the provisions of the Immigrants and Emigrants Act, be deemed or construed to make lawful his entry or residence in Sri Lanka. (1) The provisions of this Act shall be without prejudice to the operation of the Immigrants and Emigrants Act, and accordingly the fact that a person has applied for registration or is registered in the Register of Persons or is the holder of an identity card shall not, if that person has entered or is remaining in Sri Lanka in contravention of the provisions of the Immigrants and Emigrants Act, be deemed or construed to make lawful his entry or residence in Sri Lanka.'}, {'Question': 'The provisions of this Act shall be without what to the operation of the Immigrants and Emigrants Act?', 'Answer': 'prejudice', 'id': 4, 'context': '(1) The provisions of this Act shall be without prejudice to the operation of the Immigrants and Emigrants Act, and accordingly the fact that a person has applied for registration or is registered in the Register of Persons or is the holder of an identity card shall not, if that person has entered or is remaining in Sri Lanka in contravention of the provisions of the Immigrants and Emigrants Act, be deemed or construed to make lawful his entry or residence in Sri Lanka.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZERO\n",
            "Unexpected structure in the 'outputs' dictionary. Check the structure and update the code.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': \"What is the holder of a person's identity card?\", 'Answer': 'identity card', 'id': 1, 'context': '[8,37 of 1971] (3) The provisions of this Act shall be without prejudice to the operation of the Indo-Ceylon Agreement (Implementation) Act, and accordingly the fact that a person has applied for registration or is registered in the Register of Persons or is the holder of an identity card shall not in any way affect the liability of that person for removal to India from Sri Lanka under section 15 of that Act. An identity card which has been issued or obtained'}, {'Question': 'Where is the Indian Embassy in Sri Lanka?', 'Answer': 'sri lanka', 'id': 2, 'context': '[8,37 of 1971] (3) The provisions of this Act shall be without prejudice to the operation of the Indo-Ceylon Agreement (Implementation) Act, and accordingly the fact that a person has applied for registration or is registered in the Register of Persons or is the holder of an identity card shall not in any way affect the liability of that person for removal to India from Sri Lanka under section 15 of that Act.'}, {'Question': 'What is the purpose of the Indo-Ceylon Agreement?', 'Answer': 'implementation', 'id': 3, 'context': '[8,37 of 1971] (3) The provisions of this Act shall be without prejudice to the operation of the Indo-Ceylon Agreement (Implementation) Act, and accordingly the fact that a person has applied for registration or is registered in the Register of Persons or is the holder of an identity card shall not in any way affect the liability of that person for removal to India from Sri Lanka under section 15 of that Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the liability in case of a body corporate or unincorporated?', 'Answer': 'offences', 'id': 1, 'context': 'Liability in case of offences committed by a body corporate or unincorporate. All offences under this Act shall be triable summarily by a Magistrate. Offences to be triable summarily by a Magistrate.'}, {'Question': 'Who can triable offences under this Act?', 'Answer': 'magistrate', 'id': 2, 'context': 'All offences under this Act shall be triable summarily by a Magistrate. Offences to be triable summarily by a Magistrate.'}, {'Question': 'Who is responsible for the fraud and false representations that are not surrendered to the Commissioner under section 18 (1) (b) within the period referred to in that section?', 'Answer': 'commissioner', 'id': 3, 'context': 'by means of a false representation, or fraud, or which is not surrendered to the Commissioner under section 18 (1) (b) within the period referred to in that section, shall be invalid and of no effect for the purposes of this Act.'}, {'Question': 'What is the liability in case of offences committed by a body corporate or unincorporated?', 'Answer': 'liability', 'id': 4, 'context': 'Liability in case of offences committed by a body corporate or unincorporate.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person is guilty of a felony, unless he proves that the offence was committed wit, then he shall be deemed guilty of that offence.', 'Answer': 'offence', 'id': 1, 'context': ', every person who, at the time of the commission of the offence, was a director, general manager, secretary or other similar officer of the body corporate or was purporting to act-in such capacity; or (b) by a body unincorporate, every person who, at the time of the commission of the offence, was the head or secretary, or a member of the governing board, of that body, or was purporting to act in such capacity, shall be deemed to be guilty of that offence unless he proves that such offence was committed wit , every person who, at the time of the commission of the offence, was a director, general manager, secretary or other similar officer of the body corporate or was purporting to act-in such capacity; or (b) by a body unincorporate, every person who, at the time of the commission of the offence, was the head or secretary, or a member of the governing board, of that body, or was purporting to act in such capacity, shall be deemed to be guilty of that offence unless he proves that such offence was committed wit , every person who, at the time of the commission of the offence, was a director, general manager, secretary or other similar officer of the body corporate or was purporting to act-in such capacity; or (b) by a body unincorporate, every person who, at the time of the commission of the offence, was the head or secretary, or a member of the governing board, of that body, or was purporting to act in such capacity, shall be deemed to be guilty of that offence unless he proves that such offence was committed wit'}, {'Question': 'If a person was a director, general manager, secretary or other similar officer of a body corporate at the time of what offence?', 'Answer': 'commission', 'id': 2, 'context': ', every person who, at the time of the commission of the offence, was a director, general manager, secretary or other similar officer of the body corporate or was purporting to act-in such capacity; or (b) by a body unincorporate, every person who, at the time of the commission of the offence, was the head or secretary, or a member of the governing board, of that body, or was purporting to act in such capacity, shall be deemed to be guilty of that offence unless he proves that such offence was committed wit , every person who, at the time of the commission of the offence, was a director, general manager, secretary or other similar officer of the body corporate or was purporting to act-in such capacity; or (b) by a body unincorporate, every person who, at the time of the commission of the offence, was the head or secretary, or a member of the governing board, of that body, or was purporting to act in such capacity, shall be deemed to be guilty of that offence unless he proves that such offence was committed wit'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the nature of his duties in such capacity?', 'Answer': 'functions', 'id': 1, 'context': 'hout his consent or connivance and that he exercised all such diligence to prevent the commission of such offence as he ought to have exercised having regard to the nature of his functions in such capacity and in all the circumstances.'}, {'Question': 'What does the governing board mean in relation to a body unincorporated?', 'Answer': 'affairs', 'id': 2, 'context': '(2) For the purposes of this section, the term (a) \" governing board \", in relation to a body unincorporate, means the person or persons for the time being charged with the management or administration of the affairs of that body; (b) \" head\", in relation to a body unincorpor'}, {'Question': 'What is the governing board in relation to a body unincorporated?', 'Answer': 'management', 'id': 3, 'context': '(2) For the purposes of this section, the term (a) \" governing board \", in relation to a body unincorporate, means the person or persons for the time being charged with the management or administration of the affairs of that body; (b) \" head\", in relation to a body unincorpor'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are cognizable under this Act?', 'Answer': 'offences', 'id': 1, 'context': 'All offences under this Act shall be cogniz offences to be cognizable.'}, {'Question': 'What is the name of the person who for the time being occupies the position of head, by whatever name called?', 'Answer': 'secretary', 'id': 2, 'context': 'ate, means the chairman or president for the time being of that body or, in the absence of a chairman or president, the person who for the time being occupies the position of head, by whatsoever name called, of the management or administration of the affairs of that body; and (c) \" secretary\", in relation to a body unincorporate, includes any person who for the time being occupies the position of secretary, by whatsoever name called. ate, means the chairman or president for the time being of that body or, in the absence of a chairman or president, the person who for the time being occupies the position of head, by whatsoever name called, of the management or administration of the affairs of that body; and (c) \" secretary\", in relation to a body unincorporate, includes any person who for the time being occupies the position of secretary, by whatsoever name called.'}, {'Question': 'What is the position of head of the management or administration of the affairs of a body?', 'Answer': 'chairman', 'id': 3, 'context': 'ate, means the chairman or president for the time being of that body or, in the absence of a chairman or president, the person who for the time being occupies the position of head, by whatsoever name called, of the management or administration of the affairs of that body; and (c) \" secretary\", in relation to a body unincorporate, includes any person who for the time being occupies the position of secretary, by whatsoever name called. ate, means the chairman or president for the time being of that body or, in the absence of a chairman or president, the person who for the time being occupies the position of head, by whatsoever name called, of the management or administration of the affairs of that body; and (c) \" secretary\", in relation to a body unincorporate, includes any person who for the time being occupies the position of secretary, by whatsoever name called.'}, {'Question': 'What is the management of the affairs of a body?', 'Answer': 'administration', 'id': 4, 'context': 'ate, means the chairman or president for the time being of that body or, in the absence of a chairman or president, the person who for the time being occupies the position of head, by whatsoever name called, of the management or administration of the affairs of that body; and (c) \" secretary\", in relation to a body unincorporate, includes any person who for the time being occupies the position of secretary, by whatsoever name called.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is compounding of?', 'Answer': 'offences', 'id': 1, 'context': 'able offences for the purposes of the application of the provisions of the Code of Criminal Procedure Act, notwithstanding anything contained in the First Schedule to that Act. Compounding of offences.'}, {'Question': 'What is compounding of offences?', 'Answer': 'compounding', 'id': 2, 'context': 'Compounding of offences.'}, {'Question': 'What section of section 44 provides for the Commissioner to compound an offence under subsection (1) of section 44 by accepting from the person who is alleged to have committed the offence a sum of money not exceeding half the amount of the maximum fine that is liable to be imposed under this Act?', 'Answer': 'subsection', 'id': 3, 'context': 'The Commissioner may compound any offence under subsection (1) of section 44 by accepting from the person who is alleged to have, or is reasonably suspected of having, committed that offence a sum of money not exceeding half the amount of the maximum fine that is liable to be imposed under this Act on suc'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the power of the Minister to make regulations for matters under subsection (1)?', 'Answer': 'generality', 'id': 1, 'context': '(2) Without prejudice to the generality of the powers conferred by subsection (1), the Minister may make regulations for or in respect of all or any of the following matters: (a) all matters stated or required by this Act to be prescribed ; (b) all matters for which regulations are required or authorized by this Act to be made; [9,37 of 1971] (c) al'}, {'Question': 'What may the Minister make for the purpose of giving effect to the principles and provisions of this Act?', 'Answer': 'regulations', 'id': 2, 'context': '(2) Without prejudice to the generality of the powers conferred by subsection (1), the Minister may make regulations for or in respect of all or any of the following matters: (a) all matters stated or required by this Act to be prescribed ; (b) all matters for which regulations are required or authorized by this Act to be made; [9,37 of 1971] (c) al (2) Without prejudice to the generality of the powers conferred by subsection (1), the Minister may make regulations for or in respect of all or any of the following matters: (a) all matters stated or required by this Act to be prescribed ; (b) all matters for which regulations are required or authorized by this Act to be made; [9,37 of 1971] (c) al (1) The Minister may make regulations for the purpose of giving effect to the principles and provisions of this Act.'}, {'Question': 'Who may make regulations for the purpose of giving effect to the principles and provisions of this Act?', 'Answer': 'minister', 'id': 3, 'context': '(2) Without prejudice to the generality of the powers conferred by subsection (1), the Minister may make regulations for or in respect of all or any of the following matters: (a) all matters stated or required by this Act to be prescribed ; (b) all matters for which regulations are required or authorized by this Act to be made; [9,37 of 1971] (c) al (1) The Minister may make regulations for the purpose of giving effect to the principles and provisions of this Act.'}, {'Question': 'What powers does subsection (1) confer?', 'Answer': 'powers', 'id': 4, 'context': '(2) Without prejudice to the generality of the powers conferred by subsection (1), the Minister may make regulations for or in respect of all or any of the following matters: (a) all matters stated or required by this Act to be prescribed ; (b) all matters for which regulations are required or authorized by this Act to be made; [9,37 of 1971] (c) al'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the procedure to be followed by applicant for taking photographs?', 'Answer': 'sri lanka', 'id': 1, 'context': 'l matters relating to the taking of photographs for the purposes of this Act, and in particular (i) the mode or manner in which photographs may be taken, and the dimensions, specifications, standards and quality of such photographs, (ii) the registration of persons as photographers for any area or areas in Sri Lanka, and the circumstances in which such registration may be allowed, refused or cancelled, (iii) the fees payable for registration as a photographer, and (iv) the procedure to be followed by applic'}, {'Question': 'What are the dimensions, specifications, standards and quality of photographs?', 'Answer': 'specifications', 'id': 2, 'context': 'l matters relating to the taking of photographs for the purposes of this Act, and in particular (i) the mode or manner in which photographs may be taken, and the dimensions, specifications, standards and quality of such photographs, (ii) the registration of persons as photographers for any area or areas in Sri Lanka, and the circumstances in which such registration may be allowed, refused or cancelled, (iii) the fees payable for registration as a photographer, and (iv) the procedure to be followed by applic'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the establishment and maintenance of registers and what is related to the matters aforesaid?', 'Answer': 'registries', 'id': 1, 'context': 'ants for registration in obtaining photographs for the purposes of this Act; (d) the establishment and maintenance of registers and registries; and (e) all matters incidental to, or connected with, the matters aforesaid.'}, {'Question': 'What are ants for registration in obtaining for the purposes of this Act?', 'Answer': 'photographs', 'id': 2, 'context': 'ants for registration in obtaining photographs for the purposes of this Act; (d) the establishment and maintenance of registers and registries; and (e) all matters incidental to, or connected with, the matters aforesaid.'}, {'Question': 'What is the purpose of a register?', 'Answer': 'establishment', 'id': 3, 'context': 'ants for registration in obtaining photographs for the purposes of this Act; (d) the establishment and maintenance of registers and registries; and (e) all matters incidental to, or connected with, the matters aforesaid.'}, {'Question': 'What is the establishment and maintenance of registers and registries?', 'Answer': 'maintenance', 'id': 4, 'context': 'ants for registration in obtaining photographs for the purposes of this Act; (d) the establishment and maintenance of registers and registries; and (e) all matters incidental to, or connected with, the matters aforesaid.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person is not served on or notified personally to a person, it will be deemed to have been duly served or notified if it is left at the usual or last known place of abode or of business of such person, or if such person is resident in a place of residence or business of such person, or if such person is resident in a place of residence or abode?', 'Answer': 'abode', 'id': 1, 'context': '(1) Save as otherwise expressly provided in this Act, any document, decision or other matter which is required by or under this Act to be served on, or notified to, any person shall, if it is not served on, or notified personally to, such person, be deemed to have been duly served or notified (a) if it is left at the usual or last known place of abode or of business of such person, or, in case such person is resident in a'}, {'Question': 'What is the service of documents?', 'Answer': 'documents', 'id': 2, 'context': 'Service of documents.'}, {'Question': 'Any document, decision or other matter required by or under this Act shall be deemed to have been duly served on, or notified personally to, any person if it is not left at the usual or last known place of abode or of business of such person, or, in case such person is resident in a country, in case such person is resident in a country?', 'Answer': 'decision', 'id': 3, 'context': '(1) Save as otherwise expressly provided in this Act, any document, decision or other matter which is required by or under this Act to be served on, or notified to, any person shall, if it is not served on, or notified personally to, such person, be deemed to have been duly served or notified (a) if it is left at the usual or last known place of abode or of business of such person, or, in case such person is resident in a'}, {'Question': 'If a person is not served on or notified personally to a person, it shall be deemed to have been duly served or notified (a) if it is left at the usual or last known place of abode or of business of such person, or, in case such person is resident in a different state than the other state, it will be deemed to have been duly served or notified if it is left at the usual or last known place of abode or of business of such person', 'Answer': 'act', 'id': 4, 'context': '(1) Save as otherwise expressly provided in this Act, any document, decision or other matter which is required by or under this Act to be served on, or notified to, any person shall, if it is not served on, or notified personally to, such person, be deemed to have been duly served or notified (a) if it is left at the usual or last known place of abode or of business of such person, or, in case such person is resident in a (1) Save as otherwise expressly provided in this Act, any document, decision or other matter which is required by or under this Act to be served on, or notified to, any person shall, if it is not served on, or notified personally to, such person, be deemed to have been duly served or notified (a) if it is left at the usual or last known place of abode or of business of such person, or, in case such person is resident in a'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'If a person is resident on an estate, if it is sent by post in a registered letter addressed to his last known place of what?', 'Answer': 'abode', 'id': 1, 'context': 'n estate, if it is left with the Superintendent of that estate for transmission to such person; or (b) if it is sent to him by post in a registered letter addressed to his last known place of abode or of business, or in case such person is resident on any estate, if it is sent by post in a registered letter addressed to the Superintendent of that estate for transmission to such person.'}, {'Question': 'If a person is resident on an estate, if it is sent by post in a registered letter addressed to his last known place of abode or of business, or in case such person is resident on that estate, if it is sent by post in a registered letter addressed to the Superintendent of that estate for transmission to such person?', 'Answer': 'superintendent', 'id': 2, 'context': 'n estate, if it is left with the Superintendent of that estate for transmission to such person; or (b) if it is sent to him by post in a registered letter addressed to his last known place of abode or of business, or in case such person is resident on any estate, if it is sent by post in a registered letter addressed to the Superintendent of that estate for transmission to such person. n estate, if it is left with the Superintendent of that estate for transmission to such person; or (b) if it is sent to him by post in a registered letter addressed to his last known place of abode or of business, or in case such person is resident on any estate, if it is sent by post in a registered letter addressed to the Superintendent of that estate for transmission to such person.'}, {'Question': 'What is the term for any order, notice, or other document by whatever name or designation?', 'Answer': 'document', 'id': 3, 'context': '(2) In this section (a) the term \" document\" means any order, notice, or other document by whatsoever name or designation c (2) In this section (a) the term \" document\" means any order, notice, or other document by whatsoever name or designation c'}, {'Question': 'If a person is resident on an estate, if it is sent by post in a registered letter addressed to his last known place of abode or of business, or in case such person is resident on that estate, if it is sent by post in a registered letter addressed to the Superintendent of that estate for what?', 'Answer': 'transmission', 'id': 4, 'context': 'n estate, if it is left with the Superintendent of that estate for transmission to such person; or (b) if it is sent to him by post in a registered letter addressed to his last known place of abode or of business, or in case such person is resident on any estate, if it is sent by post in a registered letter addressed to the Superintendent of that estate for transmission to such person. n estate, if it is left with the Superintendent of that estate for transmission to such person; or (b) if it is sent to him by post in a registered letter addressed to his last known place of abode or of business, or in case such person is resident on any estate, if it is sent by post in a registered letter addressed to the Superintendent of that estate for transmission to such person.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the fees, penalties and fees under this Act?', 'Answer': 'fines', 'id': 1, 'context': '54 All sums paid or recovered by way of fees, fines and penalties under this Act shall be credited to the Consolidated Fund. Fees, fines and penalties to be Consolidated Fund.'}, {'Question': 'What is Superintendent in relation to?', 'Answer': 'estate', 'id': 2, 'context': 'alled; and (b) the term \" Superintendent\", in relation to any estate, means the person in charge of that estate by whatsoever name or designation called. alled; and (b) the term \" Superintendent\", in relation to any estate, means the person in charge of that estate by whatsoever name or designation called.'}, {'Question': 'In what way does the term \" Superintendent\" refer to the person in charge of an estate?', 'Answer': 'relation', 'id': 3, 'context': 'In this Act unless the context otherwise requires \" appointed date \" means the 5th day of April 1971; \" appropriate appointed period\", in relation to a person lia alled; and (b) the term \" Superintendent\", in relation to any estate, means the person in charge of that estate by whatsoever name or designation called.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who is required to apply for registration under and in accordance with the provisions of this Act?', 'Answer': 'applicant', 'id': 1, 'context': 'ble to registration, means the period within which such person is required, by virtue of the operation of section 7 or any Order made thereunder, to apply for registration under and in accordance with the provisions of this Act; \" appropriate Certifying Officer\", in relation to any applicant for registration or any registered person, means the Certifying Officer within whose area of appointment such applicant or person, as the case may be, is ordinarily resident; \" appropriate Tribunal\", in relation to an a ble to registration, means the period within which such person is required, by virtue of the operation of section 7 or any Order made thereunder, to apply for registration under and in accordance with the provisions of this Act; \" appropriate Certifying Officer\", in relation to any applicant for registration or any registered person, means the Certifying Officer within whose area of appointment such applicant or person, as the case may be, is ordinarily resident; \" appropriate Tribunal\", in relation to an a'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZERO\n",
            "Unexpected structure in the 'outputs' dictionary. Check the structure and update the code.\n",
            "ZERO\n",
            "Unexpected structure in the 'outputs' dictionary. Check the structure and update the code.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the Government Agent for a district?', 'Answer': 'government agent', 'id': 1, 'context': 'on behalf of any other person employs any person, and in particular in the case of any estate, includes any Superintendent, Assistant Superintendent, Conductor or Kangany; \" Government Agent\" means the Government Agent for a district, and includes any Assistant Government Agent or any Additional Assistant Government Agent, for that district, or any Office Assistant, or any extra Office Assistant, to such Government Agent; \" holder\", in relation to an identity card, means a person to whom such card is issued on behalf of any other person employs any person, and in particular in the case of any estate, includes any Superintendent, Assistant Superintendent, Conductor or Kangany; \" Government Agent\" means the Government Agent for a district, and includes any Assistant Government Agent or any Additional Assistant Government Agent, for that district, or any Office Assistant, or any extra Office Assistant, to such Government Agent; \" holder\", in relation to an identity card, means a person to whom such card is issued on behalf of any other person employs any person, and in particular in the case of any estate, includes any Superintendent, Assistant Superintendent, Conductor or Kangany; \" Government Agent\" means the Government Agent for a district, and includes any Assistant Government Agent or any Additional Assistant Government Agent, for that district, or any Office Assistant, or any extra Office Assistant, to such Government Agent; \" holder\", in relation to an identity card, means a person to whom such card is issued'}, {'Question': 'What is the extra office assistant to a Government Agent?', 'Answer': 'office assistant', 'id': 2, 'context': 'on behalf of any other person employs any person, and in particular in the case of any estate, includes any Superintendent, Assistant Superintendent, Conductor or Kangany; \" Government Agent\" means the Government Agent for a district, and includes any Assistant Government Agent or any Additional Assistant Government Agent, for that district, or any Office Assistant, or any extra Office Assistant, to such Government Agent; \" holder\", in relation to an identity card, means a person to whom such card is issued on behalf of any other person employs any person, and in particular in the case of any estate, includes any Superintendent, Assistant Superintendent, Conductor or Kangany; \" Government Agent\" means the Government Agent for a district, and includes any Assistant Government Agent or any Additional Assistant Government Agent, for that district, or any Office Assistant, or any extra Office Assistant, to such Government Agent; \" holder\", in relation to an identity card, means a person to whom such card is issued'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the identity card issued by the Commissioner under this Act, and includes a duplicate thereof so issued?', 'Answer': 'identity card', 'id': 1, 'context': 'under this Act; \" identity card\" means an identity card issued by the Commissioner under this Act, and includes a duplicate thereof so issued; \" person \" means an individual; \"person liable to registration\" means a person who, under the provisions of this Act, is liable to registration; \" registered person\" means a person registered in the Register of Persons under this Act; \"Registration Officer\" means a person appointed to be, or to act as, a Registration Officer for the purposes of this Act; \" Register under this Act; \" identity card\" means an identity card issued by the Commissioner under this Act, and includes a duplicate thereof so issued; \" person \" means an individual; \"person liable to registration\" means a person who, under the provisions of this Act, is liable to registration; \" registered person\" means a person registered in the Register of Persons under this Act; \"Registration Officer\" means a person appointed to be, or to act as, a Registration Officer for the purposes of this Act; \" Register'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is a person registered as under the provisions of any regulation made under this Act?', 'Answer': 'photographer', 'id': 1, 'context': 'of Persons\" means the Register of Persons, and includes any part thereof, opened and maintained by the Commissioner under this Act; \"registered photographer\" means a person registered as a photographer under the provisions of any regulation made under this Act; \"registered or registration\" means registered, or registration, as the case may be, in the Register of Persons under this Act. of Persons\" means the Register of Persons, and includes any part thereof, opened and maintained by the Commissioner under this Act; \"registered photographer\" means a person registered as a photographer under the provisions of any regulation made under this Act; \"registered or registration\" means registered, or registration, as the case may be, in the Register of Persons under this Act.'}, {'Question': 'Who is responsible for the operation of the Register of Persons under this Act?', 'Answer': 'commissioner', 'id': 2, 'context': 'of Persons\" means the Register of Persons, and includes any part thereof, opened and maintained by the Commissioner under this Act; \"registered photographer\" means a person registered as a photographer under the provisions of any regulation made under this Act; \"registered or registration\" means registered, or registration, as the case may be, in the Register of Persons under this Act.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'When was the act passed?', 'Answer': 'january', 'id': 1, 'context': 'NOW THEREFORE be it enacted by the Parliament of the Democratic Socialist Republic of Sri Lanka as follows:- Act Nos, 2 of 1995 [ 5th January , 1995 ] 58 of 1998 [ 15th December , 1998 ] [5th January , 1995 ] short title and duration of the Act. NOW THEREFORE be it enacted by the Parliament of the Democratic Socialist Republic of Sri Lanka as follows:- Act Nos, 2 of 1995 [ 5th January , 1995 ] 58 of 1998 [ 15th December , 1998 ] [5th January , 1995 ] short title and duration of the Act.'}, {'Question': 'How do I register my death?', 'Answer': 'therewith', 'id': 2, 'context': 'Registration of Deaths(Temporary Provisions) Act No 2 of 1995 As ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERETO.'}, {'Question': 'What is the purpose of the Act No 2 of 1995?', 'Answer': 'deaths', 'id': 3, 'context': 'Registration of Deaths(Temporary Provisions) Act No 2 of 1995 As ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERETO. Registration of Deaths(Temporary Provisions) Act No 2 of 1995 As ACT TO PROVIDE FOR THE REGISTRATION OF DEATHS OF PERSONS REPORTED MISSING; AND FOR MATTERS CONNECTED THEREWITH OR INCIDENTAL THERETO. This Act may be cited as the Registration of Deaths (Temporary P'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What are the names of the persons who can apply for the provisions of the Act?', 'Answer': 'death certificates', 'id': 1, 'context': 'The provisions of this Act shall be in operation for a period of two years from the date of its commencement who may apply for death certificates.'}, {'Question': 'If a person is reported missing and presumed to be dead, who can apply to register the death?', 'Answer': 'kin', 'id': 2, 'context': 'Where any person is reported missing and presumed to be dead as he has not been heard of for a period exceeding one year by those who would naturally have heard of him had he been alive, a next of kin of such person if he verily believes such person to be dead, may, apply in the manner hereinafter provided, to register the death'}, {'Question': 'When will the provisions of this Act be in effect?', 'Answer': 'commencement', 'id': 3, 'context': 'The provisions of this Act shall be in operation for a period of two years from the date of its commencement who may apply for death certificates.'}, {'Question': 'What is the purpose of the death certificate?', 'Answer': 'provisions', 'id': 4, 'context': 'The provisions of this Act shall be in operation for a period of two years from the date of its commencement who may apply for death certificates.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the District Register of Deaths and Births of the district in which the person was last residing?', 'Answer': 'births', 'id': 1, 'context': 'Every application under this Act to register the death of a person shall be made to the District Register of Births and Deaths of the district in which such person was last residing, and shall be in the Form set out in the Schedule to this Act. of such persons under the Births and Deaths Registration Act (Chapter 110) and to have issued to him, a Certificate of Death in respect of such person.'}, {'Question': 'What is the Births and Deaths Registration Act?', 'Answer': 'chapter', 'id': 2, 'context': 'of such persons under the Births and Deaths Registration Act (Chapter 110) and to have issued to him, a Certificate of Death in respect of such person.'}, {'Question': 'What is the procedure or application?', 'Answer': 'procedure', 'id': 3, 'context': 'Procedure or application 3.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Whose affidavit sets out the grounds for his belief that the person whose death is sought to be registered is death and shall be accompanied?', 'Answer': 'applicant', 'id': 1, 'context': 'by an affidavit of the applicant setting out the grounds for his belief that the person whose death is sought to the registered ,is death and shall be accompanied ,a report from the Grama Niladhari of the Grama Niladhari Division in which the person whose death is sought to be registered, was last resident confirming the fact bat such person has not been seen alive or heard of, for a period of over one year, and any other evidence in support of such application.'}, {'Question': 'What is the purpose of application 5?', 'Answer': 'display', 'id': 2, 'context': 'display of application 5.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the object of registrations?', 'Answer': 'registrations', 'id': 1, 'context': 'Objection of registrations.'}, {'Question': 'What shall be displayed on the Notice Board for a period of two weeks on the notice board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered, was last resident or had his permanent residence?', 'Answer': 'copy', 'id': 2, 'context': 'application under this Act, the District Registrar shall cause a copy of such application to be, displayed for a period of two weeks on the Notice Board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered, was last resident or had his permanent residence. Any person may within one month of the date on which a copy of an application under this Act is first displayed, forward to the District Registrar, h'}, {'Question': 'What is the act that allows a copy of an application to be displayed on the Notice Board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered, was last resident or had his permanent residence?', 'Answer': 'act', 'id': 3, 'context': 'application under this Act, the District Registrar shall cause a copy of such application to be, displayed for a period of two weeks on the Notice Board kept at his office and in the office of the Grama Niladhari in whose division the person whose death is sought to be registered, was last resident or had his permanent residence. Any person may within one month of the date on which a copy of an application under this Act is first displayed, forward to the District Registrar, h'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the process of submitting objections to an application?', 'Answer': 'forwarding', 'id': 1, 'context': '(1) On the expiry of the period of one month allowed or the forwarding of objections to an application, the District Registrar shall consider the application together with the evidence in support of the application and objections, if any'}, {'Question': 'What is the registration of the death of the person to whom such application relates?', 'Answer': 'objections', 'id': 2, 'context': 'is objections in writing to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of the objector and of any other person, set~ ting out the grounds for their objections. is objections in writing to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of the objector and of any other person, set~ ting out the grounds for their objections. is objections in writing to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of the objector and of any other person, set~ ting out the grounds for their objections.'}, {'Question': 'What is the process of death?', 'Answer': 'registration', 'id': 3, 'context': 'is objections in writing to the registration of the death of the person to whom such application relates, and such objections shall be supported by an affidavit of the objector and of any other person, set~ ting out the grounds for their objections. Registration of death 7.'}, {'Question': 'What is the maximum time allowed for the processing of objections to an application?', 'Answer': 'month', 'id': 4, 'context': '(1) On the expiry of the period of one month allowed or the forwarding of objections to an application, the District Registrar shall consider the application together with the evidence in support of the application and objections, if any'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the birth and death registration act?', 'Answer': 'births', 'id': 1, 'context': ', and the evidence in support of such objections and after such inquiry as he may deem necessary, if satisfied, as to the truth of the matters stated in the application, allow such application and shall send to the Registrar- General a Certificate under his hand setting out such of the particulars of the death as are required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid.'}, {'Question': 'What is required to be registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'particulars', 'id': 2, 'context': ', and the evidence in support of such objections and after such inquiry as he may deem necessary, if satisfied, as to the truth of the matters stated in the application, allow such application and shall send to the Registrar- General a Certificate under his hand setting out such of the particulars of the death as are required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid.'}, {'Question': 'What is necessary to ascertain the truth of the matter stated in the application?', 'Answer': 'inquiry', 'id': 3, 'context': ', and the evidence in support of such objections and after such inquiry as he may deem necessary, if satisfied, as to the truth of the matters stated in the application, allow such application and shall send to the Registrar- General a Certificate under his hand setting out such of the particulars of the death as are required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid. , and the evidence in support of such objections and after such inquiry as he may deem necessary, if satisfied, as to the truth of the matters stated in the application, allow such application and shall send to the Registrar- General a Certificate under his hand setting out such of the particulars of the death as are required to be registered, under the Births and Deaths Registration Act (Chapter 110) as he has been able to ascertain after such inquiry as aforesaid.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the birth certificate that the Registrar-General makes order directing the appropriate Registrar to enter in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'births', 'id': 1, 'context': 'ction (1) the Registrar- General shall, except in a case where he cancels a certificate in the exercise of the powers conferred on him by section 8, make order directing the appropriate Registrar to enter in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110) the particulars specified in such certificate.'}, {'Question': 'What is specified in a birth certificate under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'particulars', 'id': 2, 'context': 'ction (1) the Registrar- General shall, except in a case where he cancels a certificate in the exercise of the powers conferred on him by section 8, make order directing the appropriate Registrar to enter in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110) the particulars specified in such certificate. (3) On receipt by a Registrar of an order under subsection (2) directing him to enter the particulars relating to death in the Register of Deaths'}, {'Question': 'What is the name of the register maintained by the Registrar under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'register', 'id': 3, 'context': 'ction (1) the Registrar- General shall, except in a case where he cancels a certificate in the exercise of the powers conferred on him by section 8, make order directing the appropriate Registrar to enter in the Register of Deaths maintained by such Registrar under the Births and Deaths Registration Act (Chapter 110) the particulars specified in such certificate. (3) On receipt by a Registrar of an order under subsection (2) directing him to enter the particulars relating to death in the Register of Deaths'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the births and deaths registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'births', 'id': 1, 'context': 'maintained by him, under the Births and Deaths Registration Act (Chapter 110), the Registrar shall forthwith enter those particulars in such register and sign the register in the appropriate place.'}, {'Question': 'What is the name of the registration entry that must be attached to the order?', 'Answer': 'duplicate', 'id': 2, 'context': '(4) Every written order under subsection (2) shall be attached to the duplicate of the relevant registration entry and shall be sent, together with that duplicate, to the appropriate District Registrar for transmission to the Registrar-General for custody in his office. (4) Every written order under subsection (2) shall be attached to the duplicate of the relevant registration entry and shall be sent, together with that duplicate, to the appropriate District Registrar for transmission to the Registrar-General for custody in his office.'}, {'Question': 'What must the Registrar enter in the register?', 'Answer': 'particulars', 'id': 3, 'context': 'maintained by him, under the Births and Deaths Registration Act (Chapter 110), the Registrar shall forthwith enter those particulars in such register and sign the register in the appropriate place.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the process of a refusal by the District Registrar to issue a certificate under this Act?', 'Answer': 'notification', 'id': 1, 'context': 'An applicant who is dissatisfied with the decision of the District Registrar refusing to issue a certificate to him under section 7 or a person who has objected under section 6 to the issue of a certificate under this Act and who is dissatisfied with the decision of the District Registrar to issue such certificate may within one month of the notification of such refusal or issue, as the case may be, appeal to the Registrar-General against such refusal or issue, as the case may be- The Registr'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How is death registered under this Act?', 'Answer': 'pursuance', 'id': 1, 'context': '(1) Where any death has been registered in pursuance of an application made under this Act, and any person at any time thereafter becomes aware that the person whose death has been'}, {'Question': 'What may be issued by the District Registrar under section 7 or cancelled by the District Registrar under section 7?', 'Answer': 'certificate', 'id': 2, 'context': 'ar-General may after review of the material before him, affirm the decision of the District Registrar or direct the District Registrar to issue a certificate under section 7 or cancel a certificate issued by that District Registrar under section 7, as the case may be Procedure if person registered as dead is found to be alive. ar-General may after review of the material before him, affirm the decision of the District Registrar or direct the District Registrar to issue a certificate under section 7 or cancel a certificate issued by that District Registrar under section 7, as the case may be Procedure if person registered as dead is found to be alive.'}, {'Question': 'What is the application made under this Act?', 'Answer': 'application', 'id': 3, 'context': '(1) Where any death has been registered in pursuance of an application made under this Act, and any person at any time thereafter becomes aware that the person whose death has been'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Where is the information to be given to the Officer-in-charge of?', 'Answer': 'police station', 'id': 1, 'context': 'so registered is alive, he shall forthwith furnish such information to the Registrar-General (2) The Registrar-General, shall on receipt of such Information convey the informal ion to the Officer-in-charge of the relevant police station, who shall investigate the truth of such information and make a report to the Registrar-General, within four weeks of the date on which such information is conveyed to such officer.'}, {'Question': 'When does the Registrar-General convey the information to the Officer-in-charge of the relevant police station?', 'Answer': 'receipt', 'id': 2, 'context': 'so registered is alive, he shall forthwith furnish such information to the Registrar-General (2) The Registrar-General, shall on receipt of such Information convey the informal ion to the Officer-in-charge of the relevant police station, who shall investigate the truth of such information and make a report to the Registrar-General, within four weeks of the date on which such information is conveyed to such officer. (3) Upon receipt of a report under subsection (2) and after such inquiry as he may deem nece'}, {'Question': 'What is the informal ion?', 'Answer': 'ion', 'id': 3, 'context': 'so registered is alive, he shall forthwith furnish such information to the Registrar-General (2) The Registrar-General, shall on receipt of such Information convey the informal ion to the Officer-in-charge of the relevant police station, who shall investigate the truth of such information and make a report to the Registrar-General, within four weeks of the date on which such information is conveyed to such officer.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'What is the name of the births and deaths registered under the Births and Deaths Registration Act (Chapter 110)?', 'Answer': 'births', 'id': 1, 'context': 'ssary the Registrar-General, if satisfied that the person whose death has been registered is alive, shall take such action, or make such order or give such direction, under section 52 of the Births and Deaths Registration Act (Chapter 110), as is appropriate in the circumstances of the case.'}, {'Question': 'What is the power of the Registrar-General under this Act?', 'Answer': 'inquiry', 'id': 2, 'context': '(4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-Genera] may, for the purposes of an inquiry under this Act, exercise all the power e (4) Any inquiry held by the Registrar-General under this Act shall be concluded within one month of its commencement and the Registrar-Genera] may, for the purposes of an inquiry under this Act, exercise all the power e'}, {'Question': 'What is the Births and Deaths Registration Act?', 'Answer': 'chapter', 'id': 3, 'context': 'ssary the Registrar-General, if satisfied that the person whose death has been registered is alive, shall take such action, or make such order or give such direction, under section 52 of the Births and Deaths Registration Act (Chapter 110), as is appropriate in the circumstances of the case.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'How is death registered under this Act?', 'Answer': 'pursuance', 'id': 1, 'context': 'Any person who- (a) knowingly, makes a false statement in an application made by him under this Act, or furnishes false information under this Act, or (b) being aware that a person whose death has been registered in pursuance of an application made under this Act, is alive, fails to furnish such information to the Registrar-General, or (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act kn'}, {'Question': 'What is the Certificate of Death issued under the Births and Deaths Registration Act kn xercisable by him under the Births and Deaths Registration Act?', 'Answer': 'births', 'id': 2, 'context': 'Any person who- (a) knowingly, makes a false statement in an application made by him under this Act, or furnishes false information under this Act, or (b) being aware that a person whose death has been registered in pursuance of an application made under this Act, is alive, fails to furnish such information to the Registrar-General, or (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act kn xercisable by him under the Births and Deaths.'}, {'Question': 'What is a Certificate of Death issued under the Births and Deaths Registration Act?', 'Answer': 'certificate', 'id': 3, 'context': 'Any person who- (a) knowingly, makes a false statement in an application made by him under this Act, or furnishes false information under this Act, or (b) being aware that a person whose death has been registered in pursuance of an application made under this Act, is alive, fails to furnish such information to the Registrar-General, or (c) dishonestly or fraudulently uses a Certificate of Death issued under the Births and Deaths Registration Act kn'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model for generation\n",
            "{'questions': [{'Question': 'Who will convict a person of an offence under this Act?', 'Answer': 'high court', 'id': 1, 'context': 'owing, or having reason to believe that the person referred to in such certificate is alive; shall be guilty of an offence under this Act, and shall upon conviction after trial by the High Court be sentenced to a term of imprisonment of not less:; than three years and not exceeding five years.'}, {'Question': 'What is the reason for the Sinhala text to prevail in the case of inconsistency between the Tamil and the Sinhala text?', 'Answer': 'inconsistency', 'id': 2, 'context': 'In the event of any inconsistency between the Sinhala and Tamil texts of this Act, the Sinhala text shall prevail. sinhala text to prevail in case of inconsistency 11.'}, {'Question': 'What is the maximum term of imprisonment under this Act?', 'Answer': 'term', 'id': 3, 'context': 'owing, or having reason to believe that the person referred to in such certificate is alive; shall be guilty of an offence under this Act, and shall upon conviction after trial by the High Court be sentenced to a term of imprisonment of not less:; than three years and not exceeding five years.'}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "<ipython-input-3-b0bceeff65fe>:103: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZERO\n",
            "Unexpected structure in the 'outputs' dictionary. Check the structure and update the code.\n",
            "                                                 input  \\\n",
            "0    What is the name of the country that was print...   \n",
            "1            What is the political party of Sri Lanka?   \n",
            "2     Where is the Government Printing Bureau located?   \n",
            "3    What is DIRECTLY ATTRIBUTABLE TO ANY NATURAL D...   \n",
            "4    AN ACT TO PROVIDE FOR THE REGISTRATION OF DEAT...   \n",
            "..                                                 ...   \n",
            "614  What is the Certificate of Death issued under ...   \n",
            "615  What is a Certificate of Death issued under th...   \n",
            "616  Who will convict a person of an offence under ...   \n",
            "617  What is the reason for the Sinhala text to pre...   \n",
            "618  What is the maximum term of imprisonment under...   \n",
            "\n",
            "                                           instruction  \n",
            "0    20.00 PARLIAMENT OF THE DEMOCRATIC SOCIALIST R...  \n",
            "1    20.00 PARLIAMENT OF THE DEMOCRATIC SOCIALIST R...  \n",
            "2    PRINTED AT THE DEPARTMENT OF GOVERNMENT PRINTI...  \n",
            "3    AN ACT TO PROVIDE FOR THE REGISTRATION OF DEAT...  \n",
            "4    AN ACT TO PROVIDE FOR THE REGISTRATION OF DEAT...  \n",
            "..                                                 ...  \n",
            "614  Any person who- (a) knowingly, makes a false s...  \n",
            "615  Any person who- (a) knowingly, makes a false s...  \n",
            "616  owing, or having reason to believe that the pe...  \n",
            "617  In the event of any inconsistency between the ...  \n",
            "618  owing, or having reason to believe that the pe...  \n",
            "\n",
            "[619 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import fitz  # Importing the PyMuPDF library, which provides functionalities for working with PDF files.\n",
        "import pandas as pd  # Importing the pandas library for data manipulation and analysis.\n",
        "import zipfile  # Importing the zipfile module to work with zip files.\n",
        "import os  # Importing the os module for operating system-related functionalities.\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    \"\"\"\n",
        "    Function to extract text from a PDF file.\n",
        "\n",
        "    Parameters:\n",
        "    pdf_file (str): Path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "    str: Extracted text from the PDF.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_file)  # Open the PDF file using PyMuPDF.\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()  # Extract text from each page and concatenate.\n",
        "    return text\n",
        "\n",
        "# Function to chunk text into pieces of a specified size\n",
        "def chunk_text(text, chunk_size=4000):\n",
        "    \"\"\"\n",
        "    Function to chunk text into pieces of a specified size.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): Text to be chunked.\n",
        "    chunk_size (int): Size of each chunk. Default is 4000.\n",
        "\n",
        "    Returns:\n",
        "    list: List of text chunks.\n",
        "    \"\"\"\n",
        "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]  # Split text into chunks.\n",
        "    return chunks\n",
        "\n",
        "# Function to preprocess text (you can customize this)\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Function to preprocess text.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): Text to be preprocessed.\n",
        "\n",
        "    Returns:\n",
        "    str: Preprocessed text.\n",
        "    \"\"\"\n",
        "    text = ' '.join(text.split())  # Remove extra whitespaces.\n",
        "    return text\n",
        "\n",
        "# Specify the path to the zip file containing multiple PDFs\n",
        "zip_file_path = '/content/LawDataZip3.zip'\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_df = pd.DataFrame(columns=['input', 'instruction'])\n",
        "\n",
        "# Extract PDFs from the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# List all PDF files in the current working directory\n",
        "pdf_files = [file for file in os.listdir() if file.lower().endswith('.pdf')]\n",
        "# Loop through each PDF file\n",
        "for pdf_file_path in pdf_files:\n",
        "    # Extract text from the PDF\n",
        "    pdf_text = extract_text_from_pdf(pdf_file_path)\n",
        "\n",
        "    # Preprocess the text\n",
        "    cleaned_text = preprocess_text(pdf_text)\n",
        "\n",
        "    # Chunk the text into 512-token pieces since questgen only accepts 512 tokens per input\n",
        "    text_chunks = chunk_text(cleaned_text, chunk_size=512)\n",
        "\n",
        "    payload = {\"input_text\": \"\"}\n",
        "\n",
        "    # Loop through chunks and make predictions\n",
        "    for chunk in text_chunks:\n",
        "        try:\n",
        "            payload[\"input_text\"] = chunk\n",
        "            outputs = qg.predict_shortq(payload)  # Generate short questions using the Questgen library.\n",
        "\n",
        "            # Check the structure of the outputs dictionary\n",
        "            if 'questions' in outputs:\n",
        "                question_list = outputs['questions']\n",
        "            elif 'your_custom_key' in outputs:\n",
        "                question_list = outputs['your_custom_key']\n",
        "            else:\n",
        "                print(\"Unexpected structure in the 'outputs' dictionary. Check the structure and update the code.\")\n",
        "                continue\n",
        "\n",
        "            # Iterate through the extracted questions and contexts\n",
        "            for item in question_list:\n",
        "                question = item.get('Question', '')\n",
        "                context = item.get('context', '')\n",
        "\n",
        "                # Check if question and context are non-empty before processing\n",
        "                if question and context:\n",
        "                    # Include context in the instruction field\n",
        "                    instruction_text = context\n",
        "\n",
        "                    # Append the results to the DataFrame\n",
        "                    results_df = results_df.append({\n",
        "                        \"input\": question,\n",
        "                        \"instruction\": instruction_text\n",
        "                    }, ignore_index=True)\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error processing chunk: {e}\")\n",
        "            continue\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results_df.to_csv('LawDataset4.csv', index=False)\n",
        "\n",
        "# Print the generated DataFrame\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Set the Hugging Face Token**"
      ],
      "metadata": {
        "id": "VL01RpexsdUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # Importing the 'os' module for interacting with the operating system.\n",
        "\n",
        "# Set the environment variable 'HF_TOKEN' Hugging face writ`e token to a specific value.\n",
        "os.environ[\"HF_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "YVI9TXF-scL1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Load the Dataset**"
      ],
      "metadata": {
        "id": "s0XdMaxLslpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset  # Importing the 'load_dataset' function from the 'datasets' package.\n",
        "\n",
        "# Load the dataset named \"zoom12/SriLankaLaw\" using the 'load_dataset' function.\n",
        "dataset = load_dataset(\"zoom12/SriLankaLaw\")\n",
        "\n",
        "# Display the loaded dataset.\n",
        "dataset"
      ],
      "metadata": {
        "id": "KxzO47W0slVg",
        "outputId": "15421ce7-62b1-47a4-faac-9a87830450ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "8d36d3ba722946689886b33e9585fedf",
            "5c2dca8dc12942588b7fb04232826f8e",
            "4a173819714f4c67a531647a103e885a",
            "1d6532d5452a485085caa27907575133",
            "7231d4e557d848efb74ac3d0b876958d",
            "e98ca345ba944f5fb6d62c25a26ac779",
            "284958a6340b42808127c65fcd4a4b92",
            "02b2e2702928414c96dc4299faeb24ae",
            "1fd7d8b6f02e42569c4a455ecc4746a3",
            "fb5dec87cd974a26a47903fec1677338",
            "819659a04d784c66b70c12e61ba35412",
            "df524be1d601484681bd6b9abd2429fe",
            "2749424f0a464a1aa39dc1319df62406",
            "3960fbc308ce4198a3ffe93863c9ce9e",
            "767ffd7ae9e2412e9ead8884a8caa0d8",
            "1812830a4322462798c7a54bd260754a",
            "eef1c5e753704d9bb2e3b367acd55904",
            "30e6c8604cb74d5c9f365bc041e3dc45",
            "093ed6a11ef94026a615eb60f97a12f8",
            "ba5660e49d2d4087aabe668aef34ca30",
            "df2e3d2082434c4f8809ae8e39f53a6d",
            "7c13eb7dd094449383971c09ce441eb6",
            "37335ac97a934fda8d257decb334b600",
            "99f579d4191341b4ab360e996eb31f7d",
            "2a4492f9ba9342d2b8795767176ba6d3",
            "b563853f67e446169e9bb51e558da65e",
            "0236d5e21cae4b3982bf892a05dd6fda",
            "87d005a36a284b66bff9f98799cc4819",
            "10976a32a31e4e2bb3edee28cb32eb0d",
            "8170eed9643b4613bb49bc7e689cdc20",
            "a1f484a9e61b491694d928aaecdd1def",
            "7d87b19733c340febd3600e84bf4e781",
            "399fec787c454739875796a0cf780885"
          ]
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/335 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d36d3ba722946689886b33e9585fedf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/360k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df524be1d601484681bd6b9abd2429fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/2766 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37335ac97a934fda8d257decb334b600"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['output', 'instruction'],\n",
              "        num_rows: 2766\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Load CSV File**"
      ],
      "metadata": {
        "id": "WPex96PNssGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function loads a dataset from various sources such as a CSV file, a JSON file, or an Hugging Face dataset repository.\n",
        "dataset = load_dataset(\"csv\", data_files=\"/content/Law Dataset 4.csv\") # Change the file name to match your output CSV file or any preferred name.\n",
        "\n",
        "# Display the loaded dataset.\n",
        "dataset"
      ],
      "metadata": {
        "id": "0LECRZJlsqi3",
        "outputId": "bf6af1fe-4b8b-43ce-804c-2d02349aa478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "ccfd8304e2a2408d9bf9ad8db4d861e6",
            "d93686775f3e43cf8dc7a11790dd6032",
            "613ac0c432734412827c3ccf67815b51",
            "26f7f623361145ca8d5ba48a02df63c7",
            "7d81acffb99e4364aa8b5969b3aadfb9",
            "eb1fe607d668425eaff47fd8cb568517",
            "aec97a046acf4266a70c0f39d2493715",
            "d3fa5dfd39a244ce8fa58e5f7fb55ce5",
            "2d9855159b56494f99b8d4d6d08539d6",
            "987fe64bda9f401aaeb275dafc598ff2",
            "65da8ace1e6540f8af16b922b3aff899"
          ]
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccfd8304e2a2408d9bf9ad8db4d861e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'instruction'],\n",
              "        num_rows: 619\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Map Chat templates**"
      ],
      "metadata": {
        "id": "wlOZa7pcs2l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_template(example):\n",
        "\n",
        "    example[\"instruction\"] = f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n\"\n",
        "    return example\n",
        "\n",
        "# Apply the 'chat_template' function to each example in the dataset using the 'map' function.\n",
        "dataset = dataset.map(chat_template)"
      ],
      "metadata": {
        "id": "B7NiWIsBs7TA",
        "outputId": "7ea5dadd-9138-48f3-8a7d-831bbd23852c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "313a1cb13ef64f72954ee6c6c490727e",
            "988309523f9b443d8b370ab6fca585ab",
            "2854a9d21c774c5c9138f00693ed4c22",
            "fb340c193abb4d5bad67be6ada211cb5",
            "e05d8cce10c8400b92af92d9cbc2f5e7",
            "f9ecc0a4df2e4864b1d25d2280c8a036",
            "68fe5fefd043444485d390953e4454e7",
            "ddb2cb261e42449992bf7dc4ca27f2ee",
            "a4c2b20205394bd2badc1c1bc93cb467",
            "b161b563bf034b87ba2c51404c6724d0",
            "f790e6ac12ab46b58fce5a445a4db53f"
          ]
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/619 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "313a1cb13ef64f72954ee6c6c490727e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Push the Dataset to Hugging Face Hub**"
      ],
      "metadata": {
        "id": "payQs7vJtBDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.push_to_hub(\"zoom12/SriLankaLaw\") # pushing model to hugging face with the above define write api key"
      ],
      "metadata": {
        "id": "jpdrECHMtFIZ",
        "outputId": "62435fc7-e4c7-4b90-8e5e-a7831a6cf3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "075aa8ee20294c62a2a66c7767e934f4",
            "5f601bb15c5745a797d4fc20a8b418dc",
            "d1c77a25032745d6a69171387d61b9fe",
            "2bc94dd1b49648cabb1e8e8aa1b96e52",
            "ce417157eb3c4ee48b2a898f03edf60f",
            "e01f5cb28466495fb0ddf35ab54a68b4",
            "ff4952e82e204d4abe64ac33e6429ec8",
            "0e5f88ce696a496f88b9a2ada24c7ac0",
            "3a02551672de4e468a6f1e4f81f95604",
            "71532ce2b0494623bb7b0809813c638f",
            "1856084326ff4176b4eef337d66b0d15",
            "974db6d9faf84011b633e4284c1ab132",
            "9e3d9f7054464c2db800e1dbdc78c7ec",
            "5e70a80750584a868cfd1f0f76350eb9",
            "d8cc6832906f49ddb6322a4db28b268c",
            "4d8195a185224fbb8d4fef1c2b6be04c",
            "ea3d86ae95ab4b059147bd059c596172",
            "819e00fe1fcb46e4b2a5e8fbee3eb35c",
            "8bb9caf347094ec18e9643b010528523",
            "5ce9bdd91c624b8fb3cba707c94855ca",
            "c0534a46ebd7415eb31072208ba06bdf",
            "1769b4b077b743fe8ab309813f75aa02",
            "03636db0f3284deb8f6913115b832704",
            "12b6d19c6d634a3eada94997eea161ed",
            "beff34d231794b6b8a78ff035d4a6127",
            "b6db0fdd49094e85a726867d2c2cb2ff",
            "35beca909fbb4d42a58660093731f6af",
            "47d626c9cf1f46aeac0ec99ff2615cc9",
            "2ac63691c8654efea9fc02a45b2789a6",
            "733ab3af3bb6439c92f1b7d6fd6900f7",
            "0f162da3bf284653a2fbaa2def6f2dad",
            "76ff40487a3a4639a3a77d3fab7bdf8d",
            "1c47cb66cd0a4a1caab8e76213d66135"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "075aa8ee20294c62a2a66c7767e934f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "974db6d9faf84011b633e4284c1ab132"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/335 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03636db0f3284deb8f6913115b832704"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/zoom12/SriLankaLaw/commit/0999ef4e130c67f44a2225eebc77b8e1f96839bf', commit_message='Upload dataset', commit_description='', oid='0999ef4e130c67f44a2225eebc77b8e1f96839bf', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b53d699cd1cd40c49d84f0eaa688d068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7762674f5c3c4636bcf11e644f154d2c",
              "IPY_MODEL_b5175cdd4d9549d2851ff698c9f447e2",
              "IPY_MODEL_cf5922237ba846ef8167113628dee223"
            ],
            "layout": "IPY_MODEL_2eb5e889b15a4a17bb53810a32a72693"
          }
        },
        "7762674f5c3c4636bcf11e644f154d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d21ac0e4eb8441f5901b7329e70973a4",
            "placeholder": "​",
            "style": "IPY_MODEL_2c37b256835c4356b69e67853dd196f7",
            "value": "spiece.model: 100%"
          }
        },
        "b5175cdd4d9549d2851ff698c9f447e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e5e57de850a42d99b51545f13b4c8f1",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92fae06ae8f042339ca77823f2c66da8",
            "value": 791656
          }
        },
        "cf5922237ba846ef8167113628dee223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e9320fc2cc6433f94d92f7c6b4b95d7",
            "placeholder": "​",
            "style": "IPY_MODEL_bbe40f5ab4154473a0a61688314791ad",
            "value": " 792k/792k [00:00&lt;00:00, 6.34MB/s]"
          }
        },
        "2eb5e889b15a4a17bb53810a32a72693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d21ac0e4eb8441f5901b7329e70973a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c37b256835c4356b69e67853dd196f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e5e57de850a42d99b51545f13b4c8f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92fae06ae8f042339ca77823f2c66da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e9320fc2cc6433f94d92f7c6b4b95d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbe40f5ab4154473a0a61688314791ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b5afe3b1dfc4b0fbc40db6cfa38cbd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_420625c7c20e4c7ab17658c1c29dc7b4",
              "IPY_MODEL_1c0f1fe4c56f47d88b57a9cce1bf6cca",
              "IPY_MODEL_1fd6c2e019fd4ebdb2ecb0b7e0bf883d"
            ],
            "layout": "IPY_MODEL_3e22ea1534bc401cb6ce8943b65eb84b"
          }
        },
        "420625c7c20e4c7ab17658c1c29dc7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d16b9236474b45a8b9f8e42414778e",
            "placeholder": "​",
            "style": "IPY_MODEL_4408ed4063294ab2927afaf231337718",
            "value": "config.json: 100%"
          }
        },
        "1c0f1fe4c56f47d88b57a9cce1bf6cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d0aec02da74f9a8f6ba5b73d2d6516",
            "max": 1209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03e44ab47e4c42d6a5c12e2c69d4b79a",
            "value": 1209
          }
        },
        "1fd6c2e019fd4ebdb2ecb0b7e0bf883d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d901407748144b3d99c6a4b96f8d137e",
            "placeholder": "​",
            "style": "IPY_MODEL_a1f1d003b3854960bb6274f7035634bc",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 62.8kB/s]"
          }
        },
        "3e22ea1534bc401cb6ce8943b65eb84b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d16b9236474b45a8b9f8e42414778e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4408ed4063294ab2927afaf231337718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4d0aec02da74f9a8f6ba5b73d2d6516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e44ab47e4c42d6a5c12e2c69d4b79a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d901407748144b3d99c6a4b96f8d137e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f1d003b3854960bb6274f7035634bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "503dad18262e44dc84bcc283148e8159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fbe1756fa5e4736863a547c9f681d2c",
              "IPY_MODEL_650b80d6fd274fff9623ec26ac0867b4",
              "IPY_MODEL_fc00e15918e744a69fd19b71b25cbb66"
            ],
            "layout": "IPY_MODEL_f775f8b867eb4acc8865376282092cbf"
          }
        },
        "3fbe1756fa5e4736863a547c9f681d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05cc85246807451383fe29320725adca",
            "placeholder": "​",
            "style": "IPY_MODEL_9a2b3e1a44154160b2a720d2a095ce41",
            "value": "config.json: 100%"
          }
        },
        "650b80d6fd274fff9623ec26ac0867b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc0dbb0b88dc43fe909447b734eac4bb",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3bf925b4f4648159956c59a4fe806bc",
            "value": 1208
          }
        },
        "fc00e15918e744a69fd19b71b25cbb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bd4c536323f4f1890b1ec220b321666",
            "placeholder": "​",
            "style": "IPY_MODEL_6e54ea6665c146b7834c7043b4dd6e4a",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 42.0kB/s]"
          }
        },
        "f775f8b867eb4acc8865376282092cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05cc85246807451383fe29320725adca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2b3e1a44154160b2a720d2a095ce41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc0dbb0b88dc43fe909447b734eac4bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3bf925b4f4648159956c59a4fe806bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bd4c536323f4f1890b1ec220b321666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e54ea6665c146b7834c7043b4dd6e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "323be172daf54fd681683410c6e8fc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fab2d55fce8745b6a1130d7843882d7d",
              "IPY_MODEL_6aef4510ffa144debf0d312909afee37",
              "IPY_MODEL_0fd2511e131b4fc88a9645734ebdf4ca"
            ],
            "layout": "IPY_MODEL_a4696b5bea264d2091a2b36322e3da6b"
          }
        },
        "fab2d55fce8745b6a1130d7843882d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41371909325499e8cf83fafa16924b9",
            "placeholder": "​",
            "style": "IPY_MODEL_36396aaa899b4983870ebbcf3243a9f8",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "6aef4510ffa144debf0d312909afee37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4acfaef57f964c75a1fd9af9b35e4f5b",
            "max": 891695056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eccda2d6bd0745ad8f1f2041de1590a1",
            "value": 891695056
          }
        },
        "0fd2511e131b4fc88a9645734ebdf4ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d5799e46834de088fba9a571d31372",
            "placeholder": "​",
            "style": "IPY_MODEL_31f7bb6d0f47401d86bbae361c86f687",
            "value": " 892M/892M [00:09&lt;00:00, 44.0MB/s]"
          }
        },
        "a4696b5bea264d2091a2b36322e3da6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41371909325499e8cf83fafa16924b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36396aaa899b4983870ebbcf3243a9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4acfaef57f964c75a1fd9af9b35e4f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eccda2d6bd0745ad8f1f2041de1590a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76d5799e46834de088fba9a571d31372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f7bb6d0f47401d86bbae361c86f687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d36d3ba722946689886b33e9585fedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c2dca8dc12942588b7fb04232826f8e",
              "IPY_MODEL_4a173819714f4c67a531647a103e885a",
              "IPY_MODEL_1d6532d5452a485085caa27907575133"
            ],
            "layout": "IPY_MODEL_7231d4e557d848efb74ac3d0b876958d"
          }
        },
        "5c2dca8dc12942588b7fb04232826f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e98ca345ba944f5fb6d62c25a26ac779",
            "placeholder": "​",
            "style": "IPY_MODEL_284958a6340b42808127c65fcd4a4b92",
            "value": "Downloading readme: 100%"
          }
        },
        "4a173819714f4c67a531647a103e885a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b2e2702928414c96dc4299faeb24ae",
            "max": 335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fd7d8b6f02e42569c4a455ecc4746a3",
            "value": 335
          }
        },
        "1d6532d5452a485085caa27907575133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb5dec87cd974a26a47903fec1677338",
            "placeholder": "​",
            "style": "IPY_MODEL_819659a04d784c66b70c12e61ba35412",
            "value": " 335/335 [00:00&lt;00:00, 16.7kB/s]"
          }
        },
        "7231d4e557d848efb74ac3d0b876958d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98ca345ba944f5fb6d62c25a26ac779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "284958a6340b42808127c65fcd4a4b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02b2e2702928414c96dc4299faeb24ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd7d8b6f02e42569c4a455ecc4746a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb5dec87cd974a26a47903fec1677338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819659a04d784c66b70c12e61ba35412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df524be1d601484681bd6b9abd2429fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2749424f0a464a1aa39dc1319df62406",
              "IPY_MODEL_3960fbc308ce4198a3ffe93863c9ce9e",
              "IPY_MODEL_767ffd7ae9e2412e9ead8884a8caa0d8"
            ],
            "layout": "IPY_MODEL_1812830a4322462798c7a54bd260754a"
          }
        },
        "2749424f0a464a1aa39dc1319df62406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef1c5e753704d9bb2e3b367acd55904",
            "placeholder": "​",
            "style": "IPY_MODEL_30e6c8604cb74d5c9f365bc041e3dc45",
            "value": "Downloading data: 100%"
          }
        },
        "3960fbc308ce4198a3ffe93863c9ce9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_093ed6a11ef94026a615eb60f97a12f8",
            "max": 360083,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba5660e49d2d4087aabe668aef34ca30",
            "value": 360083
          }
        },
        "767ffd7ae9e2412e9ead8884a8caa0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df2e3d2082434c4f8809ae8e39f53a6d",
            "placeholder": "​",
            "style": "IPY_MODEL_7c13eb7dd094449383971c09ce441eb6",
            "value": " 360k/360k [00:00&lt;00:00, 579kB/s]"
          }
        },
        "1812830a4322462798c7a54bd260754a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef1c5e753704d9bb2e3b367acd55904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e6c8604cb74d5c9f365bc041e3dc45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "093ed6a11ef94026a615eb60f97a12f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5660e49d2d4087aabe668aef34ca30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df2e3d2082434c4f8809ae8e39f53a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c13eb7dd094449383971c09ce441eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37335ac97a934fda8d257decb334b600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99f579d4191341b4ab360e996eb31f7d",
              "IPY_MODEL_2a4492f9ba9342d2b8795767176ba6d3",
              "IPY_MODEL_b563853f67e446169e9bb51e558da65e"
            ],
            "layout": "IPY_MODEL_0236d5e21cae4b3982bf892a05dd6fda"
          }
        },
        "99f579d4191341b4ab360e996eb31f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87d005a36a284b66bff9f98799cc4819",
            "placeholder": "​",
            "style": "IPY_MODEL_10976a32a31e4e2bb3edee28cb32eb0d",
            "value": "Generating train split: 100%"
          }
        },
        "2a4492f9ba9342d2b8795767176ba6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8170eed9643b4613bb49bc7e689cdc20",
            "max": 2766,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1f484a9e61b491694d928aaecdd1def",
            "value": 2766
          }
        },
        "b563853f67e446169e9bb51e558da65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d87b19733c340febd3600e84bf4e781",
            "placeholder": "​",
            "style": "IPY_MODEL_399fec787c454739875796a0cf780885",
            "value": " 2766/2766 [00:00&lt;00:00, 42351.24 examples/s]"
          }
        },
        "0236d5e21cae4b3982bf892a05dd6fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d005a36a284b66bff9f98799cc4819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10976a32a31e4e2bb3edee28cb32eb0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8170eed9643b4613bb49bc7e689cdc20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f484a9e61b491694d928aaecdd1def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d87b19733c340febd3600e84bf4e781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399fec787c454739875796a0cf780885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccfd8304e2a2408d9bf9ad8db4d861e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d93686775f3e43cf8dc7a11790dd6032",
              "IPY_MODEL_613ac0c432734412827c3ccf67815b51",
              "IPY_MODEL_26f7f623361145ca8d5ba48a02df63c7"
            ],
            "layout": "IPY_MODEL_7d81acffb99e4364aa8b5969b3aadfb9"
          }
        },
        "d93686775f3e43cf8dc7a11790dd6032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb1fe607d668425eaff47fd8cb568517",
            "placeholder": "​",
            "style": "IPY_MODEL_aec97a046acf4266a70c0f39d2493715",
            "value": "Generating train split: "
          }
        },
        "613ac0c432734412827c3ccf67815b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3fa5dfd39a244ce8fa58e5f7fb55ce5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d9855159b56494f99b8d4d6d08539d6",
            "value": 1
          }
        },
        "26f7f623361145ca8d5ba48a02df63c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_987fe64bda9f401aaeb275dafc598ff2",
            "placeholder": "​",
            "style": "IPY_MODEL_65da8ace1e6540f8af16b922b3aff899",
            "value": " 619/0 [00:00&lt;00:00, 10418.31 examples/s]"
          }
        },
        "7d81acffb99e4364aa8b5969b3aadfb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb1fe607d668425eaff47fd8cb568517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aec97a046acf4266a70c0f39d2493715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3fa5dfd39a244ce8fa58e5f7fb55ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2d9855159b56494f99b8d4d6d08539d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "987fe64bda9f401aaeb275dafc598ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65da8ace1e6540f8af16b922b3aff899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "313a1cb13ef64f72954ee6c6c490727e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_988309523f9b443d8b370ab6fca585ab",
              "IPY_MODEL_2854a9d21c774c5c9138f00693ed4c22",
              "IPY_MODEL_fb340c193abb4d5bad67be6ada211cb5"
            ],
            "layout": "IPY_MODEL_e05d8cce10c8400b92af92d9cbc2f5e7"
          }
        },
        "988309523f9b443d8b370ab6fca585ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ecc0a4df2e4864b1d25d2280c8a036",
            "placeholder": "​",
            "style": "IPY_MODEL_68fe5fefd043444485d390953e4454e7",
            "value": "Map: 100%"
          }
        },
        "2854a9d21c774c5c9138f00693ed4c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddb2cb261e42449992bf7dc4ca27f2ee",
            "max": 619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4c2b20205394bd2badc1c1bc93cb467",
            "value": 619
          }
        },
        "fb340c193abb4d5bad67be6ada211cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b161b563bf034b87ba2c51404c6724d0",
            "placeholder": "​",
            "style": "IPY_MODEL_f790e6ac12ab46b58fce5a445a4db53f",
            "value": " 619/619 [00:00&lt;00:00, 10476.49 examples/s]"
          }
        },
        "e05d8cce10c8400b92af92d9cbc2f5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ecc0a4df2e4864b1d25d2280c8a036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68fe5fefd043444485d390953e4454e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddb2cb261e42449992bf7dc4ca27f2ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c2b20205394bd2badc1c1bc93cb467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b161b563bf034b87ba2c51404c6724d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f790e6ac12ab46b58fce5a445a4db53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "075aa8ee20294c62a2a66c7767e934f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f601bb15c5745a797d4fc20a8b418dc",
              "IPY_MODEL_d1c77a25032745d6a69171387d61b9fe",
              "IPY_MODEL_2bc94dd1b49648cabb1e8e8aa1b96e52"
            ],
            "layout": "IPY_MODEL_ce417157eb3c4ee48b2a898f03edf60f"
          }
        },
        "5f601bb15c5745a797d4fc20a8b418dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e01f5cb28466495fb0ddf35ab54a68b4",
            "placeholder": "​",
            "style": "IPY_MODEL_ff4952e82e204d4abe64ac33e6429ec8",
            "value": "Uploading the dataset shards: 100%"
          }
        },
        "d1c77a25032745d6a69171387d61b9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5f88ce696a496f88b9a2ada24c7ac0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a02551672de4e468a6f1e4f81f95604",
            "value": 1
          }
        },
        "2bc94dd1b49648cabb1e8e8aa1b96e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71532ce2b0494623bb7b0809813c638f",
            "placeholder": "​",
            "style": "IPY_MODEL_1856084326ff4176b4eef337d66b0d15",
            "value": " 1/1 [00:00&lt;00:00,  1.30it/s]"
          }
        },
        "ce417157eb3c4ee48b2a898f03edf60f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01f5cb28466495fb0ddf35ab54a68b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff4952e82e204d4abe64ac33e6429ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e5f88ce696a496f88b9a2ada24c7ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a02551672de4e468a6f1e4f81f95604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71532ce2b0494623bb7b0809813c638f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1856084326ff4176b4eef337d66b0d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "974db6d9faf84011b633e4284c1ab132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e3d9f7054464c2db800e1dbdc78c7ec",
              "IPY_MODEL_5e70a80750584a868cfd1f0f76350eb9",
              "IPY_MODEL_d8cc6832906f49ddb6322a4db28b268c"
            ],
            "layout": "IPY_MODEL_4d8195a185224fbb8d4fef1c2b6be04c"
          }
        },
        "9e3d9f7054464c2db800e1dbdc78c7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea3d86ae95ab4b059147bd059c596172",
            "placeholder": "​",
            "style": "IPY_MODEL_819e00fe1fcb46e4b2a5e8fbee3eb35c",
            "value": "Creating parquet from Arrow format: 100%"
          }
        },
        "5e70a80750584a868cfd1f0f76350eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb9caf347094ec18e9643b010528523",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ce9bdd91c624b8fb3cba707c94855ca",
            "value": 1
          }
        },
        "d8cc6832906f49ddb6322a4db28b268c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0534a46ebd7415eb31072208ba06bdf",
            "placeholder": "​",
            "style": "IPY_MODEL_1769b4b077b743fe8ab309813f75aa02",
            "value": " 1/1 [00:00&lt;00:00, 44.47ba/s]"
          }
        },
        "4d8195a185224fbb8d4fef1c2b6be04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3d86ae95ab4b059147bd059c596172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819e00fe1fcb46e4b2a5e8fbee3eb35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bb9caf347094ec18e9643b010528523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce9bdd91c624b8fb3cba707c94855ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0534a46ebd7415eb31072208ba06bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1769b4b077b743fe8ab309813f75aa02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03636db0f3284deb8f6913115b832704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12b6d19c6d634a3eada94997eea161ed",
              "IPY_MODEL_beff34d231794b6b8a78ff035d4a6127",
              "IPY_MODEL_b6db0fdd49094e85a726867d2c2cb2ff"
            ],
            "layout": "IPY_MODEL_35beca909fbb4d42a58660093731f6af"
          }
        },
        "12b6d19c6d634a3eada94997eea161ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47d626c9cf1f46aeac0ec99ff2615cc9",
            "placeholder": "​",
            "style": "IPY_MODEL_2ac63691c8654efea9fc02a45b2789a6",
            "value": "README.md: 100%"
          }
        },
        "beff34d231794b6b8a78ff035d4a6127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_733ab3af3bb6439c92f1b7d6fd6900f7",
            "max": 335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f162da3bf284653a2fbaa2def6f2dad",
            "value": 335
          }
        },
        "b6db0fdd49094e85a726867d2c2cb2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ff40487a3a4639a3a77d3fab7bdf8d",
            "placeholder": "​",
            "style": "IPY_MODEL_1c47cb66cd0a4a1caab8e76213d66135",
            "value": " 335/335 [00:00&lt;00:00, 24.8kB/s]"
          }
        },
        "35beca909fbb4d42a58660093731f6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d626c9cf1f46aeac0ec99ff2615cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac63691c8654efea9fc02a45b2789a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "733ab3af3bb6439c92f1b7d6fd6900f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f162da3bf284653a2fbaa2def6f2dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76ff40487a3a4639a3a77d3fab7bdf8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c47cb66cd0a4a1caab8e76213d66135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}